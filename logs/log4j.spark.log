21/03/20 10:56:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/20 10:56:25 INFO SecurityManager: Changing view acls to: wilto
21/03/20 10:56:25 INFO SecurityManager: Changing modify acls to: wilto
21/03/20 10:56:25 INFO SecurityManager: Changing view acls groups to: 
21/03/20 10:56:25 INFO SecurityManager: Changing modify acls groups to: 
21/03/20 10:56:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wilto); groups with view permissions: Set(); users  with modify permissions: Set(wilto); groups with modify permissions: Set()
21/03/20 10:56:29 INFO HiveConf: Found configuration file file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/03/20 10:56:30 INFO SparkContext: Running Spark version 3.0.1
21/03/20 10:56:30 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/03/20 10:56:30 INFO ResourceUtils: ==============================================================
21/03/20 10:56:30 INFO ResourceUtils: Resources for spark.driver:

21/03/20 10:56:30 INFO ResourceUtils: ==============================================================
21/03/20 10:56:30 INFO SparkContext: Submitted application: sparklyr
21/03/20 10:56:31 INFO SecurityManager: Changing view acls to: wilto
21/03/20 10:56:31 INFO SecurityManager: Changing modify acls to: wilto
21/03/20 10:56:31 INFO SecurityManager: Changing view acls groups to: 
21/03/20 10:56:31 INFO SecurityManager: Changing modify acls groups to: 
21/03/20 10:56:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wilto); groups with view permissions: Set(); users  with modify permissions: Set(wilto); groups with modify permissions: Set()
21/03/20 10:56:31 INFO Utils: Successfully started service 'sparkDriver' on port 49527.
21/03/20 10:56:31 INFO SparkEnv: Registering MapOutputTracker
21/03/20 10:56:31 INFO SparkEnv: Registering BlockManagerMaster
21/03/20 10:56:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/20 10:56:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/20 10:56:31 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/03/20 10:56:31 INFO DiskBlockManager: Created local directory at C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\blockmgr-67605c8a-1ea9-47c4-98ab-e829bce92fb1
21/03/20 10:56:32 INFO MemoryStore: MemoryStore started with capacity 413.9 MiB
21/03/20 10:56:32 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/20 10:56:32 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/local]. Please check your configured local directories.
21/03/20 10:56:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/20 10:56:33 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
21/03/20 10:56:33 INFO SparkContext: Added JAR file:/C:/Users/wilto/OneDrive/Documentos/R/win-library/4.0/sparklyr/java/sparklyr-3.0-2.12.jar at spark://127.0.0.1:49527/jars/sparklyr-3.0-2.12.jar with timestamp 1616248593181
21/03/20 10:56:33 INFO Executor: Starting executor ID driver on host 127.0.0.1
21/03/20 10:56:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49570.
21/03/20 10:56:33 INFO NettyBlockTransferService: Server created on 127.0.0.1:49570
21/03/20 10:56:33 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/20 10:56:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 49570, None)
21/03/20 10:56:33 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:49570 with 413.9 MiB RAM, BlockManagerId(driver, 127.0.0.1, 49570, None)
21/03/20 10:56:33 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 49570, None)
21/03/20 10:56:33 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 49570, None)
21/03/20 10:56:34 INFO SharedState: loading hive config file: file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/03/20 10:56:34 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive').
21/03/20 10:56:34 INFO SharedState: Warehouse path is 'C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive'.
21/03/20 10:56:35 WARN SharedState: Not allowing to set spark.sql.warehouse.dir or hive.metastore.warehouse.dir in SparkSession's options, it should be set statically for cross-session usages
21/03/20 10:56:44 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/03/20 10:56:44 INFO HiveConf: Found configuration file file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/03/20 10:56:47 INFO SessionState: Created HDFS directory: C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive/wilto/2301c645-a33f-424f-8819-83c196442a97
21/03/20 10:56:47 INFO SessionState: Created local directory: C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive/2301c645-a33f-424f-8819-83c196442a97
21/03/20 10:56:48 INFO SessionState: Created HDFS directory: C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive/wilto/2301c645-a33f-424f-8819-83c196442a97/_tmp_space.db
21/03/20 10:56:48 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive
21/03/20 10:56:51 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/03/20 10:56:51 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/03/20 10:56:51 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/20 10:56:51 INFO ObjectStore: ObjectStore, initialize called
21/03/20 10:56:52 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/20 10:56:52 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/20 10:56:55 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/20 10:56:59 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/20 10:56:59 INFO ObjectStore: Initialized ObjectStore
21/03/20 10:56:59 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/03/20 10:56:59 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.1.38
21/03/20 10:56:59 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/20 10:56:59 INFO HiveMetaStore: Added admin role in metastore
21/03/20 10:56:59 INFO HiveMetaStore: Added public role in metastore
21/03/20 10:56:59 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/20 10:57:00 INFO HiveMetaStore: 0: get_all_functions
21/03/20 10:57:00 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_all_functions	
21/03/20 10:57:00 INFO HiveMetaStore: 0: get_database: default
21/03/20 10:57:00 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 10:57:00 INFO HiveMetaStore: 0: get_database: global_temp
21/03/20 10:57:00 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/20 10:57:00 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/20 10:57:00 INFO HiveMetaStore: 0: get_database: default
21/03/20 10:57:00 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 10:57:00 INFO HiveMetaStore: 0: get_database: default
21/03/20 10:57:00 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 10:57:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 10:57:00 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 10:57:03 INFO CodeGenerator: Code generated in 564.8503 ms
21/03/20 10:57:03 INFO CodeGenerator: Code generated in 19.1008 ms
21/03/20 10:57:04 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 10:57:04 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/03/20 10:57:04 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/03/20 10:57:04 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/03/20 10:57:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/03/20 10:57:04 INFO DAGScheduler: Missing parents: List()
21/03/20 10:57:04 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/03/20 10:57:04 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
21/03/20 10:57:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 10:57:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 10:57:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:49570 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 10:57:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/03/20 10:57:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 10:57:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/20 10:57:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/03/20 10:57:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/03/20 10:57:05 INFO Executor: Fetching spark://127.0.0.1:49527/jars/sparklyr-3.0-2.12.jar with timestamp 1616248593181
21/03/20 10:57:05 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:49527 after 128 ms (0 ms spent in bootstraps)
21/03/20 10:57:05 INFO Utils: Fetching spark://127.0.0.1:49527/jars/sparklyr-3.0-2.12.jar to C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-3ebfcad6-5997-4eab-ba99-6d7bab283df3\userFiles-b1c4ad52-72ac-47d1-99b8-e0e251fb8458\fetchFileTemp8483772754468951602.tmp
21/03/20 10:57:06 INFO Executor: Adding file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/local/spark-3ebfcad6-5997-4eab-ba99-6d7bab283df3/userFiles-b1c4ad52-72ac-47d1-99b8-e0e251fb8458/sparklyr-3.0-2.12.jar to class loader
21/03/20 10:57:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 10:57:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
21/03/20 10:57:06 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2727 bytes result sent to driver
21/03/20 10:57:06 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 1667 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 10:57:06 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/20 10:57:06 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 2,200 s
21/03/20 10:57:06 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 10:57:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/03/20 10:57:06 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 2,358063 s
21/03/20 10:57:07 INFO HiveMetaStore: 0: get_database: default
21/03/20 10:57:07 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 10:57:07 INFO HiveMetaStore: 0: get_database: default
21/03/20 10:57:07 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 10:57:07 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 10:57:07 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 10:57:07 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 10:57:07 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/03/20 10:57:07 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/03/20 10:57:07 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/20 10:57:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/20 10:57:07 INFO DAGScheduler: Missing parents: List()
21/03/20 10:57:07 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/03/20 10:57:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 10:57:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 10:57:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:49570 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 10:57:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/03/20 10:57:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 10:57:07 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/20 10:57:07 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/03/20 10:57:07 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/03/20 10:57:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 10:57:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 10:57:07 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2598 bytes result sent to driver
21/03/20 10:57:07 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 10:57:07 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/20 10:57:07 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0,040 s
21/03/20 10:57:07 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 10:57:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/03/20 10:57:07 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0,050531 s
21/03/20 10:57:26 INFO HiveMetaStore: 0: get_database: default
21/03/20 10:57:26 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 10:57:26 INFO HiveMetaStore: 0: get_database: default
21/03/20 10:57:26 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 10:57:26 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 10:57:26 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 10:57:26 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:49570 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 10:57:26 INFO SparkContext: Starting job: collect at utils.scala:54
21/03/20 10:57:26 INFO DAGScheduler: Job 2 finished: collect at utils.scala:54, took 0,000314 s
21/03/20 10:57:27 INFO CodeGenerator: Code generated in 21.7224 ms
21/03/20 10:57:28 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 10:57:28 INFO DAGScheduler: Got job 3 (collect at utils.scala:137) with 1 output partitions
21/03/20 10:57:28 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:137)
21/03/20 10:57:28 INFO DAGScheduler: Parents of final stage: List()
21/03/20 10:57:28 INFO DAGScheduler: Missing parents: List()
21/03/20 10:57:28 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:137), which has no missing parents
21/03/20 10:57:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.7 KiB, free 413.9 MiB)
21/03/20 10:57:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 413.9 MiB)
21/03/20 10:57:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:49570 (size: 3.3 KiB, free: 413.9 MiB)
21/03/20 10:57:28 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1223
21/03/20 10:57:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 10:57:28 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/20 10:57:28 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 2, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 10:57:28 INFO Executor: Running task 0.0 in stage 4.0 (TID 2)
21/03/20 10:57:28 INFO Executor: Finished task 0.0 in stage 4.0 (TID 2). 1397 bytes result sent to driver
21/03/20 10:57:28 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 2) in 32 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 10:57:28 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/20 10:57:28 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:137) finished in 0,052 s
21/03/20 10:57:28 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 10:57:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
21/03/20 10:57:28 INFO DAGScheduler: Job 3 finished: collect at utils.scala:137, took 0,065088 s
21/03/20 10:57:28 INFO CodeGenerator: Code generated in 28.4229 ms
21/03/20 10:57:28 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:49570 in memory (size: 3.3 KiB, free: 413.9 MiB)
21/03/20 10:57:28 INFO CodeGenerator: Code generated in 16.4026 ms
21/03/20 10:57:28 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 10:57:28 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135) as input to shuffle 2
21/03/20 10:57:28 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/20 10:57:28 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/20 10:57:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/20 10:57:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/20 10:57:28 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/03/20 10:57:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 10:57:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 10:57:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:49570 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 10:57:28 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1223
21/03/20 10:57:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 10:57:28 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/20 10:57:28 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 10:57:28 INFO Executor: Running task 0.0 in stage 5.0 (TID 3)
21/03/20 10:57:28 INFO Executor: Finished task 0.0 in stage 5.0 (TID 3). 1876 bytes result sent to driver
21/03/20 10:57:28 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 193 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 10:57:28 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/20 10:57:28 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0,257 s
21/03/20 10:57:28 INFO DAGScheduler: looking for newly runnable stages
21/03/20 10:57:28 INFO DAGScheduler: running: Set()
21/03/20 10:57:28 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/20 10:57:28 INFO DAGScheduler: failed: Set()
21/03/20 10:57:28 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/03/20 10:57:28 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 10:57:28 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 10:57:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:49570 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 10:57:28 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1223
21/03/20 10:57:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 10:57:28 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/20 10:57:28 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 10:57:28 INFO Executor: Running task 0.0 in stage 6.0 (TID 4)
21/03/20 10:57:28 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 10:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
21/03/20 10:57:28 INFO Executor: Finished task 0.0 in stage 6.0 (TID 4). 2648 bytes result sent to driver
21/03/20 10:57:28 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 128 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 10:57:28 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/20 10:57:28 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0,156 s
21/03/20 10:57:28 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 10:57:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
21/03/20 10:57:28 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0,461783 s
21/03/20 10:57:29 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:49570 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 10:57:29 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:49570 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 10:57:29 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 10:57:29 INFO DAGScheduler: Got job 5 (collect at utils.scala:137) with 1 output partitions
21/03/20 10:57:29 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:137)
21/03/20 10:57:29 INFO DAGScheduler: Parents of final stage: List()
21/03/20 10:57:29 INFO DAGScheduler: Missing parents: List()
21/03/20 10:57:29 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[28] at collect at utils.scala:137), which has no missing parents
21/03/20 10:57:29 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.5 KiB, free 413.9 MiB)
21/03/20 10:57:29 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 413.9 MiB)
21/03/20 10:57:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:49570 (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 10:57:29 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1223
21/03/20 10:57:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[28] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 10:57:29 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/20 10:57:29 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 10:57:29 INFO Executor: Running task 0.0 in stage 7.0 (TID 5)
21/03/20 10:57:29 INFO Executor: Finished task 0.0 in stage 7.0 (TID 5). 1354 bytes result sent to driver
21/03/20 10:57:29 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 12 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 10:57:29 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/20 10:57:29 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:137) finished in 0,036 s
21/03/20 10:57:29 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 10:57:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
21/03/20 10:57:29 INFO DAGScheduler: Job 5 finished: collect at utils.scala:137, took 0,044614 s
21/03/20 10:57:29 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:49570 in memory (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 10:57:30 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 10:57:30 INFO DAGScheduler: Registering RDD 30 (count at utils.scala:135) as input to shuffle 3
21/03/20 10:57:30 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/20 10:57:30 INFO DAGScheduler: Final stage: ResultStage 9 (count at utils.scala:135)
21/03/20 10:57:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/20 10:57:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/20 10:57:30 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[30] at count at utils.scala:135), which has no missing parents
21/03/20 10:57:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 10:57:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 10:57:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:49570 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 10:57:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1223
21/03/20 10:57:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[30] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 10:57:30 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/20 10:57:30 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 10:57:30 INFO Executor: Running task 0.0 in stage 8.0 (TID 6)
21/03/20 10:57:30 INFO Executor: Finished task 0.0 in stage 8.0 (TID 6). 1790 bytes result sent to driver
21/03/20 10:57:30 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 28 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 10:57:30 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/20 10:57:30 INFO DAGScheduler: ShuffleMapStage 8 (count at utils.scala:135) finished in 0,048 s
21/03/20 10:57:30 INFO DAGScheduler: looking for newly runnable stages
21/03/20 10:57:30 INFO DAGScheduler: running: Set()
21/03/20 10:57:30 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/20 10:57:30 INFO DAGScheduler: failed: Set()
21/03/20 10:57:30 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[33] at count at utils.scala:135), which has no missing parents
21/03/20 10:57:30 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 10:57:30 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 10:57:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:49570 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 10:57:30 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1223
21/03/20 10:57:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[33] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 10:57:30 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/20 10:57:30 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 10:57:30 INFO Executor: Running task 0.0 in stage 9.0 (TID 7)
21/03/20 10:57:30 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 10:57:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 10:57:30 INFO Executor: Finished task 0.0 in stage 9.0 (TID 7). 2562 bytes result sent to driver
21/03/20 10:57:30 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 20 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 10:57:30 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/20 10:57:30 INFO DAGScheduler: ResultStage 9 (count at utils.scala:135) finished in 0,052 s
21/03/20 10:57:30 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 10:57:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
21/03/20 10:57:30 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0,118277 s
21/03/20 10:57:30 INFO HiveMetaStore: 0: get_database: default
21/03/20 10:57:30 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 10:57:30 INFO HiveMetaStore: 0: get_database: default
21/03/20 10:57:30 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 10:57:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 10:57:30 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 10:57:30 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:49570 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 10:57:30 INFO CodeGenerator: Code generated in 34.4377 ms
21/03/20 10:57:30 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:49570 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 10:57:30 INFO CodeGenerator: Code generated in 29.221 ms
21/03/20 10:57:31 INFO CodeGenerator: Code generated in 9.8527 ms
21/03/20 10:57:31 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 10:57:31 INFO DAGScheduler: Registering RDD 36 (count at utils.scala:135) as input to shuffle 4
21/03/20 10:57:31 INFO DAGScheduler: Got job 7 (count at utils.scala:135) with 1 output partitions
21/03/20 10:57:31 INFO DAGScheduler: Final stage: ResultStage 11 (count at utils.scala:135)
21/03/20 10:57:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
21/03/20 10:57:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
21/03/20 10:57:31 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[36] at count at utils.scala:135), which has no missing parents
21/03/20 10:57:31 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 10:57:31 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.9 MiB)
21/03/20 10:57:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:49570 (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 10:57:31 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1223
21/03/20 10:57:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[36] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 10:57:31 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/20 10:57:31 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7498 bytes)
21/03/20 10:57:31 INFO Executor: Running task 0.0 in stage 10.0 (TID 8)
21/03/20 10:57:31 INFO Executor: Finished task 0.0 in stage 10.0 (TID 8). 1790 bytes result sent to driver
21/03/20 10:57:31 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 48 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 10:57:31 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/20 10:57:31 INFO DAGScheduler: ShuffleMapStage 10 (count at utils.scala:135) finished in 0,068 s
21/03/20 10:57:31 INFO DAGScheduler: looking for newly runnable stages
21/03/20 10:57:31 INFO DAGScheduler: running: Set()
21/03/20 10:57:31 INFO DAGScheduler: waiting: Set(ResultStage 11)
21/03/20 10:57:31 INFO DAGScheduler: failed: Set()
21/03/20 10:57:31 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[39] at count at utils.scala:135), which has no missing parents
21/03/20 10:57:31 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 10:57:31 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 10:57:31 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:49570 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 10:57:31 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1223
21/03/20 10:57:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[39] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 10:57:31 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/20 10:57:31 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 9, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 10:57:31 INFO Executor: Running task 0.0 in stage 11.0 (TID 9)
21/03/20 10:57:31 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 10:57:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 10:57:31 INFO Executor: Finished task 0.0 in stage 11.0 (TID 9). 2605 bytes result sent to driver
21/03/20 10:57:31 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 9) in 20 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 10:57:31 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/20 10:57:31 INFO DAGScheduler: ResultStage 11 (count at utils.scala:135) finished in 0,036 s
21/03/20 10:57:31 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 10:57:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
21/03/20 10:57:31 INFO DAGScheduler: Job 7 finished: count at utils.scala:135, took 0,125275 s
21/03/20 10:58:11 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:49570 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 10:58:11 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:49570 in memory (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 10:58:11 INFO CodeGenerator: Code generated in 65.9332 ms
21/03/20 10:58:11 INFO CodeGenerator: Code generated in 22.1428 ms
21/03/20 10:58:11 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 10:58:11 INFO DAGScheduler: Got job 8 (collect at utils.scala:137) with 1 output partitions
21/03/20 10:58:11 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:137)
21/03/20 10:58:11 INFO DAGScheduler: Parents of final stage: List()
21/03/20 10:58:11 INFO DAGScheduler: Missing parents: List()
21/03/20 10:58:11 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[46] at collect at utils.scala:137), which has no missing parents
21/03/20 10:58:11 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 29.0 KiB, free 413.9 MiB)
21/03/20 10:58:11 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 10:58:11 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:49570 (size: 10.0 KiB, free: 413.9 MiB)
21/03/20 10:58:11 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1223
21/03/20 10:58:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[46] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 10:58:11 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/20 10:58:11 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 10, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 10:58:11 INFO Executor: Running task 0.0 in stage 12.0 (TID 10)
21/03/20 10:58:11 INFO MemoryStore: Block rdd_41_0 stored as values in memory (estimated size 3.9 KiB, free 413.9 MiB)
21/03/20 10:58:11 INFO BlockManagerInfo: Added rdd_41_0 in memory on 127.0.0.1:49570 (size: 3.9 KiB, free: 413.9 MiB)
21/03/20 10:58:11 INFO CodeGenerator: Code generated in 13.6661 ms
21/03/20 10:58:11 INFO Executor: 1 block locks were not released by TID = 10:
[rdd_41_0]
21/03/20 10:58:11 INFO Executor: Finished task 0.0 in stage 12.0 (TID 10). 2226 bytes result sent to driver
21/03/20 10:58:11 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 10) in 297 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 10:58:11 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/20 10:58:11 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:137) finished in 0,341 s
21/03/20 10:58:11 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 10:58:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
21/03/20 10:58:11 INFO DAGScheduler: Job 8 finished: collect at utils.scala:137, took 0,358607 s
21/03/20 10:58:11 INFO CodeGenerator: Code generated in 16.4322 ms
21/03/20 10:58:11 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:49570 in memory (size: 10.0 KiB, free: 413.9 MiB)
21/03/20 10:58:11 INFO CodeGenerator: Code generated in 21.1689 ms
21/03/20 10:58:11 INFO CodeGenerator: Code generated in 12.1508 ms
21/03/20 10:58:12 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 10:58:12 INFO DAGScheduler: Registering RDD 51 (count at utils.scala:135) as input to shuffle 5
21/03/20 10:58:12 INFO DAGScheduler: Got job 9 (count at utils.scala:135) with 1 output partitions
21/03/20 10:58:12 INFO DAGScheduler: Final stage: ResultStage 14 (count at utils.scala:135)
21/03/20 10:58:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/03/20 10:58:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/03/20 10:58:12 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[51] at count at utils.scala:135), which has no missing parents
21/03/20 10:58:12 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 25.0 KiB, free 413.9 MiB)
21/03/20 10:58:12 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 10.2 KiB, free 413.9 MiB)
21/03/20 10:58:12 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:49570 (size: 10.2 KiB, free: 413.9 MiB)
21/03/20 10:58:12 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1223
21/03/20 10:58:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[51] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 10:58:12 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/20 10:58:12 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 11, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 10:58:12 INFO Executor: Running task 0.0 in stage 13.0 (TID 11)
21/03/20 10:58:12 INFO BlockManager: Found block rdd_41_0 locally
21/03/20 10:58:12 INFO Executor: 1 block locks were not released by TID = 11:
[rdd_41_0]
21/03/20 10:58:12 INFO Executor: Finished task 0.0 in stage 13.0 (TID 11). 2127 bytes result sent to driver
21/03/20 10:58:12 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 11) in 40 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 10:58:12 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/20 10:58:12 INFO DAGScheduler: ShuffleMapStage 13 (count at utils.scala:135) finished in 0,064 s
21/03/20 10:58:12 INFO DAGScheduler: looking for newly runnable stages
21/03/20 10:58:12 INFO DAGScheduler: running: Set()
21/03/20 10:58:12 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/03/20 10:58:12 INFO DAGScheduler: failed: Set()
21/03/20 10:58:12 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[54] at count at utils.scala:135), which has no missing parents
21/03/20 10:58:12 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 11.5 KiB, free 413.9 MiB)
21/03/20 10:58:12 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.9 MiB)
21/03/20 10:58:12 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:49570 (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 10:58:12 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1223
21/03/20 10:58:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[54] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 10:58:12 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/20 10:58:12 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 12, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 10:58:12 INFO Executor: Running task 0.0 in stage 14.0 (TID 12)
21/03/20 10:58:12 INFO ShuffleBlockFetcherIterator: Getting 1 (54.0 B) non-empty blocks including 1 (54.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 10:58:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 10:58:12 INFO Executor: Finished task 0.0 in stage 14.0 (TID 12). 2428 bytes result sent to driver
21/03/20 10:58:12 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 12) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 10:58:12 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/20 10:58:12 INFO DAGScheduler: ResultStage 14 (count at utils.scala:135) finished in 0,036 s
21/03/20 10:58:12 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 10:58:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
21/03/20 10:58:12 INFO DAGScheduler: Job 9 finished: count at utils.scala:135, took 0,119747 s
21/03/20 11:01:56 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:49570 in memory (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 11:01:56 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:49570 in memory (size: 10.2 KiB, free: 413.9 MiB)
21/03/20 11:05:09 INFO CodeGenerator: Code generated in 16.2076 ms
21/03/20 11:05:09 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 11:05:09 INFO DAGScheduler: Registering RDD 56 (collect at utils.scala:137) as input to shuffle 6
21/03/20 11:05:09 INFO DAGScheduler: Got job 10 (collect at utils.scala:137) with 1 output partitions
21/03/20 11:05:09 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:137)
21/03/20 11:05:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
21/03/20 11:05:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
21/03/20 11:05:09 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[56] at collect at utils.scala:137), which has no missing parents
21/03/20 11:05:09 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 11:05:09 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 11:05:09 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:49570 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 11:05:09 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1223
21/03/20 11:05:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[56] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 11:05:09 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/03/20 11:05:09 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 13, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 11:05:09 INFO Executor: Running task 0.0 in stage 15.0 (TID 13)
21/03/20 11:05:09 INFO Executor: Finished task 0.0 in stage 15.0 (TID 13). 1876 bytes result sent to driver
21/03/20 11:05:09 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 13) in 64 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:05:09 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/03/20 11:05:09 INFO DAGScheduler: ShuffleMapStage 15 (collect at utils.scala:137) finished in 0,076 s
21/03/20 11:05:09 INFO DAGScheduler: looking for newly runnable stages
21/03/20 11:05:09 INFO DAGScheduler: running: Set()
21/03/20 11:05:09 INFO DAGScheduler: waiting: Set(ResultStage 16)
21/03/20 11:05:09 INFO DAGScheduler: failed: Set()
21/03/20 11:05:09 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:137), which has no missing parents
21/03/20 11:05:09 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 11:05:09 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 11:05:09 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:49570 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 11:05:09 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1223
21/03/20 11:05:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 11:05:09 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/03/20 11:05:09 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 14, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 11:05:09 INFO Executor: Running task 0.0 in stage 16.0 (TID 14)
21/03/20 11:05:09 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 11:05:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 11:05:09 INFO Executor: Finished task 0.0 in stage 16.0 (TID 14). 2605 bytes result sent to driver
21/03/20 11:05:09 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 14) in 20 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:05:09 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/03/20 11:05:09 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:137) finished in 0,036 s
21/03/20 11:05:09 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 11:05:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
21/03/20 11:05:09 INFO DAGScheduler: Job 10 finished: collect at utils.scala:137, took 0,127224 s
21/03/20 11:05:09 INFO CodeGenerator: Code generated in 12.8224 ms
21/03/20 11:05:09 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:49570 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 11:05:09 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:49570 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 11:05:10 INFO CodeGenerator: Code generated in 29.3132 ms
21/03/20 11:05:10 INFO CodeGenerator: Code generated in 17.077 ms
21/03/20 11:05:10 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 11:05:10 INFO DAGScheduler: Registering RDD 61 (count at utils.scala:135) as input to shuffle 7
21/03/20 11:05:10 INFO DAGScheduler: Got job 11 (count at utils.scala:135) with 1 output partitions
21/03/20 11:05:10 INFO DAGScheduler: Final stage: ResultStage 18 (count at utils.scala:135)
21/03/20 11:05:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
21/03/20 11:05:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
21/03/20 11:05:10 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[61] at count at utils.scala:135), which has no missing parents
21/03/20 11:05:10 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 9.1 KiB, free 413.9 MiB)
21/03/20 11:05:10 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 413.9 MiB)
21/03/20 11:05:10 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:49570 (size: 4.8 KiB, free: 413.9 MiB)
21/03/20 11:05:10 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1223
21/03/20 11:05:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[61] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 11:05:10 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/03/20 11:05:10 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 15, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 11:05:10 INFO Executor: Running task 0.0 in stage 17.0 (TID 15)
21/03/20 11:05:10 INFO Executor: Finished task 0.0 in stage 17.0 (TID 15). 1833 bytes result sent to driver
21/03/20 11:05:10 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 15) in 201 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:05:10 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/03/20 11:05:10 INFO DAGScheduler: ShuffleMapStage 17 (count at utils.scala:135) finished in 0,221 s
21/03/20 11:05:10 INFO DAGScheduler: looking for newly runnable stages
21/03/20 11:05:10 INFO DAGScheduler: running: Set()
21/03/20 11:05:10 INFO DAGScheduler: waiting: Set(ResultStage 18)
21/03/20 11:05:10 INFO DAGScheduler: failed: Set()
21/03/20 11:05:10 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[64] at count at utils.scala:135), which has no missing parents
21/03/20 11:05:10 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 12.1 KiB, free 413.9 MiB)
21/03/20 11:05:10 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.9 MiB)
21/03/20 11:05:10 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:49570 (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 11:05:10 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1223
21/03/20 11:05:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[64] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 11:05:10 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/03/20 11:05:10 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 16, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 11:05:10 INFO Executor: Running task 0.0 in stage 18.0 (TID 16)
21/03/20 11:05:10 INFO ShuffleBlockFetcherIterator: Getting 1 (49.0 B) non-empty blocks including 1 (49.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 11:05:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 11:05:10 INFO Executor: Finished task 0.0 in stage 18.0 (TID 16). 2853 bytes result sent to driver
21/03/20 11:05:10 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 16) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:05:10 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/03/20 11:05:10 INFO DAGScheduler: ResultStage 18 (count at utils.scala:135) finished in 0,056 s
21/03/20 11:05:10 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 11:05:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
21/03/20 11:05:10 INFO DAGScheduler: Job 11 finished: count at utils.scala:135, took 0,293189 s
21/03/20 11:05:44 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:49570 in memory (size: 4.8 KiB, free: 413.9 MiB)
21/03/20 11:05:44 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:49570 in memory (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 11:05:44 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 11:05:44 INFO DAGScheduler: Registering RDD 66 (collect at utils.scala:137) as input to shuffle 8
21/03/20 11:05:44 INFO DAGScheduler: Got job 12 (collect at utils.scala:137) with 1 output partitions
21/03/20 11:05:44 INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:137)
21/03/20 11:05:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
21/03/20 11:05:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
21/03/20 11:05:44 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[66] at collect at utils.scala:137), which has no missing parents
21/03/20 11:05:44 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 11:05:44 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 11:05:44 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:49570 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 11:05:44 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1223
21/03/20 11:05:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[66] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 11:05:44 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/03/20 11:05:44 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 17, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 11:05:44 INFO Executor: Running task 0.0 in stage 19.0 (TID 17)
21/03/20 11:05:44 INFO Executor: Finished task 0.0 in stage 19.0 (TID 17). 1790 bytes result sent to driver
21/03/20 11:05:44 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 17) in 32 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:05:44 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/03/20 11:05:44 INFO DAGScheduler: ShuffleMapStage 19 (collect at utils.scala:137) finished in 0,048 s
21/03/20 11:05:44 INFO DAGScheduler: looking for newly runnable stages
21/03/20 11:05:44 INFO DAGScheduler: running: Set()
21/03/20 11:05:44 INFO DAGScheduler: waiting: Set(ResultStage 20)
21/03/20 11:05:44 INFO DAGScheduler: failed: Set()
21/03/20 11:05:44 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[69] at collect at utils.scala:137), which has no missing parents
21/03/20 11:05:44 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 11:05:44 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 11:05:44 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:49570 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 11:05:44 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1223
21/03/20 11:05:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[69] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 11:05:44 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/03/20 11:05:44 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 18, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 11:05:44 INFO Executor: Running task 0.0 in stage 20.0 (TID 18)
21/03/20 11:05:44 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 11:05:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/03/20 11:05:44 INFO Executor: Finished task 0.0 in stage 20.0 (TID 18). 2566 bytes result sent to driver
21/03/20 11:05:44 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 18) in 20 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:05:44 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/03/20 11:05:44 INFO DAGScheduler: ResultStage 20 (collect at utils.scala:137) finished in 0,044 s
21/03/20 11:05:44 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 11:05:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
21/03/20 11:05:44 INFO DAGScheduler: Job 12 finished: collect at utils.scala:137, took 0,106932 s
21/03/20 11:05:44 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:49570 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 11:05:44 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:49570 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 11:05:44 INFO CodeGenerator: Code generated in 21.3225 ms
21/03/20 11:05:44 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 11:05:44 INFO DAGScheduler: Registering RDD 71 (count at utils.scala:135) as input to shuffle 9
21/03/20 11:05:44 INFO DAGScheduler: Got job 13 (count at utils.scala:135) with 1 output partitions
21/03/20 11:05:44 INFO DAGScheduler: Final stage: ResultStage 22 (count at utils.scala:135)
21/03/20 11:05:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
21/03/20 11:05:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
21/03/20 11:05:44 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[71] at count at utils.scala:135), which has no missing parents
21/03/20 11:05:44 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 9.1 KiB, free 413.9 MiB)
21/03/20 11:05:44 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 413.9 MiB)
21/03/20 11:05:44 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:49570 (size: 4.8 KiB, free: 413.9 MiB)
21/03/20 11:05:44 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1223
21/03/20 11:05:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[71] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 11:05:44 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/03/20 11:05:44 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 19, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 11:05:44 INFO Executor: Running task 0.0 in stage 21.0 (TID 19)
21/03/20 11:05:44 INFO Executor: Finished task 0.0 in stage 21.0 (TID 19). 1833 bytes result sent to driver
21/03/20 11:05:44 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 19) in 36 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:05:44 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/03/20 11:05:44 INFO DAGScheduler: ShuffleMapStage 21 (count at utils.scala:135) finished in 0,072 s
21/03/20 11:05:44 INFO DAGScheduler: looking for newly runnable stages
21/03/20 11:05:44 INFO DAGScheduler: running: Set()
21/03/20 11:05:44 INFO DAGScheduler: waiting: Set(ResultStage 22)
21/03/20 11:05:44 INFO DAGScheduler: failed: Set()
21/03/20 11:05:44 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[74] at count at utils.scala:135), which has no missing parents
21/03/20 11:05:44 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 12.4 KiB, free 413.9 MiB)
21/03/20 11:05:44 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 413.9 MiB)
21/03/20 11:05:44 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:49570 (size: 5.4 KiB, free: 413.9 MiB)
21/03/20 11:05:44 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1223
21/03/20 11:05:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[74] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 11:05:44 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/03/20 11:05:44 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 20, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 11:05:44 INFO Executor: Running task 0.0 in stage 22.0 (TID 20)
21/03/20 11:05:44 INFO ShuffleBlockFetcherIterator: Getting 1 (49.0 B) non-empty blocks including 1 (49.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 11:05:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 11:05:44 INFO Executor: Finished task 0.0 in stage 22.0 (TID 20). 2853 bytes result sent to driver
21/03/20 11:05:44 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 20) in 20 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:05:44 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/03/20 11:05:44 INFO DAGScheduler: ResultStage 22 (count at utils.scala:135) finished in 0,036 s
21/03/20 11:05:44 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 11:05:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
21/03/20 11:05:44 INFO DAGScheduler: Job 13 finished: count at utils.scala:135, took 0,120376 s
21/03/20 11:14:06 INFO SparkContext: Invoking stop() from shutdown hook
21/03/20 11:14:06 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
21/03/20 11:14:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/20 11:14:07 INFO MemoryStore: MemoryStore cleared
21/03/20 11:14:07 INFO BlockManager: BlockManager stopped
21/03/20 11:14:07 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/20 11:14:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/20 11:14:07 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-3ebfcad6-5997-4eab-ba99-6d7bab283df3\userFiles-b1c4ad52-72ac-47d1-99b8-e0e251fb8458
java.io.IOException: Failed to delete: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-3ebfcad6-5997-4eab-ba99-6d7bab283df3\userFiles-b1c4ad52-72ac-47d1-99b8-e0e251fb8458\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:105)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2012)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2012)
	at org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:631)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 11:14:07 INFO SparkContext: Successfully stopped SparkContext
21/03/20 11:14:07 INFO ShutdownHookManager: Shutdown hook called
21/03/20 11:14:07 INFO ShutdownHookManager: Deleting directory C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-3ebfcad6-5997-4eab-ba99-6d7bab283df3
21/03/20 11:14:07 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-3ebfcad6-5997-4eab-ba99-6d7bab283df3
java.io.IOException: Failed to delete: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-3ebfcad6-5997-4eab-ba99-6d7bab283df3\userFiles-b1c4ad52-72ac-47d1-99b8-e0e251fb8458\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 11:14:07 INFO ShutdownHookManager: Deleting directory C:\Users\wilto\AppData\Local\Temp\spark-e583ebfe-4ed6-4119-868b-bcbcc34339ba
21/03/20 11:14:07 INFO ShutdownHookManager: Deleting directory C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-3ebfcad6-5997-4eab-ba99-6d7bab283df3\userFiles-b1c4ad52-72ac-47d1-99b8-e0e251fb8458
21/03/20 11:14:07 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-3ebfcad6-5997-4eab-ba99-6d7bab283df3\userFiles-b1c4ad52-72ac-47d1-99b8-e0e251fb8458
java.io.IOException: Failed to delete: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-3ebfcad6-5997-4eab-ba99-6d7bab283df3\userFiles-b1c4ad52-72ac-47d1-99b8-e0e251fb8458\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 11:18:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/20 11:18:23 INFO SecurityManager: Changing view acls to: wilto
21/03/20 11:18:23 INFO SecurityManager: Changing modify acls to: wilto
21/03/20 11:18:23 INFO SecurityManager: Changing view acls groups to: 
21/03/20 11:18:23 INFO SecurityManager: Changing modify acls groups to: 
21/03/20 11:18:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wilto); groups with view permissions: Set(); users  with modify permissions: Set(wilto); groups with modify permissions: Set()
21/03/20 11:18:27 INFO HiveConf: Found configuration file file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/03/20 11:18:28 INFO SparkContext: Running Spark version 3.0.1
21/03/20 11:18:28 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/03/20 11:18:28 INFO ResourceUtils: ==============================================================
21/03/20 11:18:28 INFO ResourceUtils: Resources for spark.driver:

21/03/20 11:18:28 INFO ResourceUtils: ==============================================================
21/03/20 11:18:28 INFO SparkContext: Submitted application: sparklyr
21/03/20 11:18:29 INFO SecurityManager: Changing view acls to: wilto
21/03/20 11:18:29 INFO SecurityManager: Changing modify acls to: wilto
21/03/20 11:18:29 INFO SecurityManager: Changing view acls groups to: 
21/03/20 11:18:29 INFO SecurityManager: Changing modify acls groups to: 
21/03/20 11:18:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wilto); groups with view permissions: Set(); users  with modify permissions: Set(wilto); groups with modify permissions: Set()
21/03/20 11:18:29 INFO Utils: Successfully started service 'sparkDriver' on port 50577.
21/03/20 11:18:29 INFO SparkEnv: Registering MapOutputTracker
21/03/20 11:18:29 INFO SparkEnv: Registering BlockManagerMaster
21/03/20 11:18:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/20 11:18:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/20 11:18:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/03/20 11:18:29 INFO DiskBlockManager: Created local directory at C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\blockmgr-d10e9234-22a1-4f49-85ff-46f2856094d3
21/03/20 11:18:29 INFO MemoryStore: MemoryStore started with capacity 413.9 MiB
21/03/20 11:18:30 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/20 11:18:30 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/local]. Please check your configured local directories.
21/03/20 11:18:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/20 11:18:31 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
21/03/20 11:18:31 INFO SparkContext: Added JAR file:/C:/Users/wilto/OneDrive/Documentos/R/win-library/4.0/sparklyr/java/sparklyr-3.0-2.12.jar at spark://127.0.0.1:50577/jars/sparklyr-3.0-2.12.jar with timestamp 1616249911186
21/03/20 11:18:31 INFO Executor: Starting executor ID driver on host 127.0.0.1
21/03/20 11:18:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50620.
21/03/20 11:18:31 INFO NettyBlockTransferService: Server created on 127.0.0.1:50620
21/03/20 11:18:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/20 11:18:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 50620, None)
21/03/20 11:18:31 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:50620 with 413.9 MiB RAM, BlockManagerId(driver, 127.0.0.1, 50620, None)
21/03/20 11:18:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 50620, None)
21/03/20 11:18:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 50620, None)
21/03/20 11:18:32 INFO SharedState: loading hive config file: file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/03/20 11:18:32 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive').
21/03/20 11:18:32 INFO SharedState: Warehouse path is 'C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive'.
21/03/20 11:18:32 WARN SharedState: Not allowing to set spark.sql.warehouse.dir or hive.metastore.warehouse.dir in SparkSession's options, it should be set statically for cross-session usages
21/03/20 11:18:42 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/03/20 11:18:42 INFO HiveConf: Found configuration file file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/03/20 11:18:45 INFO SessionState: Created HDFS directory: C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive/wilto/09ad2dfa-f83e-46e8-963e-cf1635c43be7
21/03/20 11:18:45 INFO SessionState: Created local directory: C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive/09ad2dfa-f83e-46e8-963e-cf1635c43be7
21/03/20 11:18:46 INFO SessionState: Created HDFS directory: C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive/wilto/09ad2dfa-f83e-46e8-963e-cf1635c43be7/_tmp_space.db
21/03/20 11:18:46 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive
21/03/20 11:18:49 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/03/20 11:18:49 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/03/20 11:18:49 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/20 11:18:49 INFO ObjectStore: ObjectStore, initialize called
21/03/20 11:18:49 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/20 11:18:49 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/20 11:18:52 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/20 11:18:56 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/20 11:18:56 INFO ObjectStore: Initialized ObjectStore
21/03/20 11:18:56 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/03/20 11:18:56 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.1.38
21/03/20 11:18:56 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/20 11:18:57 INFO HiveMetaStore: Added admin role in metastore
21/03/20 11:18:57 INFO HiveMetaStore: Added public role in metastore
21/03/20 11:18:57 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/20 11:18:57 INFO HiveMetaStore: 0: get_all_functions
21/03/20 11:18:57 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_all_functions	
21/03/20 11:18:57 INFO HiveMetaStore: 0: get_database: default
21/03/20 11:18:57 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 11:18:57 INFO HiveMetaStore: 0: get_database: global_temp
21/03/20 11:18:57 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/20 11:18:57 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/20 11:18:57 INFO HiveMetaStore: 0: get_database: default
21/03/20 11:18:57 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 11:18:57 INFO HiveMetaStore: 0: get_database: default
21/03/20 11:18:57 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 11:18:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 11:18:57 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 11:19:00 INFO CodeGenerator: Code generated in 447.9233 ms
21/03/20 11:19:00 INFO CodeGenerator: Code generated in 28.7201 ms
21/03/20 11:19:01 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 11:19:01 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/03/20 11:19:01 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/03/20 11:19:01 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/03/20 11:19:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/03/20 11:19:01 INFO DAGScheduler: Missing parents: List()
21/03/20 11:19:01 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/03/20 11:19:01 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
21/03/20 11:19:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 11:19:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 11:19:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:50620 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 11:19:01 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/03/20 11:19:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 11:19:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/20 11:19:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/03/20 11:19:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/03/20 11:19:02 INFO Executor: Fetching spark://127.0.0.1:50577/jars/sparklyr-3.0-2.12.jar with timestamp 1616249911186
21/03/20 11:19:02 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:50577 after 84 ms (0 ms spent in bootstraps)
21/03/20 11:19:02 INFO Utils: Fetching spark://127.0.0.1:50577/jars/sparklyr-3.0-2.12.jar to C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-a02b5887-ea72-46fb-8fbd-d46c45207c31\userFiles-534e6c56-1fc3-421b-893c-90360e94a55d\fetchFileTemp666246937927077217.tmp
21/03/20 11:19:03 INFO Executor: Adding file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/local/spark-a02b5887-ea72-46fb-8fbd-d46c45207c31/userFiles-534e6c56-1fc3-421b-893c-90360e94a55d/sparklyr-3.0-2.12.jar to class loader
21/03/20 11:19:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 11:19:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
21/03/20 11:19:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2727 bytes result sent to driver
21/03/20 11:19:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 1749 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:19:03 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/20 11:19:03 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 2,217 s
21/03/20 11:19:03 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 11:19:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/03/20 11:19:03 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 2,376531 s
21/03/20 11:19:04 INFO HiveMetaStore: 0: get_database: default
21/03/20 11:19:04 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 11:19:04 INFO HiveMetaStore: 0: get_database: default
21/03/20 11:19:04 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 11:19:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 11:19:04 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 11:19:04 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 11:19:04 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/03/20 11:19:04 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/03/20 11:19:04 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/20 11:19:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/20 11:19:04 INFO DAGScheduler: Missing parents: List()
21/03/20 11:19:04 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/03/20 11:19:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 11:19:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 11:19:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:50620 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 11:19:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/03/20 11:19:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 11:19:04 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/20 11:19:04 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/03/20 11:19:04 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/03/20 11:19:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 11:19:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 11:19:04 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2555 bytes result sent to driver
21/03/20 11:19:04 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 20 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:19:04 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/20 11:19:04 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0,056 s
21/03/20 11:19:04 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 11:19:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/03/20 11:19:04 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0,074582 s
21/03/20 11:19:09 INFO HiveMetaStore: 0: get_database: default
21/03/20 11:19:09 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 11:19:09 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/20 11:19:09 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/20 11:19:09 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:50620 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 11:19:09 INFO HiveMetaStore: 0: get_database: default
21/03/20 11:19:09 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 11:19:09 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/20 11:19:09 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/20 11:19:18 INFO HiveMetaStore: 0: get_database: default
21/03/20 11:19:18 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 11:19:18 INFO HiveMetaStore: 0: get_database: default
21/03/20 11:19:18 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 11:19:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 11:19:18 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 11:19:18 INFO SparkContext: Starting job: collect at utils.scala:54
21/03/20 11:19:18 INFO DAGScheduler: Job 2 finished: collect at utils.scala:54, took 0,000286 s
21/03/20 11:19:19 INFO CodeGenerator: Code generated in 33.5456 ms
21/03/20 11:19:19 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 11:19:19 INFO DAGScheduler: Got job 3 (collect at utils.scala:137) with 1 output partitions
21/03/20 11:19:19 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:137)
21/03/20 11:19:19 INFO DAGScheduler: Parents of final stage: List()
21/03/20 11:19:19 INFO DAGScheduler: Missing parents: List()
21/03/20 11:19:19 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:137), which has no missing parents
21/03/20 11:19:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.7 KiB, free 413.9 MiB)
21/03/20 11:19:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 413.9 MiB)
21/03/20 11:19:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:50620 (size: 3.3 KiB, free: 413.9 MiB)
21/03/20 11:19:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1223
21/03/20 11:19:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 11:19:19 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/20 11:19:19 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 2, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 11:19:19 INFO Executor: Running task 0.0 in stage 4.0 (TID 2)
21/03/20 11:19:19 INFO Executor: Finished task 0.0 in stage 4.0 (TID 2). 1354 bytes result sent to driver
21/03/20 11:19:19 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 2) in 32 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:19:19 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/20 11:19:19 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:137) finished in 0,060 s
21/03/20 11:19:19 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 11:19:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
21/03/20 11:19:19 INFO DAGScheduler: Job 3 finished: collect at utils.scala:137, took 0,074266 s
21/03/20 11:19:20 INFO CodeGenerator: Code generated in 21.7651 ms
21/03/20 11:19:20 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:50620 in memory (size: 3.3 KiB, free: 413.9 MiB)
21/03/20 11:19:20 INFO CodeGenerator: Code generated in 16.8724 ms
21/03/20 11:19:20 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 11:19:20 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135) as input to shuffle 2
21/03/20 11:19:20 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/20 11:19:20 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/20 11:19:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/20 11:19:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/20 11:19:20 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/03/20 11:19:20 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 11:19:20 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 11:19:20 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:50620 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 11:19:20 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1223
21/03/20 11:19:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 11:19:20 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/20 11:19:20 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 11:19:20 INFO Executor: Running task 0.0 in stage 5.0 (TID 3)
21/03/20 11:19:20 INFO Executor: Finished task 0.0 in stage 5.0 (TID 3). 1919 bytes result sent to driver
21/03/20 11:19:20 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 212 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:19:20 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/20 11:19:20 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0,251 s
21/03/20 11:19:20 INFO DAGScheduler: looking for newly runnable stages
21/03/20 11:19:20 INFO DAGScheduler: running: Set()
21/03/20 11:19:20 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/20 11:19:20 INFO DAGScheduler: failed: Set()
21/03/20 11:19:20 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/03/20 11:19:20 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 11:19:20 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 11:19:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:50620 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 11:19:20 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1223
21/03/20 11:19:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 11:19:20 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/20 11:19:20 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 11:19:20 INFO Executor: Running task 0.0 in stage 6.0 (TID 4)
21/03/20 11:19:20 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 11:19:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
21/03/20 11:19:20 INFO Executor: Finished task 0.0 in stage 6.0 (TID 4). 2648 bytes result sent to driver
21/03/20 11:19:20 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 74 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:19:20 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/20 11:19:20 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0,106 s
21/03/20 11:19:20 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 11:19:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
21/03/20 11:19:20 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0,426355 s
21/03/20 11:19:21 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:50620 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 11:19:21 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:50620 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 11:19:21 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 11:19:21 INFO DAGScheduler: Got job 5 (collect at utils.scala:137) with 1 output partitions
21/03/20 11:19:21 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:137)
21/03/20 11:19:21 INFO DAGScheduler: Parents of final stage: List()
21/03/20 11:19:21 INFO DAGScheduler: Missing parents: List()
21/03/20 11:19:21 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[28] at collect at utils.scala:137), which has no missing parents
21/03/20 11:19:21 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.5 KiB, free 413.9 MiB)
21/03/20 11:19:21 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 413.9 MiB)
21/03/20 11:19:21 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:50620 (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 11:19:21 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1223
21/03/20 11:19:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[28] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 11:19:21 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/20 11:19:21 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 11:19:21 INFO Executor: Running task 0.0 in stage 7.0 (TID 5)
21/03/20 11:19:21 INFO Executor: Finished task 0.0 in stage 7.0 (TID 5). 1354 bytes result sent to driver
21/03/20 11:19:22 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:19:22 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/20 11:19:22 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:137) finished in 0,048 s
21/03/20 11:19:22 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 11:19:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
21/03/20 11:19:22 INFO DAGScheduler: Job 5 finished: collect at utils.scala:137, took 0,075861 s
21/03/20 11:19:22 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:50620 in memory (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 11:19:22 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 11:19:22 INFO DAGScheduler: Registering RDD 30 (count at utils.scala:135) as input to shuffle 3
21/03/20 11:19:22 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/20 11:19:22 INFO DAGScheduler: Final stage: ResultStage 9 (count at utils.scala:135)
21/03/20 11:19:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/20 11:19:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/20 11:19:22 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[30] at count at utils.scala:135), which has no missing parents
21/03/20 11:19:22 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 11:19:22 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 11:19:22 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:50620 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 11:19:22 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1223
21/03/20 11:19:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[30] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 11:19:22 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/20 11:19:22 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 11:19:22 INFO Executor: Running task 0.0 in stage 8.0 (TID 6)
21/03/20 11:19:22 INFO Executor: Finished task 0.0 in stage 8.0 (TID 6). 1833 bytes result sent to driver
21/03/20 11:19:22 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 40 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:19:22 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/20 11:19:22 INFO DAGScheduler: ShuffleMapStage 8 (count at utils.scala:135) finished in 0,060 s
21/03/20 11:19:22 INFO DAGScheduler: looking for newly runnable stages
21/03/20 11:19:22 INFO DAGScheduler: running: Set()
21/03/20 11:19:22 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/20 11:19:22 INFO DAGScheduler: failed: Set()
21/03/20 11:19:22 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[33] at count at utils.scala:135), which has no missing parents
21/03/20 11:19:22 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 11:19:22 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 11:19:22 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:50620 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 11:19:22 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1223
21/03/20 11:19:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[33] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 11:19:22 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/20 11:19:22 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 11:19:22 INFO Executor: Running task 0.0 in stage 9.0 (TID 7)
21/03/20 11:19:22 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 11:19:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 11:19:22 INFO Executor: Finished task 0.0 in stage 9.0 (TID 7). 2605 bytes result sent to driver
21/03/20 11:19:22 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 20 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:19:22 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/20 11:19:22 INFO DAGScheduler: ResultStage 9 (count at utils.scala:135) finished in 0,040 s
21/03/20 11:19:22 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 11:19:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
21/03/20 11:19:22 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0,122423 s
21/03/20 11:19:22 INFO HiveMetaStore: 0: get_database: default
21/03/20 11:19:22 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 11:19:22 INFO HiveMetaStore: 0: get_database: default
21/03/20 11:19:22 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 11:19:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 11:19:22 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 11:19:22 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:50620 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 11:19:22 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:50620 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 11:19:23 INFO CodeGenerator: Code generated in 13.8931 ms
21/03/20 11:19:23 INFO CodeGenerator: Code generated in 30.1298 ms
21/03/20 11:19:23 INFO CodeGenerator: Code generated in 14.6213 ms
21/03/20 11:19:23 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 11:19:23 INFO DAGScheduler: Registering RDD 36 (count at utils.scala:135) as input to shuffle 4
21/03/20 11:19:23 INFO DAGScheduler: Got job 7 (count at utils.scala:135) with 1 output partitions
21/03/20 11:19:23 INFO DAGScheduler: Final stage: ResultStage 11 (count at utils.scala:135)
21/03/20 11:19:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
21/03/20 11:19:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
21/03/20 11:19:23 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[36] at count at utils.scala:135), which has no missing parents
21/03/20 11:19:23 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 11:19:23 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.9 MiB)
21/03/20 11:19:23 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:50620 (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 11:19:23 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1223
21/03/20 11:19:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[36] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 11:19:23 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/20 11:19:23 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7498 bytes)
21/03/20 11:19:23 INFO Executor: Running task 0.0 in stage 10.0 (TID 8)
21/03/20 11:19:23 INFO Executor: Finished task 0.0 in stage 10.0 (TID 8). 1790 bytes result sent to driver
21/03/20 11:19:23 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 52 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:19:23 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/20 11:19:23 INFO DAGScheduler: ShuffleMapStage 10 (count at utils.scala:135) finished in 0,072 s
21/03/20 11:19:23 INFO DAGScheduler: looking for newly runnable stages
21/03/20 11:19:23 INFO DAGScheduler: running: Set()
21/03/20 11:19:23 INFO DAGScheduler: waiting: Set(ResultStage 11)
21/03/20 11:19:23 INFO DAGScheduler: failed: Set()
21/03/20 11:19:23 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[39] at count at utils.scala:135), which has no missing parents
21/03/20 11:19:23 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 11:19:23 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 11:19:23 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:50620 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 11:19:23 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1223
21/03/20 11:19:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[39] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 11:19:23 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/20 11:19:23 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 9, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 11:19:23 INFO Executor: Running task 0.0 in stage 11.0 (TID 9)
21/03/20 11:19:23 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 11:19:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 11:19:23 INFO Executor: Finished task 0.0 in stage 11.0 (TID 9). 2648 bytes result sent to driver
21/03/20 11:19:23 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:50620 in memory (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 11:19:23 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 9) in 36 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:19:23 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/20 11:19:23 INFO DAGScheduler: ResultStage 11 (count at utils.scala:135) finished in 0,048 s
21/03/20 11:19:23 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 11:19:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
21/03/20 11:19:23 INFO DAGScheduler: Job 7 finished: count at utils.scala:135, took 0,134066 s
21/03/20 11:19:24 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:50620 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 11:19:24 INFO CodeGenerator: Code generated in 43.3436 ms
21/03/20 11:19:24 INFO CodeGenerator: Code generated in 27.0137 ms
21/03/20 11:19:24 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 11:19:24 INFO DAGScheduler: Got job 8 (collect at utils.scala:137) with 1 output partitions
21/03/20 11:19:24 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:137)
21/03/20 11:19:24 INFO DAGScheduler: Parents of final stage: List()
21/03/20 11:19:24 INFO DAGScheduler: Missing parents: List()
21/03/20 11:19:24 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[46] at collect at utils.scala:137), which has no missing parents
21/03/20 11:19:24 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 29.0 KiB, free 413.9 MiB)
21/03/20 11:19:24 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 11:19:24 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:50620 (size: 10.0 KiB, free: 413.9 MiB)
21/03/20 11:19:24 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1223
21/03/20 11:19:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[46] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 11:19:24 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/20 11:19:24 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 10, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 11:19:24 INFO Executor: Running task 0.0 in stage 12.0 (TID 10)
21/03/20 11:19:24 INFO MemoryStore: Block rdd_41_0 stored as values in memory (estimated size 3.9 KiB, free 413.9 MiB)
21/03/20 11:19:24 INFO BlockManagerInfo: Added rdd_41_0 in memory on 127.0.0.1:50620 (size: 3.9 KiB, free: 413.9 MiB)
21/03/20 11:19:24 INFO CodeGenerator: Code generated in 12.3926 ms
21/03/20 11:19:25 INFO Executor: 1 block locks were not released by TID = 10:
[rdd_41_0]
21/03/20 11:19:25 INFO Executor: Finished task 0.0 in stage 12.0 (TID 10). 2226 bytes result sent to driver
21/03/20 11:19:25 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 10) in 304 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:19:25 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/20 11:19:25 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:137) finished in 0,344 s
21/03/20 11:19:25 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 11:19:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
21/03/20 11:19:25 INFO DAGScheduler: Job 8 finished: collect at utils.scala:137, took 0,362782 s
21/03/20 11:19:25 INFO CodeGenerator: Code generated in 25.0224 ms
21/03/20 11:19:25 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:50620 in memory (size: 10.0 KiB, free: 413.9 MiB)
21/03/20 11:19:25 INFO CodeGenerator: Code generated in 27.2259 ms
21/03/20 11:19:25 INFO CodeGenerator: Code generated in 20.0316 ms
21/03/20 11:19:25 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 11:19:25 INFO DAGScheduler: Registering RDD 51 (count at utils.scala:135) as input to shuffle 5
21/03/20 11:19:25 INFO DAGScheduler: Got job 9 (count at utils.scala:135) with 1 output partitions
21/03/20 11:19:25 INFO DAGScheduler: Final stage: ResultStage 14 (count at utils.scala:135)
21/03/20 11:19:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/03/20 11:19:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/03/20 11:19:25 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[51] at count at utils.scala:135), which has no missing parents
21/03/20 11:19:25 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 25.0 KiB, free 413.9 MiB)
21/03/20 11:19:25 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 10.2 KiB, free 413.9 MiB)
21/03/20 11:19:25 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:50620 (size: 10.2 KiB, free: 413.9 MiB)
21/03/20 11:19:25 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1223
21/03/20 11:19:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[51] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 11:19:25 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/20 11:19:25 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 11, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 11:19:25 INFO Executor: Running task 0.0 in stage 13.0 (TID 11)
21/03/20 11:19:25 INFO BlockManager: Found block rdd_41_0 locally
21/03/20 11:19:25 INFO Executor: 1 block locks were not released by TID = 11:
[rdd_41_0]
21/03/20 11:19:25 INFO Executor: Finished task 0.0 in stage 13.0 (TID 11). 2127 bytes result sent to driver
21/03/20 11:19:25 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 11) in 32 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:19:25 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/20 11:19:25 INFO DAGScheduler: ShuffleMapStage 13 (count at utils.scala:135) finished in 0,052 s
21/03/20 11:19:25 INFO DAGScheduler: looking for newly runnable stages
21/03/20 11:19:25 INFO DAGScheduler: running: Set()
21/03/20 11:19:25 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/03/20 11:19:25 INFO DAGScheduler: failed: Set()
21/03/20 11:19:25 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[54] at count at utils.scala:135), which has no missing parents
21/03/20 11:19:25 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 11.5 KiB, free 413.9 MiB)
21/03/20 11:19:25 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.9 MiB)
21/03/20 11:19:25 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:50620 (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 11:19:25 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1223
21/03/20 11:19:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[54] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 11:19:25 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/20 11:19:25 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 12, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 11:19:25 INFO Executor: Running task 0.0 in stage 14.0 (TID 12)
21/03/20 11:19:25 INFO ShuffleBlockFetcherIterator: Getting 1 (54.0 B) non-empty blocks including 1 (54.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 11:19:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 11:19:25 INFO Executor: Finished task 0.0 in stage 14.0 (TID 12). 2428 bytes result sent to driver
21/03/20 11:19:25 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 12) in 20 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 11:19:25 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/20 11:19:25 INFO DAGScheduler: ResultStage 14 (count at utils.scala:135) finished in 0,052 s
21/03/20 11:19:25 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 11:19:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
21/03/20 11:19:25 INFO DAGScheduler: Job 9 finished: count at utils.scala:135, took 0,118175 s
21/03/20 14:19:56 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:913)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:200)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:294)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
21/03/20 14:23:12 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:913)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:200)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:294)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
21/03/20 14:23:22 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:913)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:200)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:294)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
21/03/20 14:23:32 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:913)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:200)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:294)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
21/03/20 14:23:34 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
21/03/20 14:23:34 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
21/03/20 14:23:34 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
21/03/20 14:23:34 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
21/03/20 14:29:21 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:50620 in memory (size: 10.2 KiB, free: 413.9 MiB)
21/03/20 14:29:21 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:50620 in memory (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 14:34:24 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:34:24 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:34:24 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:34:24 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:34:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 14:34:24 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 14:34:24 INFO CodeGenerator: Code generated in 12.8659 ms
21/03/20 14:34:24 INFO SparkContext: Starting job: collect at utils.scala:54
21/03/20 14:34:24 INFO DAGScheduler: Got job 10 (collect at utils.scala:54) with 1 output partitions
21/03/20 14:34:24 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:54)
21/03/20 14:34:24 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:34:24 INFO DAGScheduler: Missing parents: List()
21/03/20 14:34:24 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[60] at map at utils.scala:54), which has no missing parents
21/03/20 14:34:24 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.7 KiB, free 413.9 MiB)
21/03/20 14:34:24 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.9 MiB)
21/03/20 14:34:24 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:50620 (size: 4.6 KiB, free: 413.9 MiB)
21/03/20 14:34:24 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1223
21/03/20 14:34:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[60] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/20 14:34:24 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/03/20 14:34:24 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 13, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
21/03/20 14:34:24 INFO Executor: Running task 0.0 in stage 15.0 (TID 13)
21/03/20 14:34:24 INFO CodeGenerator: Code generated in 13.2754 ms
21/03/20 14:34:24 INFO Executor: Finished task 0.0 in stage 15.0 (TID 13). 1155 bytes result sent to driver
21/03/20 14:34:24 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 13) in 200 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:34:24 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/03/20 14:34:24 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:54) finished in 0,220 s
21/03/20 14:34:24 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:34:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
21/03/20 14:34:24 INFO DAGScheduler: Job 10 finished: collect at utils.scala:54, took 0,228583 s
21/03/20 14:34:41 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:34:41 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:34:41 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:34:41 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:34:41 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 14:34:41 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 14:34:41 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:50620 in memory (size: 4.6 KiB, free: 413.9 MiB)
21/03/20 14:34:41 INFO SparkContext: Starting job: collect at utils.scala:54
21/03/20 14:34:41 INFO DAGScheduler: Got job 11 (collect at utils.scala:54) with 1 output partitions
21/03/20 14:34:41 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:54)
21/03/20 14:34:41 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:34:41 INFO DAGScheduler: Missing parents: List()
21/03/20 14:34:41 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[67] at map at utils.scala:54), which has no missing parents
21/03/20 14:34:41 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 8.7 KiB, free 413.9 MiB)
21/03/20 14:34:41 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.9 MiB)
21/03/20 14:34:41 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:50620 (size: 4.6 KiB, free: 413.9 MiB)
21/03/20 14:34:41 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1223
21/03/20 14:34:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[67] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/20 14:34:41 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/03/20 14:34:41 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 14, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
21/03/20 14:34:41 INFO Executor: Running task 0.0 in stage 16.0 (TID 14)
21/03/20 14:34:41 INFO Executor: Finished task 0.0 in stage 16.0 (TID 14). 1069 bytes result sent to driver
21/03/20 14:34:41 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 14) in 12 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:34:41 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/03/20 14:34:41 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:54) finished in 0,028 s
21/03/20 14:34:41 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:34:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
21/03/20 14:34:41 INFO DAGScheduler: Job 11 finished: collect at utils.scala:54, took 0,037981 s
21/03/20 14:34:47 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:50620 in memory (size: 4.6 KiB, free: 413.9 MiB)
21/03/20 14:34:47 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:34:47 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:34:47 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:34:47 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:34:47 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 14:34:47 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 14:34:47 INFO SparkContext: Starting job: collect at utils.scala:54
21/03/20 14:34:47 INFO DAGScheduler: Got job 12 (collect at utils.scala:54) with 1 output partitions
21/03/20 14:34:47 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:54)
21/03/20 14:34:47 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:34:47 INFO DAGScheduler: Missing parents: List()
21/03/20 14:34:47 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[74] at map at utils.scala:54), which has no missing parents
21/03/20 14:34:47 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 8.7 KiB, free 413.9 MiB)
21/03/20 14:34:47 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.9 MiB)
21/03/20 14:34:47 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:50620 (size: 4.6 KiB, free: 413.9 MiB)
21/03/20 14:34:47 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1223
21/03/20 14:34:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[74] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/20 14:34:47 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/03/20 14:34:47 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 15, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
21/03/20 14:34:47 INFO Executor: Running task 0.0 in stage 17.0 (TID 15)
21/03/20 14:34:47 INFO Executor: Finished task 0.0 in stage 17.0 (TID 15). 1026 bytes result sent to driver
21/03/20 14:34:47 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 15) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:34:47 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/03/20 14:34:47 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:54) finished in 0,036 s
21/03/20 14:34:47 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:34:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
21/03/20 14:34:47 INFO DAGScheduler: Job 12 finished: collect at utils.scala:54, took 0,043289 s
21/03/20 14:37:40 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:37:40 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:37:40 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:37:40 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:37:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 14:37:40 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 14:37:40 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:50620 in memory (size: 4.6 KiB, free: 413.9 MiB)
21/03/20 14:37:40 INFO SparkContext: Starting job: collect at utils.scala:54
21/03/20 14:37:40 INFO DAGScheduler: Got job 13 (collect at utils.scala:54) with 1 output partitions
21/03/20 14:37:40 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:54)
21/03/20 14:37:40 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:37:40 INFO DAGScheduler: Missing parents: List()
21/03/20 14:37:40 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[81] at map at utils.scala:54), which has no missing parents
21/03/20 14:37:40 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 8.7 KiB, free 413.9 MiB)
21/03/20 14:37:40 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.9 MiB)
21/03/20 14:37:40 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:50620 (size: 4.6 KiB, free: 413.9 MiB)
21/03/20 14:37:40 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1223
21/03/20 14:37:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[81] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/20 14:37:40 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/03/20 14:37:40 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 16, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
21/03/20 14:37:40 INFO Executor: Running task 0.0 in stage 18.0 (TID 16)
21/03/20 14:37:40 INFO Executor: Finished task 0.0 in stage 18.0 (TID 16). 1069 bytes result sent to driver
21/03/20 14:37:40 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 16) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:37:40 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/03/20 14:37:40 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:54) finished in 0,028 s
21/03/20 14:37:40 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:37:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
21/03/20 14:37:40 INFO DAGScheduler: Job 13 finished: collect at utils.scala:54, took 0,034686 s
21/03/20 14:37:41 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:50620 in memory (size: 4.6 KiB, free: 413.9 MiB)
21/03/20 14:37:41 INFO InMemoryFileIndex: It took 52 ms to list leaf files for 1 paths.
21/03/20 14:37:41 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
21/03/20 14:37:42 INFO FileSourceStrategy: Pruning directories with: 
21/03/20 14:37:42 INFO FileSourceStrategy: Pushed Filters: 
21/03/20 14:37:42 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#882, None)) > 0)
21/03/20 14:37:42 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/20 14:37:42 INFO CodeGenerator: Code generated in 11.6389 ms
21/03/20 14:37:42 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 280.4 KiB, free 413.6 MiB)
21/03/20 14:37:42 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 413.6 MiB)
21/03/20 14:37:42 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:50620 (size: 28.0 KiB, free: 413.9 MiB)
21/03/20 14:37:42 INFO SparkContext: Created broadcast 17 from csv at <unknown>:0
21/03/20 14:37:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
21/03/20 14:37:42 INFO SparkContext: Starting job: csv at <unknown>:0
21/03/20 14:37:42 INFO DAGScheduler: Got job 14 (csv at <unknown>:0) with 1 output partitions
21/03/20 14:37:42 INFO DAGScheduler: Final stage: ResultStage 19 (csv at <unknown>:0)
21/03/20 14:37:42 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:37:42 INFO DAGScheduler: Missing parents: List()
21/03/20 14:37:42 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[85] at csv at <unknown>:0), which has no missing parents
21/03/20 14:37:42 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 10.7 KiB, free 413.6 MiB)
21/03/20 14:37:42 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.6 MiB)
21/03/20 14:37:42 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:50620 (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 14:37:42 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1223
21/03/20 14:37:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[85] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/03/20 14:37:42 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/03/20 14:37:42 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 17, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:37:42 INFO Executor: Running task 0.0 in stage 19.0 (TID 17)
21/03/20 14:37:42 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 0-134217728, partition values: [empty row]
21/03/20 14:37:42 INFO CodeGenerator: Code generated in 13.7832 ms
21/03/20 14:37:43 INFO Executor: Finished task 0.0 in stage 19.0 (TID 17). 1732 bytes result sent to driver
21/03/20 14:37:43 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 17) in 425 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:37:43 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/03/20 14:37:43 INFO DAGScheduler: ResultStage 19 (csv at <unknown>:0) finished in 0,465 s
21/03/20 14:37:43 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:37:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
21/03/20 14:37:43 INFO DAGScheduler: Job 14 finished: csv at <unknown>:0, took 0,481243 s
21/03/20 14:37:43 INFO CodeGenerator: Code generated in 13.1715 ms
21/03/20 14:37:43 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:50620 in memory (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 14:37:43 INFO FileSourceStrategy: Pruning directories with: 
21/03/20 14:37:43 INFO FileSourceStrategy: Pushed Filters: 
21/03/20 14:37:43 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/20 14:37:43 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/20 14:37:43 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 280.4 KiB, free 413.3 MiB)
21/03/20 14:37:43 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 413.3 MiB)
21/03/20 14:37:43 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:50620 (size: 28.0 KiB, free: 413.9 MiB)
21/03/20 14:37:43 INFO SparkContext: Created broadcast 19 from csv at <unknown>:0
21/03/20 14:37:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
21/03/20 14:37:43 INFO SparkContext: Starting job: csv at <unknown>:0
21/03/20 14:37:43 INFO DAGScheduler: Got job 15 (csv at <unknown>:0) with 24 output partitions
21/03/20 14:37:43 INFO DAGScheduler: Final stage: ResultStage 20 (csv at <unknown>:0)
21/03/20 14:37:43 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:37:43 INFO DAGScheduler: Missing parents: List()
21/03/20 14:37:43 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[91] at csv at <unknown>:0), which has no missing parents
21/03/20 14:37:43 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 16.0 KiB, free 413.3 MiB)
21/03/20 14:37:43 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 413.3 MiB)
21/03/20 14:37:43 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:50620 (size: 8.1 KiB, free: 413.9 MiB)
21/03/20 14:37:43 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1223
21/03/20 14:37:43 INFO DAGScheduler: Submitting 24 missing tasks from ResultStage 20 (MapPartitionsRDD[91] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
21/03/20 14:37:43 INFO TaskSchedulerImpl: Adding task set 20.0 with 24 tasks
21/03/20 14:37:43 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 18, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:37:43 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 19, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:37:43 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 20, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:37:43 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 21, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:37:43 INFO TaskSetManager: Starting task 4.0 in stage 20.0 (TID 22, 127.0.0.1, executor driver, partition 4, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:37:43 INFO TaskSetManager: Starting task 5.0 in stage 20.0 (TID 23, 127.0.0.1, executor driver, partition 5, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:37:43 INFO TaskSetManager: Starting task 6.0 in stage 20.0 (TID 24, 127.0.0.1, executor driver, partition 6, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:37:43 INFO TaskSetManager: Starting task 7.0 in stage 20.0 (TID 25, 127.0.0.1, executor driver, partition 7, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:37:43 INFO Executor: Running task 0.0 in stage 20.0 (TID 18)
21/03/20 14:37:43 INFO Executor: Running task 1.0 in stage 20.0 (TID 19)
21/03/20 14:37:43 INFO Executor: Running task 2.0 in stage 20.0 (TID 20)
21/03/20 14:37:43 INFO Executor: Running task 3.0 in stage 20.0 (TID 21)
21/03/20 14:37:43 INFO Executor: Running task 4.0 in stage 20.0 (TID 22)
21/03/20 14:37:43 INFO Executor: Running task 5.0 in stage 20.0 (TID 23)
21/03/20 14:37:43 INFO Executor: Running task 6.0 in stage 20.0 (TID 24)
21/03/20 14:37:43 INFO Executor: Running task 7.0 in stage 20.0 (TID 25)
21/03/20 14:37:43 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 536870912-671088640, partition values: [empty row]
21/03/20 14:37:43 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 402653184-536870912, partition values: [empty row]
21/03/20 14:37:43 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 268435456-402653184, partition values: [empty row]
21/03/20 14:37:43 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 134217728-268435456, partition values: [empty row]
21/03/20 14:37:43 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 0-134217728, partition values: [empty row]
21/03/20 14:37:43 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 671088640-805306368, partition values: [empty row]
21/03/20 14:37:43 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 805306368-939524096, partition values: [empty row]
21/03/20 14:37:43 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 939524096-1073741824, partition values: [empty row]
21/03/20 14:37:44 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:50620 in memory (size: 28.0 KiB, free: 413.9 MiB)
21/03/20 14:37:44 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:50620 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:38:05 INFO Executor: Finished task 1.0 in stage 20.0 (TID 19). 1906 bytes result sent to driver
21/03/20 14:38:05 INFO TaskSetManager: Starting task 8.0 in stage 20.0 (TID 26, 127.0.0.1, executor driver, partition 8, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:05 INFO Executor: Running task 8.0 in stage 20.0 (TID 26)
21/03/20 14:38:05 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 19) in 22229 ms on 127.0.0.1 (executor driver) (1/24)
21/03/20 14:38:05 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 1073741824-1207959552, partition values: [empty row]
21/03/20 14:38:06 INFO Executor: Finished task 4.0 in stage 20.0 (TID 22). 1863 bytes result sent to driver
21/03/20 14:38:06 INFO TaskSetManager: Starting task 9.0 in stage 20.0 (TID 27, 127.0.0.1, executor driver, partition 9, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:06 INFO TaskSetManager: Finished task 4.0 in stage 20.0 (TID 22) in 22506 ms on 127.0.0.1 (executor driver) (2/24)
21/03/20 14:38:06 INFO Executor: Running task 9.0 in stage 20.0 (TID 27)
21/03/20 14:38:06 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 1207959552-1342177280, partition values: [empty row]
21/03/20 14:38:06 INFO Executor: Finished task 7.0 in stage 20.0 (TID 25). 1863 bytes result sent to driver
21/03/20 14:38:06 INFO TaskSetManager: Starting task 10.0 in stage 20.0 (TID 28, 127.0.0.1, executor driver, partition 10, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:06 INFO TaskSetManager: Finished task 7.0 in stage 20.0 (TID 25) in 22841 ms on 127.0.0.1 (executor driver) (3/24)
21/03/20 14:38:06 INFO Executor: Running task 10.0 in stage 20.0 (TID 28)
21/03/20 14:38:06 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 1342177280-1476395008, partition values: [empty row]
21/03/20 14:38:07 INFO Executor: Finished task 0.0 in stage 20.0 (TID 18). 1863 bytes result sent to driver
21/03/20 14:38:07 INFO TaskSetManager: Starting task 11.0 in stage 20.0 (TID 29, 127.0.0.1, executor driver, partition 11, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:07 INFO Executor: Running task 11.0 in stage 20.0 (TID 29)
21/03/20 14:38:07 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 18) in 23409 ms on 127.0.0.1 (executor driver) (4/24)
21/03/20 14:38:07 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 1476395008-1610612736, partition values: [empty row]
21/03/20 14:38:07 INFO Executor: Finished task 5.0 in stage 20.0 (TID 23). 1863 bytes result sent to driver
21/03/20 14:38:07 INFO TaskSetManager: Starting task 12.0 in stage 20.0 (TID 30, 127.0.0.1, executor driver, partition 12, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:07 INFO Executor: Running task 12.0 in stage 20.0 (TID 30)
21/03/20 14:38:07 INFO TaskSetManager: Finished task 5.0 in stage 20.0 (TID 23) in 23520 ms on 127.0.0.1 (executor driver) (5/24)
21/03/20 14:38:07 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 1610612736-1744830464, partition values: [empty row]
21/03/20 14:38:07 INFO Executor: Finished task 3.0 in stage 20.0 (TID 21). 1863 bytes result sent to driver
21/03/20 14:38:07 INFO TaskSetManager: Starting task 13.0 in stage 20.0 (TID 31, 127.0.0.1, executor driver, partition 13, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:07 INFO Executor: Running task 13.0 in stage 20.0 (TID 31)
21/03/20 14:38:07 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 1744830464-1879048192, partition values: [empty row]
21/03/20 14:38:07 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 21) in 23739 ms on 127.0.0.1 (executor driver) (6/24)
21/03/20 14:38:07 INFO Executor: Finished task 2.0 in stage 20.0 (TID 20). 1863 bytes result sent to driver
21/03/20 14:38:07 INFO TaskSetManager: Starting task 14.0 in stage 20.0 (TID 32, 127.0.0.1, executor driver, partition 14, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:07 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 20) in 24119 ms on 127.0.0.1 (executor driver) (7/24)
21/03/20 14:38:07 INFO Executor: Running task 14.0 in stage 20.0 (TID 32)
21/03/20 14:38:07 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 1879048192-2013265920, partition values: [empty row]
21/03/20 14:38:07 INFO Executor: Finished task 6.0 in stage 20.0 (TID 24). 1863 bytes result sent to driver
21/03/20 14:38:07 INFO TaskSetManager: Starting task 15.0 in stage 20.0 (TID 33, 127.0.0.1, executor driver, partition 15, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:07 INFO Executor: Running task 15.0 in stage 20.0 (TID 33)
21/03/20 14:38:07 INFO TaskSetManager: Finished task 6.0 in stage 20.0 (TID 24) in 24303 ms on 127.0.0.1 (executor driver) (8/24)
21/03/20 14:38:07 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 2013265920-2147483648, partition values: [empty row]
21/03/20 14:38:30 INFO Executor: Finished task 10.0 in stage 20.0 (TID 28). 1863 bytes result sent to driver
21/03/20 14:38:30 INFO TaskSetManager: Starting task 16.0 in stage 20.0 (TID 34, 127.0.0.1, executor driver, partition 16, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:30 INFO TaskSetManager: Finished task 10.0 in stage 20.0 (TID 28) in 24399 ms on 127.0.0.1 (executor driver) (9/24)
21/03/20 14:38:30 INFO Executor: Running task 16.0 in stage 20.0 (TID 34)
21/03/20 14:38:30 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 2147483648-2281701376, partition values: [empty row]
21/03/20 14:38:30 INFO Executor: Finished task 12.0 in stage 20.0 (TID 30). 1863 bytes result sent to driver
21/03/20 14:38:30 INFO TaskSetManager: Starting task 17.0 in stage 20.0 (TID 35, 127.0.0.1, executor driver, partition 17, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:30 INFO Executor: Running task 17.0 in stage 20.0 (TID 35)
21/03/20 14:38:30 INFO TaskSetManager: Finished task 12.0 in stage 20.0 (TID 30) in 23839 ms on 127.0.0.1 (executor driver) (10/24)
21/03/20 14:38:30 INFO Executor: Finished task 8.0 in stage 20.0 (TID 26). 1820 bytes result sent to driver
21/03/20 14:38:30 INFO TaskSetManager: Starting task 18.0 in stage 20.0 (TID 36, 127.0.0.1, executor driver, partition 18, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:30 INFO Executor: Running task 18.0 in stage 20.0 (TID 36)
21/03/20 14:38:31 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 2281701376-2415919104, partition values: [empty row]
21/03/20 14:38:31 INFO TaskSetManager: Finished task 8.0 in stage 20.0 (TID 26) in 25164 ms on 127.0.0.1 (executor driver) (11/24)
21/03/20 14:38:31 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 2415919104-2550136832, partition values: [empty row]
21/03/20 14:38:31 INFO Executor: Finished task 14.0 in stage 20.0 (TID 32). 1820 bytes result sent to driver
21/03/20 14:38:31 INFO TaskSetManager: Starting task 19.0 in stage 20.0 (TID 37, 127.0.0.1, executor driver, partition 19, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:31 INFO Executor: Running task 19.0 in stage 20.0 (TID 37)
21/03/20 14:38:31 INFO TaskSetManager: Finished task 14.0 in stage 20.0 (TID 32) in 23474 ms on 127.0.0.1 (executor driver) (12/24)
21/03/20 14:38:31 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 2550136832-2684354560, partition values: [empty row]
21/03/20 14:38:31 INFO Executor: Finished task 11.0 in stage 20.0 (TID 29). 1863 bytes result sent to driver
21/03/20 14:38:31 INFO TaskSetManager: Starting task 20.0 in stage 20.0 (TID 38, 127.0.0.1, executor driver, partition 20, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:31 INFO Executor: Running task 20.0 in stage 20.0 (TID 38)
21/03/20 14:38:31 INFO TaskSetManager: Finished task 11.0 in stage 20.0 (TID 29) in 24254 ms on 127.0.0.1 (executor driver) (13/24)
21/03/20 14:38:31 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 2684354560-2818572288, partition values: [empty row]
21/03/20 14:38:31 INFO Executor: Finished task 9.0 in stage 20.0 (TID 27). 1820 bytes result sent to driver
21/03/20 14:38:31 INFO TaskSetManager: Starting task 21.0 in stage 20.0 (TID 39, 127.0.0.1, executor driver, partition 21, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:31 INFO TaskSetManager: Finished task 9.0 in stage 20.0 (TID 27) in 25688 ms on 127.0.0.1 (executor driver) (14/24)
21/03/20 14:38:31 INFO Executor: Running task 21.0 in stage 20.0 (TID 39)
21/03/20 14:38:31 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 2818572288-2952790016, partition values: [empty row]
21/03/20 14:38:32 INFO Executor: Finished task 15.0 in stage 20.0 (TID 33). 1863 bytes result sent to driver
21/03/20 14:38:32 INFO TaskSetManager: Starting task 22.0 in stage 20.0 (TID 40, 127.0.0.1, executor driver, partition 22, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:32 INFO Executor: Running task 22.0 in stage 20.0 (TID 40)
21/03/20 14:38:32 INFO TaskSetManager: Finished task 15.0 in stage 20.0 (TID 33) in 24269 ms on 127.0.0.1 (executor driver) (15/24)
21/03/20 14:38:32 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 2952790016-3087007744, partition values: [empty row]
21/03/20 14:38:32 INFO Executor: Finished task 13.0 in stage 20.0 (TID 31). 1863 bytes result sent to driver
21/03/20 14:38:32 INFO TaskSetManager: Starting task 23.0 in stage 20.0 (TID 41, 127.0.0.1, executor driver, partition 23, PROCESS_LOCAL, 7758 bytes)
21/03/20 14:38:32 INFO Executor: Running task 23.0 in stage 20.0 (TID 41)
21/03/20 14:38:32 INFO TaskSetManager: Finished task 13.0 in stage 20.0 (TID 31) in 25050 ms on 127.0.0.1 (executor driver) (16/24)
21/03/20 14:38:32 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 3087007744-3113283357, partition values: [empty row]
21/03/20 14:38:36 INFO Executor: Finished task 23.0 in stage 20.0 (TID 41). 1863 bytes result sent to driver
21/03/20 14:38:36 INFO TaskSetManager: Finished task 23.0 in stage 20.0 (TID 41) in 4570 ms on 127.0.0.1 (executor driver) (17/24)
21/03/20 14:38:52 INFO Executor: Finished task 17.0 in stage 20.0 (TID 35). 1820 bytes result sent to driver
21/03/20 14:38:52 INFO TaskSetManager: Finished task 17.0 in stage 20.0 (TID 35) in 21190 ms on 127.0.0.1 (executor driver) (18/24)
21/03/20 14:38:52 INFO Executor: Finished task 18.0 in stage 20.0 (TID 36). 1820 bytes result sent to driver
21/03/20 14:38:52 INFO TaskSetManager: Finished task 18.0 in stage 20.0 (TID 36) in 21241 ms on 127.0.0.1 (executor driver) (19/24)
21/03/20 14:38:52 INFO Executor: Finished task 16.0 in stage 20.0 (TID 34). 1863 bytes result sent to driver
21/03/20 14:38:52 INFO TaskSetManager: Finished task 16.0 in stage 20.0 (TID 34) in 21767 ms on 127.0.0.1 (executor driver) (20/24)
21/03/20 14:38:53 INFO Executor: Finished task 21.0 in stage 20.0 (TID 39). 1863 bytes result sent to driver
21/03/20 14:38:53 INFO TaskSetManager: Finished task 21.0 in stage 20.0 (TID 39) in 21375 ms on 127.0.0.1 (executor driver) (21/24)
21/03/20 14:38:53 INFO Executor: Finished task 20.0 in stage 20.0 (TID 38). 1863 bytes result sent to driver
21/03/20 14:38:53 INFO TaskSetManager: Finished task 20.0 in stage 20.0 (TID 38) in 22172 ms on 127.0.0.1 (executor driver) (22/24)
21/03/20 14:38:53 INFO Executor: Finished task 19.0 in stage 20.0 (TID 37). 1820 bytes result sent to driver
21/03/20 14:38:53 INFO TaskSetManager: Finished task 19.0 in stage 20.0 (TID 37) in 22357 ms on 127.0.0.1 (executor driver) (23/24)
21/03/20 14:38:54 INFO Executor: Finished task 22.0 in stage 20.0 (TID 40). 1863 bytes result sent to driver
21/03/20 14:38:54 INFO TaskSetManager: Finished task 22.0 in stage 20.0 (TID 40) in 21979 ms on 127.0.0.1 (executor driver) (24/24)
21/03/20 14:38:54 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/03/20 14:38:54 INFO DAGScheduler: ResultStage 20 (csv at <unknown>:0) finished in 70,562 s
21/03/20 14:38:54 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:38:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
21/03/20 14:38:54 INFO DAGScheduler: Job 15 finished: csv at <unknown>:0, took 70,575167 s
21/03/20 14:38:54 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:38:54 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:38:54 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:38:54 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:38:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 14:38:54 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 14:38:54 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:38:54 INFO DAGScheduler: Registering RDD 94 (count at utils.scala:135) as input to shuffle 6
21/03/20 14:38:54 INFO DAGScheduler: Got job 16 (count at utils.scala:135) with 1 output partitions
21/03/20 14:38:54 INFO DAGScheduler: Final stage: ResultStage 22 (count at utils.scala:135)
21/03/20 14:38:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
21/03/20 14:38:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
21/03/20 14:38:54 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[94] at count at utils.scala:135), which has no missing parents
21/03/20 14:38:54 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 10.1 KiB, free 413.6 MiB)
21/03/20 14:38:54 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.6 MiB)
21/03/20 14:38:54 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:50620 (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 14:38:54 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1223
21/03/20 14:38:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[94] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:38:54 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/03/20 14:38:54 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 42, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7498 bytes)
21/03/20 14:38:54 INFO Executor: Running task 0.0 in stage 21.0 (TID 42)
21/03/20 14:38:54 INFO Executor: Finished task 0.0 in stage 21.0 (TID 42). 1790 bytes result sent to driver
21/03/20 14:38:54 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 42) in 36 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:38:54 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/03/20 14:38:54 INFO DAGScheduler: ShuffleMapStage 21 (count at utils.scala:135) finished in 0,072 s
21/03/20 14:38:54 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:38:54 INFO DAGScheduler: running: Set()
21/03/20 14:38:54 INFO DAGScheduler: waiting: Set(ResultStage 22)
21/03/20 14:38:54 INFO DAGScheduler: failed: Set()
21/03/20 14:38:54 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[97] at count at utils.scala:135), which has no missing parents
21/03/20 14:38:54 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 10.1 KiB, free 413.6 MiB)
21/03/20 14:38:54 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.6 MiB)
21/03/20 14:38:54 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:50620 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:38:54 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1223
21/03/20 14:38:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[97] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:38:54 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/03/20 14:38:54 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 43, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:38:54 INFO Executor: Running task 0.0 in stage 22.0 (TID 43)
21/03/20 14:38:54 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:38:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:38:54 INFO Executor: Finished task 0.0 in stage 22.0 (TID 43). 2605 bytes result sent to driver
21/03/20 14:38:54 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 43) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:38:54 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/03/20 14:38:54 INFO DAGScheduler: ResultStage 22 (count at utils.scala:135) finished in 0,044 s
21/03/20 14:38:54 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:38:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
21/03/20 14:38:54 INFO DAGScheduler: Job 16 finished: count at utils.scala:135, took 0,131638 s
21/03/20 14:38:55 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:50620 in memory (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 14:38:55 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:50620 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:38:55 INFO FileSourceStrategy: Pruning directories with: 
21/03/20 14:38:55 INFO FileSourceStrategy: Pushed Filters: 
21/03/20 14:38:55 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/20 14:38:55 INFO FileSourceStrategy: Output Data Schema: struct<tipo_de_registro: int, indicador: string, tipo_atualizacao: string, cnpj: bigint, identificador_socio: int ... 15 more fields>
21/03/20 14:38:55 INFO CodeGenerator: Code generated in 53.9016 ms
21/03/20 14:38:55 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 280.4 KiB, free 413.3 MiB)
21/03/20 14:38:55 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 413.3 MiB)
21/03/20 14:38:55 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:50620 (size: 28.0 KiB, free: 413.9 MiB)
21/03/20 14:38:55 INFO SparkContext: Created broadcast 23 from sql at <unknown>:0
21/03/20 14:38:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
21/03/20 14:38:55 INFO SparkContext: Starting job: sql at <unknown>:0
21/03/20 14:38:55 INFO DAGScheduler: Registering RDD 104 (sql at <unknown>:0) as input to shuffle 7
21/03/20 14:38:55 INFO DAGScheduler: Got job 17 (sql at <unknown>:0) with 1 output partitions
21/03/20 14:38:55 INFO DAGScheduler: Final stage: ResultStage 24 (sql at <unknown>:0)
21/03/20 14:38:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
21/03/20 14:38:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
21/03/20 14:38:55 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[104] at sql at <unknown>:0), which has no missing parents
21/03/20 14:38:55 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 31.0 KiB, free 413.3 MiB)
21/03/20 14:38:55 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 13.3 KiB, free 413.3 MiB)
21/03/20 14:38:55 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:50620 (size: 13.3 KiB, free: 413.8 MiB)
21/03/20 14:38:55 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1223
21/03/20 14:38:55 INFO DAGScheduler: Submitting 24 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[104] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
21/03/20 14:38:55 INFO TaskSchedulerImpl: Adding task set 23.0 with 24 tasks
21/03/20 14:38:55 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 44, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7747 bytes)
21/03/20 14:38:55 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 45, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7747 bytes)
21/03/20 14:38:55 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 46, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7747 bytes)
21/03/20 14:38:55 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 47, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7747 bytes)
21/03/20 14:38:55 INFO TaskSetManager: Starting task 4.0 in stage 23.0 (TID 48, 127.0.0.1, executor driver, partition 4, PROCESS_LOCAL, 7747 bytes)
21/03/20 14:38:55 INFO TaskSetManager: Starting task 5.0 in stage 23.0 (TID 49, 127.0.0.1, executor driver, partition 5, PROCESS_LOCAL, 7747 bytes)
21/03/20 14:38:55 INFO TaskSetManager: Starting task 6.0 in stage 23.0 (TID 50, 127.0.0.1, executor driver, partition 6, PROCESS_LOCAL, 7747 bytes)
21/03/20 14:38:55 INFO TaskSetManager: Starting task 7.0 in stage 23.0 (TID 51, 127.0.0.1, executor driver, partition 7, PROCESS_LOCAL, 7747 bytes)
21/03/20 14:38:55 INFO Executor: Running task 0.0 in stage 23.0 (TID 44)
21/03/20 14:38:55 INFO Executor: Running task 3.0 in stage 23.0 (TID 47)
21/03/20 14:38:55 INFO Executor: Running task 4.0 in stage 23.0 (TID 48)
21/03/20 14:38:55 INFO Executor: Running task 7.0 in stage 23.0 (TID 51)
21/03/20 14:38:55 INFO Executor: Running task 6.0 in stage 23.0 (TID 50)
21/03/20 14:38:55 INFO Executor: Running task 2.0 in stage 23.0 (TID 46)
21/03/20 14:38:55 INFO Executor: Running task 5.0 in stage 23.0 (TID 49)
21/03/20 14:38:55 INFO Executor: Running task 1.0 in stage 23.0 (TID 45)
21/03/20 14:38:55 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 536870912-671088640, partition values: [empty row]
21/03/20 14:38:55 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 939524096-1073741824, partition values: [empty row]
21/03/20 14:38:55 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 0-134217728, partition values: [empty row]
21/03/20 14:38:55 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 402653184-536870912, partition values: [empty row]
21/03/20 14:38:55 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 268435456-402653184, partition values: [empty row]
21/03/20 14:38:55 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 134217728-268435456, partition values: [empty row]
21/03/20 14:38:55 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 805306368-939524096, partition values: [empty row]
21/03/20 14:38:55 INFO FileScanRDD: Reading File path: file:///C:/qsa_cnpj/bd_cnpj_tratados/cnpj_dados_socios_pj.csv, range: 671088640-805306368, partition values: [empty row]
21/03/20 14:38:55 INFO CodeGenerator: Code generated in 56.3591 ms
21/03/20 14:38:57 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:50620 in memory (size: 8.1 KiB, free: 413.9 MiB)
21/03/20 14:38:57 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:50620 in memory (size: 28.0 KiB, free: 413.9 MiB)
21/03/20 14:39:21 INFO TaskSchedulerImpl: Cancelling stage 23
21/03/20 14:39:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage cancelled
21/03/20 14:39:22 INFO Executor: Executor is trying to kill task 7.0 in stage 23.0 (TID 51), reason: Stage cancelled
21/03/20 14:39:22 INFO Executor: Executor is trying to kill task 4.0 in stage 23.0 (TID 48), reason: Stage cancelled
21/03/20 14:39:22 INFO Executor: Executor is trying to kill task 1.0 in stage 23.0 (TID 45), reason: Stage cancelled
21/03/20 14:39:22 INFO Executor: Executor is trying to kill task 5.0 in stage 23.0 (TID 49), reason: Stage cancelled
21/03/20 14:39:22 INFO Executor: Executor is trying to kill task 2.0 in stage 23.0 (TID 46), reason: Stage cancelled
21/03/20 14:39:22 INFO Executor: Executor is trying to kill task 6.0 in stage 23.0 (TID 50), reason: Stage cancelled
21/03/20 14:39:22 INFO Executor: Executor is trying to kill task 3.0 in stage 23.0 (TID 47), reason: Stage cancelled
21/03/20 14:39:22 INFO Executor: Executor is trying to kill task 0.0 in stage 23.0 (TID 44), reason: Stage cancelled
21/03/20 14:39:22 WARN BlockManager: Putting block rdd_100_2 failed due to exception org.apache.spark.TaskKilledException.
21/03/20 14:39:22 WARN BlockManager: Putting block rdd_100_5 failed due to exception org.apache.spark.TaskKilledException.
21/03/20 14:39:22 WARN BlockManager: Putting block rdd_100_6 failed due to exception org.apache.spark.TaskKilledException.
21/03/20 14:39:22 WARN BlockManager: Putting block rdd_100_4 failed due to exception org.apache.spark.TaskKilledException.
21/03/20 14:39:22 WARN BlockManager: Putting block rdd_100_3 failed due to exception org.apache.spark.TaskKilledException.
21/03/20 14:39:22 WARN BlockManager: Putting block rdd_100_7 failed due to exception org.apache.spark.TaskKilledException.
21/03/20 14:39:22 WARN BlockManager: Putting block rdd_100_1 failed due to exception org.apache.spark.TaskKilledException.
21/03/20 14:39:22 WARN BlockManager: Block rdd_100_2 could not be removed as it was not found on disk or in memory
21/03/20 14:39:22 WARN BlockManager: Block rdd_100_6 could not be removed as it was not found on disk or in memory
21/03/20 14:39:22 WARN BlockManager: Putting block rdd_100_0 failed due to exception org.apache.spark.TaskKilledException.
21/03/20 14:39:22 WARN BlockManager: Block rdd_100_4 could not be removed as it was not found on disk or in memory
21/03/20 14:39:22 WARN BlockManager: Block rdd_100_5 could not be removed as it was not found on disk or in memory
21/03/20 14:39:22 WARN BlockManager: Block rdd_100_3 could not be removed as it was not found on disk or in memory
21/03/20 14:39:22 WARN BlockManager: Block rdd_100_7 could not be removed as it was not found on disk or in memory
21/03/20 14:39:22 WARN BlockManager: Block rdd_100_1 could not be removed as it was not found on disk or in memory
21/03/20 14:39:22 WARN BlockManager: Block rdd_100_0 could not be removed as it was not found on disk or in memory
21/03/20 14:39:22 INFO Executor: Executor killed task 4.0 in stage 23.0 (TID 48), reason: Stage cancelled
21/03/20 14:39:22 INFO Executor: Executor killed task 7.0 in stage 23.0 (TID 51), reason: Stage cancelled
21/03/20 14:39:22 INFO Executor: Executor killed task 6.0 in stage 23.0 (TID 50), reason: Stage cancelled
21/03/20 14:39:22 INFO Executor: Executor killed task 3.0 in stage 23.0 (TID 47), reason: Stage cancelled
21/03/20 14:39:22 INFO Executor: Executor killed task 2.0 in stage 23.0 (TID 46), reason: Stage cancelled
21/03/20 14:39:22 INFO Executor: Executor killed task 1.0 in stage 23.0 (TID 45), reason: Stage cancelled
21/03/20 14:39:22 INFO Executor: Executor killed task 5.0 in stage 23.0 (TID 49), reason: Stage cancelled
21/03/20 14:39:22 INFO Executor: Executor killed task 0.0 in stage 23.0 (TID 44), reason: Stage cancelled
21/03/20 14:39:22 INFO TaskSchedulerImpl: Stage 23 was cancelled
21/03/20 14:39:22 INFO DAGScheduler: ShuffleMapStage 23 (sql at <unknown>:0) failed in 26,258 s due to Job 17 cancelled as part of cancellation of all jobs
21/03/20 14:39:22 INFO DAGScheduler: Job 17 failed: sql at <unknown>:0, took 26,281564 s
21/03/20 14:39:22 INFO SparkContext: Invoking stop() from shutdown hook
21/03/20 14:39:22 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
21/03/20 14:39:22 WARN TaskSetManager: Lost task 4.0 in stage 23.0 (TID 48, 127.0.0.1, executor driver): TaskKilled (Stage cancelled)
21/03/20 14:39:22 WARN TaskSetManager: Lost task 6.0 in stage 23.0 (TID 50, 127.0.0.1, executor driver): TaskKilled (Stage cancelled)
21/03/20 14:39:22 WARN TaskSetManager: Lost task 5.0 in stage 23.0 (TID 49, 127.0.0.1, executor driver): TaskKilled (Stage cancelled)
21/03/20 14:39:22 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$Lambda$3435/30079146@1b4a277 rejected from java.util.concurrent.ThreadPoolExecutor@136856d[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 47]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.reject(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.execute(Unknown Source)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:137)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:624)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:599)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:71)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:203)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 14:39:22 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$Lambda$3435/30079146@1144c87 rejected from java.util.concurrent.ThreadPoolExecutor@136856d[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 47]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.reject(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.execute(Unknown Source)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:137)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:624)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:599)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:71)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:203)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 14:39:22 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$Lambda$3435/30079146@10c84ce rejected from java.util.concurrent.ThreadPoolExecutor@136856d[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 47]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.reject(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.execute(Unknown Source)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:137)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:624)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:599)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:71)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:203)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 14:39:22 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$Lambda$3435/30079146@989340 rejected from java.util.concurrent.ThreadPoolExecutor@136856d[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 47]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.reject(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.execute(Unknown Source)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:137)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:624)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:599)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:71)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:203)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 14:39:22 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$Lambda$3435/30079146@1151a9 rejected from java.util.concurrent.ThreadPoolExecutor@136856d[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 47]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.reject(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.execute(Unknown Source)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:137)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:624)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:599)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:71)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:203)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 14:39:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/20 14:39:22 INFO MemoryStore: MemoryStore cleared
21/03/20 14:39:22 INFO BlockManager: BlockManager stopped
21/03/20 14:39:22 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/20 14:39:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/20 14:39:22 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-a02b5887-ea72-46fb-8fbd-d46c45207c31\userFiles-534e6c56-1fc3-421b-893c-90360e94a55d
java.io.IOException: Failed to delete: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-a02b5887-ea72-46fb-8fbd-d46c45207c31\userFiles-534e6c56-1fc3-421b-893c-90360e94a55d\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:105)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2012)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2012)
	at org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:631)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 14:39:22 INFO SparkContext: Successfully stopped SparkContext
21/03/20 14:39:22 INFO ShutdownHookManager: Shutdown hook called
21/03/20 14:39:22 INFO ShutdownHookManager: Deleting directory C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-a02b5887-ea72-46fb-8fbd-d46c45207c31\userFiles-534e6c56-1fc3-421b-893c-90360e94a55d
21/03/20 14:39:22 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-a02b5887-ea72-46fb-8fbd-d46c45207c31\userFiles-534e6c56-1fc3-421b-893c-90360e94a55d
java.io.IOException: Failed to delete: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-a02b5887-ea72-46fb-8fbd-d46c45207c31\userFiles-534e6c56-1fc3-421b-893c-90360e94a55d\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 14:39:22 INFO ShutdownHookManager: Deleting directory C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-a02b5887-ea72-46fb-8fbd-d46c45207c31
21/03/20 14:39:22 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-a02b5887-ea72-46fb-8fbd-d46c45207c31
java.io.IOException: Failed to delete: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-a02b5887-ea72-46fb-8fbd-d46c45207c31\userFiles-534e6c56-1fc3-421b-893c-90360e94a55d\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 14:39:22 INFO ShutdownHookManager: Deleting directory C:\Users\wilto\AppData\Local\Temp\spark-221c647c-639a-4530-a5db-09e09b52d9f0
21/03/20 14:48:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/20 14:48:14 INFO SecurityManager: Changing view acls to: wilto
21/03/20 14:48:14 INFO SecurityManager: Changing modify acls to: wilto
21/03/20 14:48:14 INFO SecurityManager: Changing view acls groups to: 
21/03/20 14:48:14 INFO SecurityManager: Changing modify acls groups to: 
21/03/20 14:48:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wilto); groups with view permissions: Set(); users  with modify permissions: Set(wilto); groups with modify permissions: Set()
21/03/20 14:48:17 INFO HiveConf: Found configuration file file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/03/20 14:48:18 INFO SparkContext: Running Spark version 3.0.1
21/03/20 14:48:18 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/03/20 14:48:18 INFO ResourceUtils: ==============================================================
21/03/20 14:48:18 INFO ResourceUtils: Resources for spark.driver:

21/03/20 14:48:18 INFO ResourceUtils: ==============================================================
21/03/20 14:48:18 INFO SparkContext: Submitted application: sparklyr
21/03/20 14:48:18 INFO SecurityManager: Changing view acls to: wilto
21/03/20 14:48:18 INFO SecurityManager: Changing modify acls to: wilto
21/03/20 14:48:18 INFO SecurityManager: Changing view acls groups to: 
21/03/20 14:48:18 INFO SecurityManager: Changing modify acls groups to: 
21/03/20 14:48:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wilto); groups with view permissions: Set(); users  with modify permissions: Set(wilto); groups with modify permissions: Set()
21/03/20 14:48:18 INFO Utils: Successfully started service 'sparkDriver' on port 49805.
21/03/20 14:48:18 INFO SparkEnv: Registering MapOutputTracker
21/03/20 14:48:19 INFO SparkEnv: Registering BlockManagerMaster
21/03/20 14:48:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/20 14:48:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/20 14:48:19 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/03/20 14:48:19 INFO DiskBlockManager: Created local directory at C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\blockmgr-d45b3ad4-3b44-4615-9e7d-efc1deb6b2c2
21/03/20 14:48:19 INFO MemoryStore: MemoryStore started with capacity 413.9 MiB
21/03/20 14:48:19 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/20 14:48:19 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/local]. Please check your configured local directories.
21/03/20 14:48:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/20 14:48:20 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
21/03/20 14:48:20 INFO SparkContext: Added JAR file:/C:/Users/wilto/OneDrive/Documentos/R/win-library/4.0/sparklyr/java/sparklyr-3.0-2.12.jar at spark://127.0.0.1:49805/jars/sparklyr-3.0-2.12.jar with timestamp 1616262500863
21/03/20 14:48:21 INFO Executor: Starting executor ID driver on host 127.0.0.1
21/03/20 14:48:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49848.
21/03/20 14:48:21 INFO NettyBlockTransferService: Server created on 127.0.0.1:49848
21/03/20 14:48:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/20 14:48:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 49848, None)
21/03/20 14:48:21 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:49848 with 413.9 MiB RAM, BlockManagerId(driver, 127.0.0.1, 49848, None)
21/03/20 14:48:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 49848, None)
21/03/20 14:48:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 49848, None)
21/03/20 14:48:22 INFO SharedState: loading hive config file: file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/03/20 14:48:22 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive').
21/03/20 14:48:22 INFO SharedState: Warehouse path is 'C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive'.
21/03/20 14:48:22 WARN SharedState: Not allowing to set spark.sql.warehouse.dir or hive.metastore.warehouse.dir in SparkSession's options, it should be set statically for cross-session usages
21/03/20 14:48:32 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/03/20 14:48:32 INFO HiveConf: Found configuration file file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/03/20 14:48:35 INFO SessionState: Created HDFS directory: C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive/wilto/0f022933-f26f-4f3e-8907-5973ee42dbaa
21/03/20 14:48:35 INFO SessionState: Created local directory: C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive/0f022933-f26f-4f3e-8907-5973ee42dbaa
21/03/20 14:48:36 INFO SessionState: Created HDFS directory: C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive/wilto/0f022933-f26f-4f3e-8907-5973ee42dbaa/_tmp_space.db
21/03/20 14:48:36 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive
21/03/20 14:48:39 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/03/20 14:48:39 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/03/20 14:48:39 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/20 14:48:39 INFO ObjectStore: ObjectStore, initialize called
21/03/20 14:48:39 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/20 14:48:39 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/20 14:48:43 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/20 14:48:46 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/20 14:48:46 INFO ObjectStore: Initialized ObjectStore
21/03/20 14:48:47 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/03/20 14:48:47 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.1.38
21/03/20 14:48:47 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/20 14:48:47 INFO HiveMetaStore: Added admin role in metastore
21/03/20 14:48:47 INFO HiveMetaStore: Added public role in metastore
21/03/20 14:48:47 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/20 14:48:48 INFO HiveMetaStore: 0: get_all_functions
21/03/20 14:48:48 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_all_functions	
21/03/20 14:48:48 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:48:48 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:48:48 INFO HiveMetaStore: 0: get_database: global_temp
21/03/20 14:48:48 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/20 14:48:48 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/20 14:48:48 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:48:48 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:48:48 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:48:48 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:48:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 14:48:48 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 14:48:51 INFO SparkContext: Starting job: collect at utils.scala:54
21/03/20 14:48:51 INFO DAGScheduler: Job 0 finished: collect at utils.scala:54, took 0,009805 s
21/03/20 14:48:53 INFO CodeGenerator: Code generated in 633.5731 ms
21/03/20 14:48:54 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:48:54 INFO DAGScheduler: Got job 1 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:48:54 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:137)
21/03/20 14:48:54 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:48:54 INFO DAGScheduler: Missing parents: List()
21/03/20 14:48:54 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137), which has no missing parents
21/03/20 14:48:54 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
21/03/20 14:48:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.7 KiB, free 413.9 MiB)
21/03/20 14:48:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 413.9 MiB)
21/03/20 14:48:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:49848 (size: 3.3 KiB, free: 413.9 MiB)
21/03/20 14:48:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/03/20 14:48:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:48:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/20 14:48:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 14:48:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/20 14:48:54 INFO Executor: Fetching spark://127.0.0.1:49805/jars/sparklyr-3.0-2.12.jar with timestamp 1616262500863
21/03/20 14:48:55 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:49805 after 160 ms (0 ms spent in bootstraps)
21/03/20 14:48:55 INFO Utils: Fetching spark://127.0.0.1:49805/jars/sparklyr-3.0-2.12.jar to C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-6b35cc38-6524-48c1-a022-2e12d823d664\userFiles-268699f0-2202-4605-a224-33034dbefc77\fetchFileTemp2215341856783448188.tmp
21/03/20 14:48:56 INFO Executor: Adding file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/local/spark-6b35cc38-6524-48c1-a022-2e12d823d664/userFiles-268699f0-2202-4605-a224-33034dbefc77/sparklyr-3.0-2.12.jar to class loader
21/03/20 14:48:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1483 bytes result sent to driver
21/03/20 14:48:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2049 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:48:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/20 14:48:56 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:137) finished in 2,600 s
21/03/20 14:48:56 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:48:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
21/03/20 14:48:56 INFO DAGScheduler: Job 1 finished: collect at utils.scala:137, took 2,728942 s
21/03/20 14:48:56 INFO CodeGenerator: Code generated in 55.3469 ms
21/03/20 14:48:57 INFO CodeGenerator: Code generated in 27.1245 ms
21/03/20 14:48:57 INFO CodeGenerator: Code generated in 36.8651 ms
21/03/20 14:48:57 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:48:57 INFO DAGScheduler: Registering RDD 11 (count at utils.scala:135) as input to shuffle 0
21/03/20 14:48:57 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/20 14:48:57 INFO DAGScheduler: Final stage: ResultStage 2 (count at utils.scala:135)
21/03/20 14:48:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
21/03/20 14:48:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
21/03/20 14:48:57 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/03/20 14:48:57 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:48:57 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:48:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:48:57 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/03/20 14:48:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:48:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/20 14:48:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 14:48:57 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/20 14:48:58 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1919 bytes result sent to driver
21/03/20 14:48:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 346 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:48:58 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/20 14:48:58 INFO DAGScheduler: ShuffleMapStage 1 (count at utils.scala:135) finished in 0,392 s
21/03/20 14:48:58 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:48:58 INFO DAGScheduler: running: Set()
21/03/20 14:48:58 INFO DAGScheduler: waiting: Set(ResultStage 2)
21/03/20 14:48:58 INFO DAGScheduler: failed: Set()
21/03/20 14:48:58 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135), which has no missing parents
21/03/20 14:48:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:48:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:48:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:48:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1223
21/03/20 14:48:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:48:58 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/20 14:48:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:48:58 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/20 14:48:58 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:48:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 27 ms
21/03/20 14:48:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2605 bytes result sent to driver
21/03/20 14:48:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 182 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:48:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/20 14:48:58 INFO DAGScheduler: ResultStage 2 (count at utils.scala:135) finished in 0,212 s
21/03/20 14:48:58 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:48:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
21/03/20 14:48:58 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0,668331 s
21/03/20 14:48:59 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:48:59 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:48:59 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:48:59 INFO DAGScheduler: Got job 3 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:48:59 INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:137)
21/03/20 14:48:59 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:48:59 INFO DAGScheduler: Missing parents: List()
21/03/20 14:48:59 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137), which has no missing parents
21/03/20 14:48:59 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.5 KiB, free 413.9 MiB)
21/03/20 14:48:59 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 413.9 MiB)
21/03/20 14:48:59 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:49848 (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 14:48:59 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1223
21/03/20 14:48:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:48:59 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/20 14:48:59 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 14:48:59 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/20 14:48:59 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1311 bytes result sent to driver
21/03/20 14:48:59 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 22 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:48:59 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/20 14:48:59 INFO DAGScheduler: ResultStage 3 (collect at utils.scala:137) finished in 0,042 s
21/03/20 14:48:59 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:48:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/03/20 14:48:59 INFO DAGScheduler: Job 3 finished: collect at utils.scala:137, took 0,048900 s
21/03/20 14:48:59 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:49848 in memory (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 14:48:59 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:48:59 INFO DAGScheduler: Registering RDD 18 (count at utils.scala:135) as input to shuffle 1
21/03/20 14:48:59 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/20 14:48:59 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/03/20 14:48:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/20 14:48:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/20 14:48:59 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135), which has no missing parents
21/03/20 14:48:59 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:48:59 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:48:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:48:59 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1223
21/03/20 14:48:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:48:59 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/20 14:48:59 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 14:48:59 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/20 14:48:59 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1790 bytes result sent to driver
21/03/20 14:48:59 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 28 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:48:59 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/20 14:48:59 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0,053 s
21/03/20 14:48:59 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:48:59 INFO DAGScheduler: running: Set()
21/03/20 14:48:59 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/20 14:48:59 INFO DAGScheduler: failed: Set()
21/03/20 14:48:59 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/20 14:48:59 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:48:59 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:48:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:48:59 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1223
21/03/20 14:48:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:48:59 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/20 14:48:59 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:48:59 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/20 14:48:59 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:48:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:48:59 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2605 bytes result sent to driver
21/03/20 14:48:59 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 26 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:48:59 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/20 14:48:59 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0,064 s
21/03/20 14:48:59 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:48:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
21/03/20 14:48:59 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0,133802 s
21/03/20 14:49:00 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:49:00 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:49:01 INFO CodeGenerator: Code generated in 51.1369 ms
21/03/20 14:49:01 INFO CodeGenerator: Code generated in 21.2004 ms
21/03/20 14:49:01 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:49:01 INFO DAGScheduler: Got job 5 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:49:01 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:137)
21/03/20 14:49:01 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:49:01 INFO DAGScheduler: Missing parents: List()
21/03/20 14:49:01 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[28] at collect at utils.scala:137), which has no missing parents
21/03/20 14:49:01 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 28.9 KiB, free 413.9 MiB)
21/03/20 14:49:01 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 413.9 MiB)
21/03/20 14:49:01 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:49848 (size: 9.9 KiB, free: 413.9 MiB)
21/03/20 14:49:01 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[28] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:01 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/20 14:49:01 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 14:49:01 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/20 14:49:01 INFO MemoryStore: Block rdd_23_0 stored as values in memory (estimated size 3.9 KiB, free 413.9 MiB)
21/03/20 14:49:01 INFO BlockManagerInfo: Added rdd_23_0 in memory on 127.0.0.1:49848 (size: 3.9 KiB, free: 413.9 MiB)
21/03/20 14:49:01 INFO CodeGenerator: Code generated in 43.935 ms
21/03/20 14:49:01 INFO Executor: 1 block locks were not released by TID = 6:
[rdd_23_0]
21/03/20 14:49:01 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2226 bytes result sent to driver
21/03/20 14:49:01 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 389 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:01 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/20 14:49:01 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:137) finished in 0,420 s
21/03/20 14:49:01 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:49:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
21/03/20 14:49:01 INFO DAGScheduler: Job 5 finished: collect at utils.scala:137, took 0,441112 s
21/03/20 14:49:01 INFO CodeGenerator: Code generated in 26.1115 ms
21/03/20 14:49:01 INFO CodeGenerator: Code generated in 21.6445 ms
21/03/20 14:49:01 INFO CodeGenerator: Code generated in 12.1258 ms
21/03/20 14:49:01 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:49:01 INFO DAGScheduler: Registering RDD 33 (count at utils.scala:135) as input to shuffle 2
21/03/20 14:49:01 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/20 14:49:01 INFO DAGScheduler: Final stage: ResultStage 8 (count at utils.scala:135)
21/03/20 14:49:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
21/03/20 14:49:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
21/03/20 14:49:01 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[33] at count at utils.scala:135), which has no missing parents
21/03/20 14:49:01 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.0 KiB, free 413.8 MiB)
21/03/20 14:49:01 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.2 KiB, free 413.8 MiB)
21/03/20 14:49:01 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:49848 (size: 10.2 KiB, free: 413.9 MiB)
21/03/20 14:49:01 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[33] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:01 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/20 14:49:01 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 14:49:02 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/20 14:49:02 INFO BlockManager: Found block rdd_23_0 locally
21/03/20 14:49:02 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_23_0]
21/03/20 14:49:02 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2084 bytes result sent to driver
21/03/20 14:49:02 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 41 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:02 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/20 14:49:02 INFO DAGScheduler: ShuffleMapStage 7 (count at utils.scala:135) finished in 0,056 s
21/03/20 14:49:02 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:49:02 INFO DAGScheduler: running: Set()
21/03/20 14:49:02 INFO DAGScheduler: waiting: Set(ResultStage 8)
21/03/20 14:49:02 INFO DAGScheduler: failed: Set()
21/03/20 14:49:02 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[36] at count at utils.scala:135), which has no missing parents
21/03/20 14:49:02 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.5 KiB, free 413.8 MiB)
21/03/20 14:49:02 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.8 MiB)
21/03/20 14:49:02 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:49848 (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 14:49:02 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[36] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:02 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/20 14:49:02 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:49:02 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/03/20 14:49:02 INFO ShuffleBlockFetcherIterator: Getting 1 (54.0 B) non-empty blocks including 1 (54.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:49:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:49:02 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2428 bytes result sent to driver
21/03/20 14:49:02 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 21 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:02 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/20 14:49:02 INFO DAGScheduler: ResultStage 8 (count at utils.scala:135) finished in 0,038 s
21/03/20 14:49:02 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:49:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
21/03/20 14:49:02 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0,115051 s
21/03/20 14:49:03 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:49848 in memory (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 14:49:03 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:49848 in memory (size: 10.2 KiB, free: 413.9 MiB)
21/03/20 14:49:03 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:49:03 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:49:03 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:49:03 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:49:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 14:49:03 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 14:49:03 INFO CodeGenerator: Code generated in 36.7846 ms
21/03/20 14:49:03 INFO CodeGenerator: Code generated in 34.6756 ms
21/03/20 14:49:03 INFO CodeGenerator: Code generated in 62.9674 ms
21/03/20 14:49:03 INFO CodeGenerator: Code generated in 13.4403 ms
21/03/20 14:49:04 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:49:04 INFO DAGScheduler: Registering RDD 39 (count at utils.scala:135) as input to shuffle 3
21/03/20 14:49:04 INFO DAGScheduler: Got job 7 (count at utils.scala:135) with 1 output partitions
21/03/20 14:49:04 INFO DAGScheduler: Final stage: ResultStage 10 (count at utils.scala:135)
21/03/20 14:49:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
21/03/20 14:49:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
21/03/20 14:49:04 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[39] at count at utils.scala:135), which has no missing parents
21/03/20 14:49:04 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:49:04 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.9 MiB)
21/03/20 14:49:04 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:49848 (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 14:49:04 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[39] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:04 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/20 14:49:04 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7498 bytes)
21/03/20 14:49:04 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/03/20 14:49:04 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1790 bytes result sent to driver
21/03/20 14:49:04 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 38 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:04 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/20 14:49:04 INFO DAGScheduler: ShuffleMapStage 9 (count at utils.scala:135) finished in 0,058 s
21/03/20 14:49:04 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:49:04 INFO DAGScheduler: running: Set()
21/03/20 14:49:04 INFO DAGScheduler: waiting: Set(ResultStage 10)
21/03/20 14:49:04 INFO DAGScheduler: failed: Set()
21/03/20 14:49:04 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[42] at count at utils.scala:135), which has no missing parents
21/03/20 14:49:04 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 10.1 KiB, free 413.8 MiB)
21/03/20 14:49:04 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
21/03/20 14:49:04 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:49:04 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[42] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:04 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/20 14:49:04 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:49:04 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/03/20 14:49:04 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:49:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/03/20 14:49:04 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2605 bytes result sent to driver
21/03/20 14:49:04 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 18 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:04 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/20 14:49:04 INFO DAGScheduler: ResultStage 10 (count at utils.scala:135) finished in 0,034 s
21/03/20 14:49:04 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:49:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
21/03/20 14:49:04 INFO DAGScheduler: Job 7 finished: count at utils.scala:135, took 0,108553 s
21/03/20 14:49:04 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:49:04 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:49848 in memory (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 14:49:04 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:49:04 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:49:04 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:49:04 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:49:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 14:49:04 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 14:49:04 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:49:04 INFO DAGScheduler: Registering RDD 45 (count at utils.scala:135) as input to shuffle 4
21/03/20 14:49:04 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/03/20 14:49:04 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:135)
21/03/20 14:49:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/03/20 14:49:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/03/20 14:49:04 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[45] at count at utils.scala:135), which has no missing parents
21/03/20 14:49:04 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:49:04 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.9 MiB)
21/03/20 14:49:04 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:49848 (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 14:49:04 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[45] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:04 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/20 14:49:04 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7498 bytes)
21/03/20 14:49:04 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/03/20 14:49:04 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1833 bytes result sent to driver
21/03/20 14:49:04 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 30 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:04 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/20 14:49:04 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:135) finished in 0,045 s
21/03/20 14:49:04 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:49:04 INFO DAGScheduler: running: Set()
21/03/20 14:49:04 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/03/20 14:49:04 INFO DAGScheduler: failed: Set()
21/03/20 14:49:04 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[48] at count at utils.scala:135), which has no missing parents
21/03/20 14:49:04 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 10.1 KiB, free 413.8 MiB)
21/03/20 14:49:04 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
21/03/20 14:49:04 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:49:04 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[48] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:04 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/20 14:49:04 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:49:04 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/03/20 14:49:04 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:49:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:49:04 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2605 bytes result sent to driver
21/03/20 14:49:04 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 15 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:04 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/20 14:49:04 INFO DAGScheduler: ResultStage 12 (count at utils.scala:135) finished in 0,045 s
21/03/20 14:49:04 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:49:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
21/03/20 14:49:04 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0,097631 s
21/03/20 14:49:04 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:49:05 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:49848 in memory (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 14:49:06 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:49848 in memory (size: 3.3 KiB, free: 413.9 MiB)
21/03/20 14:49:06 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:49848 in memory (size: 9.9 KiB, free: 413.9 MiB)
21/03/20 14:49:21 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:49:21 INFO DAGScheduler: Got job 9 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:49:21 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:137)
21/03/20 14:49:21 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:49:21 INFO DAGScheduler: Missing parents: List()
21/03/20 14:49:21 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[53] at collect at utils.scala:137), which has no missing parents
21/03/20 14:49:21 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 29.7 KiB, free 413.9 MiB)
21/03/20 14:49:21 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 10.4 KiB, free 413.9 MiB)
21/03/20 14:49:21 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:49848 (size: 10.4 KiB, free: 413.9 MiB)
21/03/20 14:49:21 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[53] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:21 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/20 14:49:21 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 14:49:21 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/03/20 14:49:21 INFO BlockManager: Found block rdd_23_0 locally
21/03/20 14:49:21 INFO Executor: 1 block locks were not released by TID = 13:
[rdd_23_0]
21/03/20 14:49:21 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2226 bytes result sent to driver
21/03/20 14:49:21 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:21 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/20 14:49:21 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:137) finished in 0,044 s
21/03/20 14:49:21 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:49:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
21/03/20 14:49:21 INFO DAGScheduler: Job 9 finished: collect at utils.scala:137, took 0,050878 s
21/03/20 14:49:21 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:49848 in memory (size: 10.4 KiB, free: 413.9 MiB)
21/03/20 14:49:21 INFO CodeGenerator: Code generated in 23.2437 ms
21/03/20 14:49:21 INFO CodeGenerator: Code generated in 16.4719 ms
21/03/20 14:49:21 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:49:21 INFO DAGScheduler: Registering RDD 58 (count at utils.scala:135) as input to shuffle 5
21/03/20 14:49:21 INFO DAGScheduler: Got job 10 (count at utils.scala:135) with 1 output partitions
21/03/20 14:49:21 INFO DAGScheduler: Final stage: ResultStage 15 (count at utils.scala:135)
21/03/20 14:49:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
21/03/20 14:49:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
21/03/20 14:49:21 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[58] at count at utils.scala:135), which has no missing parents
21/03/20 14:49:21 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 25.0 KiB, free 413.9 MiB)
21/03/20 14:49:21 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 10.2 KiB, free 413.9 MiB)
21/03/20 14:49:21 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:49848 (size: 10.2 KiB, free: 413.9 MiB)
21/03/20 14:49:21 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[58] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:21 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/20 14:49:21 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 14:49:21 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/03/20 14:49:21 INFO BlockManager: Found block rdd_23_0 locally
21/03/20 14:49:21 INFO Executor: 1 block locks were not released by TID = 14:
[rdd_23_0]
21/03/20 14:49:21 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 2084 bytes result sent to driver
21/03/20 14:49:21 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 41 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:21 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/20 14:49:21 INFO DAGScheduler: ShuffleMapStage 14 (count at utils.scala:135) finished in 0,057 s
21/03/20 14:49:21 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:49:21 INFO DAGScheduler: running: Set()
21/03/20 14:49:21 INFO DAGScheduler: waiting: Set(ResultStage 15)
21/03/20 14:49:21 INFO DAGScheduler: failed: Set()
21/03/20 14:49:21 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[61] at count at utils.scala:135), which has no missing parents
21/03/20 14:49:21 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 11.5 KiB, free 413.9 MiB)
21/03/20 14:49:21 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.9 MiB)
21/03/20 14:49:21 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:49848 (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 14:49:21 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[61] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:21 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/03/20 14:49:21 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:49:21 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/03/20 14:49:21 INFO ShuffleBlockFetcherIterator: Getting 1 (54.0 B) non-empty blocks including 1 (54.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:49:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:49:21 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 2428 bytes result sent to driver
21/03/20 14:49:21 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 20 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:21 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/03/20 14:49:21 INFO DAGScheduler: ResultStage 15 (count at utils.scala:135) finished in 0,052 s
21/03/20 14:49:21 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:49:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
21/03/20 14:49:21 INFO DAGScheduler: Job 10 finished: count at utils.scala:135, took 0,126239 s
21/03/20 14:49:47 INFO CodeGenerator: Code generated in 13.7239 ms
21/03/20 14:49:47 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:49848 in memory (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 14:49:47 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:49:47 INFO DAGScheduler: Registering RDD 63 (collect at utils.scala:137) as input to shuffle 6
21/03/20 14:49:47 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:49848 in memory (size: 10.2 KiB, free: 413.9 MiB)
21/03/20 14:49:47 INFO DAGScheduler: Got job 11 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:49:47 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:137)
21/03/20 14:49:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
21/03/20 14:49:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
21/03/20 14:49:47 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[63] at collect at utils.scala:137), which has no missing parents
21/03/20 14:49:47 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:49:47 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:49:47 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:49:47 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[63] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:47 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/03/20 14:49:47 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 14:49:47 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/03/20 14:49:48 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1790 bytes result sent to driver
21/03/20 14:49:48 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 36 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:48 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/03/20 14:49:48 INFO DAGScheduler: ShuffleMapStage 16 (collect at utils.scala:137) finished in 0,056 s
21/03/20 14:49:48 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:49:48 INFO DAGScheduler: running: Set()
21/03/20 14:49:48 INFO DAGScheduler: waiting: Set(ResultStage 17)
21/03/20 14:49:48 INFO DAGScheduler: failed: Set()
21/03/20 14:49:48 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[66] at collect at utils.scala:137), which has no missing parents
21/03/20 14:49:48 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:49:48 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:49:48 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:49:48 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[66] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:48 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/03/20 14:49:48 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:49:48 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/03/20 14:49:48 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:49:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:49:48 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 2605 bytes result sent to driver
21/03/20 14:49:48 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:48 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/03/20 14:49:48 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:137) finished in 0,032 s
21/03/20 14:49:48 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:49:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
21/03/20 14:49:48 INFO DAGScheduler: Job 11 finished: collect at utils.scala:137, took 0,103646 s
21/03/20 14:49:48 INFO CodeGenerator: Code generated in 8.8036 ms
21/03/20 14:49:48 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:49:48 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:49:48 INFO CodeGenerator: Code generated in 20.3047 ms
21/03/20 14:49:48 INFO CodeGenerator: Code generated in 18.2357 ms
21/03/20 14:49:48 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:49:48 INFO DAGScheduler: Registering RDD 68 (count at utils.scala:135) as input to shuffle 7
21/03/20 14:49:48 INFO DAGScheduler: Got job 12 (count at utils.scala:135) with 1 output partitions
21/03/20 14:49:48 INFO DAGScheduler: Final stage: ResultStage 19 (count at utils.scala:135)
21/03/20 14:49:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
21/03/20 14:49:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
21/03/20 14:49:48 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[68] at count at utils.scala:135), which has no missing parents
21/03/20 14:49:48 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 9.1 KiB, free 413.9 MiB)
21/03/20 14:49:48 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 413.9 MiB)
21/03/20 14:49:48 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:49848 (size: 4.8 KiB, free: 413.9 MiB)
21/03/20 14:49:48 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[68] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:48 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/03/20 14:49:48 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 14:49:48 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/03/20 14:49:48 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1790 bytes result sent to driver
21/03/20 14:49:48 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 40 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:48 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/03/20 14:49:48 INFO DAGScheduler: ShuffleMapStage 18 (count at utils.scala:135) finished in 0,060 s
21/03/20 14:49:48 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:49:48 INFO DAGScheduler: running: Set()
21/03/20 14:49:48 INFO DAGScheduler: waiting: Set(ResultStage 19)
21/03/20 14:49:48 INFO DAGScheduler: failed: Set()
21/03/20 14:49:48 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[71] at count at utils.scala:135), which has no missing parents
21/03/20 14:49:48 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 12.1 KiB, free 413.9 MiB)
21/03/20 14:49:48 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.9 MiB)
21/03/20 14:49:48 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:49848 (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 14:49:48 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[71] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:48 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/03/20 14:49:48 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:49:48 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/03/20 14:49:48 INFO ShuffleBlockFetcherIterator: Getting 1 (49.0 B) non-empty blocks including 1 (49.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:49:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:49:48 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 2853 bytes result sent to driver
21/03/20 14:49:48 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 26 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:48 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/03/20 14:49:48 INFO DAGScheduler: ResultStage 19 (count at utils.scala:135) finished in 0,042 s
21/03/20 14:49:48 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:49:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
21/03/20 14:49:48 INFO DAGScheduler: Job 12 finished: count at utils.scala:135, took 0,113245 s
21/03/20 14:49:57 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:49848 in memory (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 14:49:57 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:49848 in memory (size: 4.8 KiB, free: 413.9 MiB)
21/03/20 14:49:57 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:49:57 INFO DAGScheduler: Registering RDD 73 (collect at utils.scala:137) as input to shuffle 8
21/03/20 14:49:57 INFO DAGScheduler: Got job 13 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:49:57 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:137)
21/03/20 14:49:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
21/03/20 14:49:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
21/03/20 14:49:57 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[73] at collect at utils.scala:137), which has no missing parents
21/03/20 14:49:57 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:49:57 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:49:57 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:49:57 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[73] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:57 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/03/20 14:49:57 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 14:49:57 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/03/20 14:49:57 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1790 bytes result sent to driver
21/03/20 14:49:57 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 56 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:57 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/03/20 14:49:57 INFO DAGScheduler: ShuffleMapStage 20 (collect at utils.scala:137) finished in 0,080 s
21/03/20 14:49:57 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:49:57 INFO DAGScheduler: running: Set()
21/03/20 14:49:57 INFO DAGScheduler: waiting: Set(ResultStage 21)
21/03/20 14:49:57 INFO DAGScheduler: failed: Set()
21/03/20 14:49:57 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[76] at collect at utils.scala:137), which has no missing parents
21/03/20 14:49:57 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:49:57 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:49:57 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:49:57 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[76] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:57 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/03/20 14:49:57 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:49:57 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/03/20 14:49:57 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:49:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:49:57 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 2566 bytes result sent to driver
21/03/20 14:49:57 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 20 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:57 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/03/20 14:49:57 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:137) finished in 0,035 s
21/03/20 14:49:57 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:49:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
21/03/20 14:49:57 INFO DAGScheduler: Job 13 finished: collect at utils.scala:137, took 0,135861 s
21/03/20 14:49:57 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:49:57 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:49:57 INFO CodeGenerator: Code generated in 23.8511 ms
21/03/20 14:49:58 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:49:58 INFO DAGScheduler: Registering RDD 78 (count at utils.scala:135) as input to shuffle 9
21/03/20 14:49:58 INFO DAGScheduler: Got job 14 (count at utils.scala:135) with 1 output partitions
21/03/20 14:49:58 INFO DAGScheduler: Final stage: ResultStage 23 (count at utils.scala:135)
21/03/20 14:49:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
21/03/20 14:49:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
21/03/20 14:49:58 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[78] at count at utils.scala:135), which has no missing parents
21/03/20 14:49:58 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 9.1 KiB, free 413.9 MiB)
21/03/20 14:49:58 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 413.9 MiB)
21/03/20 14:49:58 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:49848 (size: 4.8 KiB, free: 413.9 MiB)
21/03/20 14:49:58 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[78] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:58 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/03/20 14:49:58 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 14:49:58 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/03/20 14:49:58 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1790 bytes result sent to driver
21/03/20 14:49:58 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:58 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/03/20 14:49:58 INFO DAGScheduler: ShuffleMapStage 22 (count at utils.scala:135) finished in 0,048 s
21/03/20 14:49:58 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:49:58 INFO DAGScheduler: running: Set()
21/03/20 14:49:58 INFO DAGScheduler: waiting: Set(ResultStage 23)
21/03/20 14:49:58 INFO DAGScheduler: failed: Set()
21/03/20 14:49:58 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[81] at count at utils.scala:135), which has no missing parents
21/03/20 14:49:58 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 12.4 KiB, free 413.9 MiB)
21/03/20 14:49:58 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 413.9 MiB)
21/03/20 14:49:58 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:49848 (size: 5.4 KiB, free: 413.9 MiB)
21/03/20 14:49:58 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1223
21/03/20 14:49:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[81] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:49:58 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/03/20 14:49:58 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:49:58 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/03/20 14:49:58 INFO ShuffleBlockFetcherIterator: Getting 1 (49.0 B) non-empty blocks including 1 (49.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:49:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/20 14:49:58 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2853 bytes result sent to driver
21/03/20 14:49:58 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 20 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:49:58 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/03/20 14:49:58 INFO DAGScheduler: ResultStage 23 (count at utils.scala:135) finished in 0,032 s
21/03/20 14:49:58 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:49:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
21/03/20 14:49:58 INFO DAGScheduler: Job 14 finished: count at utils.scala:135, took 0,090943 s
21/03/20 14:51:44 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:49848 in memory (size: 5.4 KiB, free: 413.9 MiB)
21/03/20 14:51:44 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:49848 in memory (size: 4.8 KiB, free: 413.9 MiB)
21/03/20 14:51:44 INFO CodeGenerator: Code generated in 15.2799 ms
21/03/20 14:51:44 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:51:44 INFO DAGScheduler: Got job 15 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:51:44 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:137)
21/03/20 14:51:44 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:51:44 INFO DAGScheduler: Missing parents: List()
21/03/20 14:51:44 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[83] at collect at utils.scala:137), which has no missing parents
21/03/20 14:51:44 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.1 KiB, free 413.9 MiB)
21/03/20 14:51:44 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 413.9 MiB)
21/03/20 14:51:44 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:49848 (size: 3.6 KiB, free: 413.9 MiB)
21/03/20 14:51:44 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[83] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:51:44 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/03/20 14:51:44 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 14:51:44 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
21/03/20 14:51:44 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1354 bytes result sent to driver
21/03/20 14:51:44 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 17 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:51:44 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/03/20 14:51:44 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:137) finished in 0,037 s
21/03/20 14:51:44 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:51:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
21/03/20 14:51:44 INFO DAGScheduler: Job 15 finished: collect at utils.scala:137, took 0,044662 s
21/03/20 14:51:44 INFO CodeGenerator: Code generated in 18.8909 ms
21/03/20 14:51:44 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:51:44 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:49848 in memory (size: 3.6 KiB, free: 413.9 MiB)
21/03/20 14:51:44 INFO DAGScheduler: Registering RDD 85 (count at utils.scala:135) as input to shuffle 10
21/03/20 14:51:44 INFO DAGScheduler: Got job 16 (count at utils.scala:135) with 1 output partitions
21/03/20 14:51:44 INFO DAGScheduler: Final stage: ResultStage 26 (count at utils.scala:135)
21/03/20 14:51:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
21/03/20 14:51:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
21/03/20 14:51:44 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[85] at count at utils.scala:135), which has no missing parents
21/03/20 14:51:44 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:51:44 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:51:44 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:51:44 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[85] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:51:44 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/03/20 14:51:44 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 14:51:44 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
21/03/20 14:51:44 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 1790 bytes result sent to driver
21/03/20 14:51:44 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 28 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:51:44 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/03/20 14:51:44 INFO DAGScheduler: ShuffleMapStage 25 (count at utils.scala:135) finished in 0,040 s
21/03/20 14:51:44 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:51:44 INFO DAGScheduler: running: Set()
21/03/20 14:51:44 INFO DAGScheduler: waiting: Set(ResultStage 26)
21/03/20 14:51:44 INFO DAGScheduler: failed: Set()
21/03/20 14:51:44 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[88] at count at utils.scala:135), which has no missing parents
21/03/20 14:51:44 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:51:44 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:51:44 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:51:44 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[88] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:51:44 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/03/20 14:51:44 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:51:44 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
21/03/20 14:51:44 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:51:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:51:44 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2605 bytes result sent to driver
21/03/20 14:51:44 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:51:44 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/03/20 14:51:44 INFO DAGScheduler: ResultStage 26 (count at utils.scala:135) finished in 0,028 s
21/03/20 14:51:44 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:51:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
21/03/20 14:51:44 INFO DAGScheduler: Job 16 finished: count at utils.scala:135, took 0,083461 s
21/03/20 14:51:44 INFO CodeGenerator: Code generated in 11.3804 ms
21/03/20 14:51:44 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:51:44 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:51:45 INFO SparkContext: Starting job: aggregate at samplingutils.scala:37
21/03/20 14:51:45 INFO DAGScheduler: Got job 17 (aggregate at samplingutils.scala:37) with 1 output partitions
21/03/20 14:51:45 INFO DAGScheduler: Final stage: ResultStage 27 (aggregate at samplingutils.scala:37)
21/03/20 14:51:45 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:51:45 INFO DAGScheduler: Missing parents: List()
21/03/20 14:51:45 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[92] at rdd at <unknown>:0), which has no missing parents
21/03/20 14:51:45 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 14.1 KiB, free 413.9 MiB)
21/03/20 14:51:45 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 413.9 MiB)
21/03/20 14:51:45 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:49848 (size: 7.0 KiB, free: 413.9 MiB)
21/03/20 14:51:45 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[92] at rdd at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/03/20 14:51:45 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
21/03/20 14:51:45 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 14:51:45 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
21/03/20 14:51:45 INFO CodeGenerator: Code generated in 10.3628 ms
21/03/20 14:51:45 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 4790 bytes result sent to driver
21/03/20 14:51:45 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 155 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:51:45 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
21/03/20 14:51:45 INFO DAGScheduler: ResultStage 27 (aggregate at samplingutils.scala:37) finished in 0,191 s
21/03/20 14:51:45 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:51:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
21/03/20 14:51:45 INFO DAGScheduler: Job 17 finished: aggregate at samplingutils.scala:37, took 0,223617 s
21/03/20 14:51:45 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:49848 in memory (size: 7.0 KiB, free: 413.9 MiB)
21/03/20 14:51:45 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:51:45 INFO DAGScheduler: Got job 18 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:51:45 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:137)
21/03/20 14:51:45 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:51:45 INFO DAGScheduler: Missing parents: List()
21/03/20 14:51:45 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[96] at collect at utils.scala:137), which has no missing parents
21/03/20 14:51:45 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 7.1 KiB, free 413.9 MiB)
21/03/20 14:51:45 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 413.9 MiB)
21/03/20 14:51:45 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:49848 (size: 3.6 KiB, free: 413.9 MiB)
21/03/20 14:51:45 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[96] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:51:45 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
21/03/20 14:51:45 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 14:51:45 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
21/03/20 14:51:45 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 1354 bytes result sent to driver
21/03/20 14:51:45 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 12 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:51:45 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
21/03/20 14:51:45 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:137) finished in 0,024 s
21/03/20 14:51:45 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:51:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
21/03/20 14:51:45 INFO DAGScheduler: Job 18 finished: collect at utils.scala:137, took 0,030805 s
21/03/20 14:51:45 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:49848 in memory (size: 3.6 KiB, free: 413.9 MiB)
21/03/20 14:51:45 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:51:45 INFO DAGScheduler: Registering RDD 98 (count at utils.scala:135) as input to shuffle 11
21/03/20 14:51:45 INFO DAGScheduler: Got job 19 (count at utils.scala:135) with 1 output partitions
21/03/20 14:51:45 INFO DAGScheduler: Final stage: ResultStage 30 (count at utils.scala:135)
21/03/20 14:51:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
21/03/20 14:51:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
21/03/20 14:51:45 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[98] at count at utils.scala:135), which has no missing parents
21/03/20 14:51:45 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:51:45 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:51:45 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:51:45 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[98] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:51:45 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
21/03/20 14:51:45 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 14:51:45 INFO Executor: Running task 0.0 in stage 29.0 (TID 29)
21/03/20 14:51:45 INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 1790 bytes result sent to driver
21/03/20 14:51:45 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:51:45 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
21/03/20 14:51:45 INFO DAGScheduler: ShuffleMapStage 29 (count at utils.scala:135) finished in 0,040 s
21/03/20 14:51:45 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:51:45 INFO DAGScheduler: running: Set()
21/03/20 14:51:45 INFO DAGScheduler: waiting: Set(ResultStage 30)
21/03/20 14:51:45 INFO DAGScheduler: failed: Set()
21/03/20 14:51:45 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[101] at count at utils.scala:135), which has no missing parents
21/03/20 14:51:45 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:51:45 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:51:45 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:51:45 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[101] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:51:45 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
21/03/20 14:51:45 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:51:45 INFO Executor: Running task 0.0 in stage 30.0 (TID 30)
21/03/20 14:51:45 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:51:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:51:45 INFO Executor: Finished task 0.0 in stage 30.0 (TID 30). 2562 bytes result sent to driver
21/03/20 14:51:45 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:51:45 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
21/03/20 14:51:45 INFO DAGScheduler: ResultStage 30 (count at utils.scala:135) finished in 0,036 s
21/03/20 14:51:45 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:51:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
21/03/20 14:51:45 INFO DAGScheduler: Job 19 finished: count at utils.scala:135, took 0,084503 s
21/03/20 14:51:46 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:51:46 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:51:46 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:51:46 INFO DAGScheduler: Got job 20 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:51:46 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:137)
21/03/20 14:51:46 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:51:46 INFO DAGScheduler: Missing parents: List()
21/03/20 14:51:46 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[103] at collect at utils.scala:137), which has no missing parents
21/03/20 14:51:46 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 7.1 KiB, free 413.9 MiB)
21/03/20 14:51:46 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 413.9 MiB)
21/03/20 14:51:46 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:49848 (size: 3.6 KiB, free: 413.9 MiB)
21/03/20 14:51:46 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[103] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:51:46 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
21/03/20 14:51:46 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 31, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 14:51:46 INFO Executor: Running task 0.0 in stage 31.0 (TID 31)
21/03/20 14:51:46 INFO Executor: Finished task 0.0 in stage 31.0 (TID 31). 1311 bytes result sent to driver
21/03/20 14:51:46 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 31) in 12 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:51:46 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
21/03/20 14:51:46 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:137) finished in 0,024 s
21/03/20 14:51:46 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:51:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
21/03/20 14:51:46 INFO DAGScheduler: Job 20 finished: collect at utils.scala:137, took 0,031442 s
21/03/20 14:51:46 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:49848 in memory (size: 3.6 KiB, free: 413.9 MiB)
21/03/20 14:51:46 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:51:46 INFO DAGScheduler: Registering RDD 105 (count at utils.scala:135) as input to shuffle 12
21/03/20 14:51:46 INFO DAGScheduler: Got job 21 (count at utils.scala:135) with 1 output partitions
21/03/20 14:51:46 INFO DAGScheduler: Final stage: ResultStage 33 (count at utils.scala:135)
21/03/20 14:51:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
21/03/20 14:51:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 32)
21/03/20 14:51:46 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[105] at count at utils.scala:135), which has no missing parents
21/03/20 14:51:46 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:51:46 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:51:46 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:51:46 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[105] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:51:46 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
21/03/20 14:51:46 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 32, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 14:51:46 INFO Executor: Running task 0.0 in stage 32.0 (TID 32)
21/03/20 14:51:46 INFO Executor: Finished task 0.0 in stage 32.0 (TID 32). 1790 bytes result sent to driver
21/03/20 14:51:46 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 32) in 36 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:51:46 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
21/03/20 14:51:46 INFO DAGScheduler: ShuffleMapStage 32 (count at utils.scala:135) finished in 0,060 s
21/03/20 14:51:46 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:51:46 INFO DAGScheduler: running: Set()
21/03/20 14:51:46 INFO DAGScheduler: waiting: Set(ResultStage 33)
21/03/20 14:51:46 INFO DAGScheduler: failed: Set()
21/03/20 14:51:46 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[108] at count at utils.scala:135), which has no missing parents
21/03/20 14:51:46 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:51:46 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:51:46 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:51:46 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[108] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:51:46 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
21/03/20 14:51:46 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 33, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:51:46 INFO Executor: Running task 0.0 in stage 33.0 (TID 33)
21/03/20 14:51:46 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:51:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:51:46 INFO Executor: Finished task 0.0 in stage 33.0 (TID 33). 2605 bytes result sent to driver
21/03/20 14:51:46 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 33) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:51:46 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
21/03/20 14:51:46 INFO DAGScheduler: ResultStage 33 (count at utils.scala:135) finished in 0,028 s
21/03/20 14:51:46 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:51:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
21/03/20 14:51:46 INFO DAGScheduler: Job 21 finished: count at utils.scala:135, took 0,100438 s
21/03/20 14:51:46 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:51:46 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:51:46 INFO SparkContext: Starting job: aggregate at samplingutils.scala:37
21/03/20 14:51:46 INFO DAGScheduler: Got job 22 (aggregate at samplingutils.scala:37) with 1 output partitions
21/03/20 14:51:46 INFO DAGScheduler: Final stage: ResultStage 34 (aggregate at samplingutils.scala:37)
21/03/20 14:51:46 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:51:46 INFO DAGScheduler: Missing parents: List()
21/03/20 14:51:46 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[112] at rdd at <unknown>:0), which has no missing parents
21/03/20 14:51:46 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 14.1 KiB, free 413.9 MiB)
21/03/20 14:51:46 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 413.9 MiB)
21/03/20 14:51:46 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:49848 (size: 7.0 KiB, free: 413.9 MiB)
21/03/20 14:51:46 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[112] at rdd at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/03/20 14:51:46 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
21/03/20 14:51:46 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 34, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 14:51:46 INFO Executor: Running task 0.0 in stage 34.0 (TID 34)
21/03/20 14:51:46 INFO Executor: Finished task 0.0 in stage 34.0 (TID 34). 4704 bytes result sent to driver
21/03/20 14:51:46 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 34) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:51:46 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
21/03/20 14:51:46 INFO DAGScheduler: ResultStage 34 (aggregate at samplingutils.scala:37) finished in 0,033 s
21/03/20 14:51:46 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:51:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
21/03/20 14:51:46 INFO DAGScheduler: Job 22 finished: aggregate at samplingutils.scala:37, took 0,041093 s
21/03/20 14:51:47 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:49848 in memory (size: 7.0 KiB, free: 413.9 MiB)
21/03/20 14:51:47 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:51:47 INFO DAGScheduler: Got job 23 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:51:47 INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:137)
21/03/20 14:51:47 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:51:47 INFO DAGScheduler: Missing parents: List()
21/03/20 14:51:47 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[116] at collect at utils.scala:137), which has no missing parents
21/03/20 14:51:47 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 7.1 KiB, free 413.9 MiB)
21/03/20 14:51:47 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 413.9 MiB)
21/03/20 14:51:47 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:49848 (size: 3.6 KiB, free: 413.9 MiB)
21/03/20 14:51:47 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[116] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:51:47 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
21/03/20 14:51:47 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 35, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 14:51:47 INFO Executor: Running task 0.0 in stage 35.0 (TID 35)
21/03/20 14:51:47 INFO Executor: Finished task 0.0 in stage 35.0 (TID 35). 1311 bytes result sent to driver
21/03/20 14:51:47 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 35) in 8 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:51:47 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
21/03/20 14:51:47 INFO DAGScheduler: ResultStage 35 (collect at utils.scala:137) finished in 0,016 s
21/03/20 14:51:47 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:51:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
21/03/20 14:51:47 INFO DAGScheduler: Job 23 finished: collect at utils.scala:137, took 0,024119 s
21/03/20 14:51:47 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:51:47 INFO DAGScheduler: Registering RDD 118 (count at utils.scala:135) as input to shuffle 13
21/03/20 14:51:47 INFO DAGScheduler: Got job 24 (count at utils.scala:135) with 1 output partitions
21/03/20 14:51:47 INFO DAGScheduler: Final stage: ResultStage 37 (count at utils.scala:135)
21/03/20 14:51:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
21/03/20 14:51:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 36)
21/03/20 14:51:47 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[118] at count at utils.scala:135), which has no missing parents
21/03/20 14:51:47 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:51:47 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:49848 in memory (size: 3.6 KiB, free: 413.9 MiB)
21/03/20 14:51:47 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:51:47 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:51:47 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[118] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:51:47 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
21/03/20 14:51:47 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 36, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 14:51:47 INFO Executor: Running task 0.0 in stage 36.0 (TID 36)
21/03/20 14:51:47 INFO Executor: Finished task 0.0 in stage 36.0 (TID 36). 1747 bytes result sent to driver
21/03/20 14:51:47 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 36) in 36 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:51:47 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
21/03/20 14:51:47 INFO DAGScheduler: ShuffleMapStage 36 (count at utils.scala:135) finished in 0,064 s
21/03/20 14:51:47 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:51:47 INFO DAGScheduler: running: Set()
21/03/20 14:51:47 INFO DAGScheduler: waiting: Set(ResultStage 37)
21/03/20 14:51:47 INFO DAGScheduler: failed: Set()
21/03/20 14:51:47 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[121] at count at utils.scala:135), which has no missing parents
21/03/20 14:51:47 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:51:47 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:51:47 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:51:47 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[121] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:51:47 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
21/03/20 14:51:47 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 37, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:51:47 INFO Executor: Running task 0.0 in stage 37.0 (TID 37)
21/03/20 14:51:47 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:51:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:51:47 INFO Executor: Finished task 0.0 in stage 37.0 (TID 37). 2562 bytes result sent to driver
21/03/20 14:51:47 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 37) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:51:47 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
21/03/20 14:51:47 INFO DAGScheduler: ResultStage 37 (count at utils.scala:135) finished in 0,028 s
21/03/20 14:51:47 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:51:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
21/03/20 14:51:47 INFO DAGScheduler: Job 24 finished: count at utils.scala:135, took 0,106959 s
21/03/20 14:51:47 INFO CodeGenerator: Code generated in 13.2088 ms
21/03/20 14:51:47 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:51:47 INFO DAGScheduler: Got job 25 (collect at utils.scala:137) with 8 output partitions
21/03/20 14:51:47 INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:137)
21/03/20 14:51:47 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:51:47 INFO DAGScheduler: Missing parents: List()
21/03/20 14:51:47 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[123] at collect at utils.scala:137), which has no missing parents
21/03/20 14:51:47 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 10.8 KiB, free 413.9 MiB)
21/03/20 14:51:47 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:51:47 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:51:47 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:51:47 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:47 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 38 (MapPartitionsRDD[123] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
21/03/20 14:51:47 INFO TaskSchedulerImpl: Adding task set 38.0 with 8 tasks
21/03/20 14:51:47 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 38, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8573 bytes)
21/03/20 14:51:47 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:51:47 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 39, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 8573 bytes)
21/03/20 14:51:47 INFO TaskSetManager: Starting task 2.0 in stage 38.0 (TID 40, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 8573 bytes)
21/03/20 14:51:47 INFO TaskSetManager: Starting task 3.0 in stage 38.0 (TID 41, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 8573 bytes)
21/03/20 14:51:47 INFO TaskSetManager: Starting task 4.0 in stage 38.0 (TID 42, 127.0.0.1, executor driver, partition 4, PROCESS_LOCAL, 8573 bytes)
21/03/20 14:51:47 INFO TaskSetManager: Starting task 5.0 in stage 38.0 (TID 43, 127.0.0.1, executor driver, partition 5, PROCESS_LOCAL, 8573 bytes)
21/03/20 14:51:47 INFO TaskSetManager: Starting task 6.0 in stage 38.0 (TID 44, 127.0.0.1, executor driver, partition 6, PROCESS_LOCAL, 8573 bytes)
21/03/20 14:51:47 INFO TaskSetManager: Starting task 7.0 in stage 38.0 (TID 45, 127.0.0.1, executor driver, partition 7, PROCESS_LOCAL, 8573 bytes)
21/03/20 14:51:47 INFO Executor: Running task 0.0 in stage 38.0 (TID 38)
21/03/20 14:51:47 INFO Executor: Running task 1.0 in stage 38.0 (TID 39)
21/03/20 14:51:47 INFO Executor: Running task 3.0 in stage 38.0 (TID 41)
21/03/20 14:51:47 INFO Executor: Running task 2.0 in stage 38.0 (TID 40)
21/03/20 14:51:47 INFO Executor: Running task 4.0 in stage 38.0 (TID 42)
21/03/20 14:51:47 INFO Executor: Running task 5.0 in stage 38.0 (TID 43)
21/03/20 14:51:47 INFO Executor: Running task 6.0 in stage 38.0 (TID 44)
21/03/20 14:51:47 INFO Executor: Running task 7.0 in stage 38.0 (TID 45)
21/03/20 14:51:47 INFO CodeGenerator: Code generated in 38.7487 ms
21/03/20 14:51:47 INFO Executor: Finished task 4.0 in stage 38.0 (TID 42). 1434 bytes result sent to driver
21/03/20 14:51:47 INFO Executor: Finished task 1.0 in stage 38.0 (TID 39). 1443 bytes result sent to driver
21/03/20 14:51:47 INFO Executor: Finished task 5.0 in stage 38.0 (TID 43). 1438 bytes result sent to driver
21/03/20 14:51:47 INFO Executor: Finished task 3.0 in stage 38.0 (TID 41). 1444 bytes result sent to driver
21/03/20 14:51:47 INFO Executor: Finished task 7.0 in stage 38.0 (TID 45). 1437 bytes result sent to driver
21/03/20 14:51:47 INFO Executor: Finished task 6.0 in stage 38.0 (TID 44). 1441 bytes result sent to driver
21/03/20 14:51:47 INFO Executor: Finished task 0.0 in stage 38.0 (TID 38). 1439 bytes result sent to driver
21/03/20 14:51:47 INFO Executor: Finished task 2.0 in stage 38.0 (TID 40). 1446 bytes result sent to driver
21/03/20 14:51:47 INFO TaskSetManager: Finished task 4.0 in stage 38.0 (TID 42) in 188 ms on 127.0.0.1 (executor driver) (1/8)
21/03/20 14:51:47 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 39) in 192 ms on 127.0.0.1 (executor driver) (2/8)
21/03/20 14:51:47 INFO TaskSetManager: Finished task 5.0 in stage 38.0 (TID 43) in 188 ms on 127.0.0.1 (executor driver) (3/8)
21/03/20 14:51:47 INFO TaskSetManager: Finished task 3.0 in stage 38.0 (TID 41) in 192 ms on 127.0.0.1 (executor driver) (4/8)
21/03/20 14:51:47 INFO TaskSetManager: Finished task 7.0 in stage 38.0 (TID 45) in 184 ms on 127.0.0.1 (executor driver) (5/8)
21/03/20 14:51:47 INFO TaskSetManager: Finished task 6.0 in stage 38.0 (TID 44) in 188 ms on 127.0.0.1 (executor driver) (6/8)
21/03/20 14:51:47 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 38) in 204 ms on 127.0.0.1 (executor driver) (7/8)
21/03/20 14:51:47 INFO TaskSetManager: Finished task 2.0 in stage 38.0 (TID 40) in 200 ms on 127.0.0.1 (executor driver) (8/8)
21/03/20 14:51:47 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
21/03/20 14:51:47 INFO DAGScheduler: ResultStage 38 (collect at utils.scala:137) finished in 0,240 s
21/03/20 14:51:47 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:51:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
21/03/20 14:51:47 INFO DAGScheduler: Job 25 finished: collect at utils.scala:137, took 0,250275 s
21/03/20 14:51:47 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:51:48 INFO CodeGenerator: Code generated in 21.4051 ms
21/03/20 14:51:48 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:51:48 INFO DAGScheduler: Registering RDD 125 (count at utils.scala:135) as input to shuffle 14
21/03/20 14:51:48 INFO DAGScheduler: Got job 26 (count at utils.scala:135) with 1 output partitions
21/03/20 14:51:48 INFO DAGScheduler: Final stage: ResultStage 40 (count at utils.scala:135)
21/03/20 14:51:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
21/03/20 14:51:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 39)
21/03/20 14:51:48 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[125] at count at utils.scala:135), which has no missing parents
21/03/20 14:51:48 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 14.1 KiB, free 413.9 MiB)
21/03/20 14:51:48 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 413.9 MiB)
21/03/20 14:51:48 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:49848 (size: 6.7 KiB, free: 413.9 MiB)
21/03/20 14:51:48 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:48 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[125] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
21/03/20 14:51:48 INFO TaskSchedulerImpl: Adding task set 39.0 with 8 tasks
21/03/20 14:51:48 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 46, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8562 bytes)
21/03/20 14:51:48 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 47, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 8562 bytes)
21/03/20 14:51:48 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 48, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 8562 bytes)
21/03/20 14:51:48 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 49, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 8562 bytes)
21/03/20 14:51:48 INFO TaskSetManager: Starting task 4.0 in stage 39.0 (TID 50, 127.0.0.1, executor driver, partition 4, PROCESS_LOCAL, 8562 bytes)
21/03/20 14:51:48 INFO TaskSetManager: Starting task 5.0 in stage 39.0 (TID 51, 127.0.0.1, executor driver, partition 5, PROCESS_LOCAL, 8562 bytes)
21/03/20 14:51:48 INFO TaskSetManager: Starting task 6.0 in stage 39.0 (TID 52, 127.0.0.1, executor driver, partition 6, PROCESS_LOCAL, 8562 bytes)
21/03/20 14:51:48 INFO TaskSetManager: Starting task 7.0 in stage 39.0 (TID 53, 127.0.0.1, executor driver, partition 7, PROCESS_LOCAL, 8562 bytes)
21/03/20 14:51:48 INFO Executor: Running task 0.0 in stage 39.0 (TID 46)
21/03/20 14:51:48 INFO Executor: Running task 3.0 in stage 39.0 (TID 49)
21/03/20 14:51:48 INFO Executor: Running task 7.0 in stage 39.0 (TID 53)
21/03/20 14:51:48 INFO Executor: Running task 1.0 in stage 39.0 (TID 47)
21/03/20 14:51:48 INFO Executor: Running task 2.0 in stage 39.0 (TID 48)
21/03/20 14:51:48 INFO Executor: Running task 5.0 in stage 39.0 (TID 51)
21/03/20 14:51:48 INFO Executor: Running task 6.0 in stage 39.0 (TID 52)
21/03/20 14:51:48 INFO Executor: Running task 4.0 in stage 39.0 (TID 50)
21/03/20 14:51:48 INFO Executor: Finished task 4.0 in stage 39.0 (TID 50). 1876 bytes result sent to driver
21/03/20 14:51:48 INFO TaskSetManager: Finished task 4.0 in stage 39.0 (TID 50) in 80 ms on 127.0.0.1 (executor driver) (1/8)
21/03/20 14:51:48 INFO Executor: Finished task 1.0 in stage 39.0 (TID 47). 1833 bytes result sent to driver
21/03/20 14:51:48 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 47) in 92 ms on 127.0.0.1 (executor driver) (2/8)
21/03/20 14:51:48 INFO Executor: Finished task 3.0 in stage 39.0 (TID 49). 1833 bytes result sent to driver
21/03/20 14:51:48 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 49) in 92 ms on 127.0.0.1 (executor driver) (3/8)
21/03/20 14:51:48 INFO Executor: Finished task 0.0 in stage 39.0 (TID 46). 1833 bytes result sent to driver
21/03/20 14:51:48 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 46) in 104 ms on 127.0.0.1 (executor driver) (4/8)
21/03/20 14:51:48 INFO Executor: Finished task 2.0 in stage 39.0 (TID 48). 1833 bytes result sent to driver
21/03/20 14:51:48 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 48) in 108 ms on 127.0.0.1 (executor driver) (5/8)
21/03/20 14:51:48 INFO Executor: Finished task 7.0 in stage 39.0 (TID 53). 1833 bytes result sent to driver
21/03/20 14:51:48 INFO TaskSetManager: Finished task 7.0 in stage 39.0 (TID 53) in 108 ms on 127.0.0.1 (executor driver) (6/8)
21/03/20 14:51:48 INFO Executor: Finished task 5.0 in stage 39.0 (TID 51). 1833 bytes result sent to driver
21/03/20 14:51:48 INFO TaskSetManager: Finished task 5.0 in stage 39.0 (TID 51) in 144 ms on 127.0.0.1 (executor driver) (7/8)
21/03/20 14:51:48 INFO Executor: Finished task 6.0 in stage 39.0 (TID 52). 1876 bytes result sent to driver
21/03/20 14:51:48 INFO TaskSetManager: Finished task 6.0 in stage 39.0 (TID 52) in 156 ms on 127.0.0.1 (executor driver) (8/8)
21/03/20 14:51:48 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
21/03/20 14:51:48 INFO DAGScheduler: ShuffleMapStage 39 (count at utils.scala:135) finished in 0,176 s
21/03/20 14:51:48 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:51:48 INFO DAGScheduler: running: Set()
21/03/20 14:51:48 INFO DAGScheduler: waiting: Set(ResultStage 40)
21/03/20 14:51:48 INFO DAGScheduler: failed: Set()
21/03/20 14:51:48 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[128] at count at utils.scala:135), which has no missing parents
21/03/20 14:51:48 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:51:48 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:51:48 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:51:48 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1223
21/03/20 14:51:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[128] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:51:48 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
21/03/20 14:51:48 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 54, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:51:48 INFO Executor: Running task 0.0 in stage 40.0 (TID 54)
21/03/20 14:51:48 INFO ShuffleBlockFetcherIterator: Getting 8 (480.0 B) non-empty blocks including 8 (480.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:51:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:51:48 INFO Executor: Finished task 0.0 in stage 40.0 (TID 54). 2605 bytes result sent to driver
21/03/20 14:51:48 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 54) in 36 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:51:48 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
21/03/20 14:51:48 INFO DAGScheduler: ResultStage 40 (count at utils.scala:135) finished in 0,048 s
21/03/20 14:51:48 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:51:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
21/03/20 14:51:48 INFO DAGScheduler: Job 26 finished: count at utils.scala:135, took 0,241175 s
21/03/20 14:55:35 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:55:35 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:49848 in memory (size: 6.7 KiB, free: 413.9 MiB)
21/03/20 14:55:35 INFO Instrumentation: [5cd57720] training finished
21/03/20 14:55:35 INFO Instrumentation: [7b862ba6] training finished
21/03/20 14:55:35 INFO CodeGenerator: Code generated in 79.2392 ms
21/03/20 14:55:35 INFO Instrumentation: [4a0b1805] Stage class: LinearRegression
21/03/20 14:55:35 INFO Instrumentation: [4a0b1805] Stage uid: linear_regression__45eef3f5_2c9a_437b_9022_4ad9abbd0993
21/03/20 14:55:36 INFO CodeGenerator: Code generated in 40.5773 ms
21/03/20 14:55:36 INFO Instrumentation: [4a0b1805] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
21/03/20 14:55:36 INFO Instrumentation: [4a0b1805] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
21/03/20 14:55:36 INFO Instrumentation: [4a0b1805] {"numFeatures":1}
21/03/20 14:55:36 WARN Instrumentation: [4a0b1805] regParam is zero, which might cause numerical instability and overfitting.
21/03/20 14:55:36 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
21/03/20 14:55:36 INFO DAGScheduler: Got job 27 (treeAggregate at WeightedLeastSquares.scala:107) with 1 output partitions
21/03/20 14:55:36 INFO DAGScheduler: Final stage: ResultStage 41 (treeAggregate at WeightedLeastSquares.scala:107)
21/03/20 14:55:36 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:55:36 INFO DAGScheduler: Missing parents: List()
21/03/20 14:55:36 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[144] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
21/03/20 14:55:36 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 44.0 KiB, free 413.9 MiB)
21/03/20 14:55:36 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 413.9 MiB)
21/03/20 14:55:36 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:49848 (size: 17.2 KiB, free: 413.9 MiB)
21/03/20 14:55:36 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1223
21/03/20 14:55:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[144] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0))
21/03/20 14:55:36 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
21/03/20 14:55:36 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 55, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 14:55:36 INFO Executor: Running task 0.0 in stage 41.0 (TID 55)
21/03/20 14:55:36 INFO BlockManager: Found block rdd_23_0 locally
21/03/20 14:55:36 INFO CodeGenerator: Code generated in 14.4312 ms
21/03/20 14:55:36 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
21/03/20 14:55:36 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
21/03/20 14:55:37 INFO Executor: Finished task 0.0 in stage 41.0 (TID 55). 2032 bytes result sent to driver
21/03/20 14:55:37 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 55) in 206 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:55:37 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
21/03/20 14:55:37 INFO DAGScheduler: ResultStage 41 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0,334 s
21/03/20 14:55:37 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:55:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
21/03/20 14:55:37 INFO DAGScheduler: Job 27 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0,344586 s
21/03/20 14:55:37 INFO Instrumentation: [4a0b1805] Number of instances: 32.
21/03/20 14:55:37 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
21/03/20 14:55:37 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
21/03/20 14:55:37 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:49848 in memory (size: 17.2 KiB, free: 413.9 MiB)
21/03/20 14:55:37 INFO CodeGenerator: Code generated in 28.3656 ms
21/03/20 14:55:37 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
21/03/20 14:55:37 INFO DAGScheduler: Got job 28 (treeAggregate at Statistics.scala:58) with 1 output partitions
21/03/20 14:55:37 INFO DAGScheduler: Final stage: ResultStage 42 (treeAggregate at Statistics.scala:58)
21/03/20 14:55:37 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:55:37 INFO DAGScheduler: Missing parents: List()
21/03/20 14:55:37 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[154] at treeAggregate at Statistics.scala:58), which has no missing parents
21/03/20 14:55:37 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 46.9 KiB, free 413.9 MiB)
21/03/20 14:55:37 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 413.9 MiB)
21/03/20 14:55:37 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:49848 (size: 19.1 KiB, free: 413.9 MiB)
21/03/20 14:55:37 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1223
21/03/20 14:55:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[154] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0))
21/03/20 14:55:37 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
21/03/20 14:55:37 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 56, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 14:55:37 INFO Executor: Running task 0.0 in stage 42.0 (TID 56)
21/03/20 14:55:37 INFO BlockManager: Found block rdd_23_0 locally
21/03/20 14:55:37 INFO CodeGenerator: Code generated in 13.8316 ms
21/03/20 14:55:37 INFO Executor: Finished task 0.0 in stage 42.0 (TID 56). 2877 bytes result sent to driver
21/03/20 14:55:37 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 56) in 131 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:55:37 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
21/03/20 14:55:37 INFO DAGScheduler: ResultStage 42 (treeAggregate at Statistics.scala:58) finished in 0,155 s
21/03/20 14:55:37 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:55:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
21/03/20 14:55:37 INFO DAGScheduler: Job 28 finished: treeAggregate at Statistics.scala:58, took 0,163815 s
21/03/20 14:55:37 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:49848 in memory (size: 19.1 KiB, free: 413.9 MiB)
21/03/20 14:55:37 INFO CodeGenerator: Code generated in 16.0087 ms
21/03/20 14:55:37 INFO SparkContext: Starting job: count at LinearRegression.scala:927
21/03/20 14:55:37 INFO DAGScheduler: Registering RDD 159 (count at LinearRegression.scala:927) as input to shuffle 15
21/03/20 14:55:37 INFO DAGScheduler: Got job 29 (count at LinearRegression.scala:927) with 1 output partitions
21/03/20 14:55:37 INFO DAGScheduler: Final stage: ResultStage 44 (count at LinearRegression.scala:927)
21/03/20 14:55:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
21/03/20 14:55:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)
21/03/20 14:55:37 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[159] at count at LinearRegression.scala:927), which has no missing parents
21/03/20 14:55:37 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 26.3 KiB, free 413.9 MiB)
21/03/20 14:55:37 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 413.9 MiB)
21/03/20 14:55:37 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:49848 (size: 10.7 KiB, free: 413.9 MiB)
21/03/20 14:55:37 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1223
21/03/20 14:55:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[159] at count at LinearRegression.scala:927) (first 15 tasks are for partitions Vector(0))
21/03/20 14:55:37 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
21/03/20 14:55:37 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 57, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 14:55:37 INFO Executor: Running task 0.0 in stage 43.0 (TID 57)
21/03/20 14:55:37 INFO BlockManager: Found block rdd_23_0 locally
21/03/20 14:55:38 INFO Executor: Finished task 0.0 in stage 43.0 (TID 57). 2231 bytes result sent to driver
21/03/20 14:55:38 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 57) in 40 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:55:38 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
21/03/20 14:55:38 INFO DAGScheduler: ShuffleMapStage 43 (count at LinearRegression.scala:927) finished in 0,060 s
21/03/20 14:55:38 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:55:38 INFO DAGScheduler: running: Set()
21/03/20 14:55:38 INFO DAGScheduler: waiting: Set(ResultStage 44)
21/03/20 14:55:38 INFO DAGScheduler: failed: Set()
21/03/20 14:55:38 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[162] at count at LinearRegression.scala:927), which has no missing parents
21/03/20 14:55:38 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:55:38 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:55:38 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:55:38 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1223
21/03/20 14:55:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[162] at count at LinearRegression.scala:927) (first 15 tasks are for partitions Vector(0))
21/03/20 14:55:38 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
21/03/20 14:55:38 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 58, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:55:38 INFO Executor: Running task 0.0 in stage 44.0 (TID 58)
21/03/20 14:55:38 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:55:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:55:38 INFO Executor: Finished task 0.0 in stage 44.0 (TID 58). 2562 bytes result sent to driver
21/03/20 14:55:38 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 58) in 20 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:55:38 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
21/03/20 14:55:38 INFO DAGScheduler: ResultStage 44 (count at LinearRegression.scala:927) finished in 0,032 s
21/03/20 14:55:38 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:55:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
21/03/20 14:55:38 INFO DAGScheduler: Job 29 finished: count at LinearRegression.scala:927, took 0,102281 s
21/03/20 14:55:38 INFO Instrumentation: [7b578817] training finished
21/03/20 14:55:38 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:55:38 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:49848 in memory (size: 10.7 KiB, free: 413.9 MiB)
21/03/20 14:55:38 INFO CodeGenerator: Code generated in 15.5599 ms
21/03/20 14:55:38 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:55:38 INFO DAGScheduler: Got job 30 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:55:38 INFO DAGScheduler: Final stage: ResultStage 45 (collect at utils.scala:137)
21/03/20 14:55:38 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:55:38 INFO DAGScheduler: Missing parents: List()
21/03/20 14:55:38 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[164] at collect at utils.scala:137), which has no missing parents
21/03/20 14:55:38 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 7.6 KiB, free 413.9 MiB)
21/03/20 14:55:38 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 413.9 MiB)
21/03/20 14:55:38 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:49848 (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 14:55:38 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1223
21/03/20 14:55:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[164] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:55:38 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
21/03/20 14:55:38 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 59, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 14:55:38 INFO Executor: Running task 0.0 in stage 45.0 (TID 59)
21/03/20 14:55:38 INFO Executor: Finished task 0.0 in stage 45.0 (TID 59). 1311 bytes result sent to driver
21/03/20 14:55:38 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 59) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:55:38 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
21/03/20 14:55:38 INFO DAGScheduler: ResultStage 45 (collect at utils.scala:137) finished in 0,028 s
21/03/20 14:55:38 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:55:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
21/03/20 14:55:38 INFO DAGScheduler: Job 30 finished: collect at utils.scala:137, took 0,036548 s
21/03/20 14:55:38 INFO CodeGenerator: Code generated in 13.1663 ms
21/03/20 14:55:38 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:49848 in memory (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 14:55:38 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:55:38 INFO DAGScheduler: Registering RDD 166 (count at utils.scala:135) as input to shuffle 16
21/03/20 14:55:38 INFO DAGScheduler: Got job 31 (count at utils.scala:135) with 1 output partitions
21/03/20 14:55:38 INFO DAGScheduler: Final stage: ResultStage 47 (count at utils.scala:135)
21/03/20 14:55:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
21/03/20 14:55:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 46)
21/03/20 14:55:38 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[166] at count at utils.scala:135), which has no missing parents
21/03/20 14:55:38 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:55:38 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:55:38 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:55:38 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1223
21/03/20 14:55:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[166] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:55:38 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
21/03/20 14:55:38 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 60, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 14:55:38 INFO Executor: Running task 0.0 in stage 46.0 (TID 60)
21/03/20 14:55:38 INFO Executor: Finished task 0.0 in stage 46.0 (TID 60). 1790 bytes result sent to driver
21/03/20 14:55:38 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 60) in 32 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:55:38 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
21/03/20 14:55:38 INFO DAGScheduler: ShuffleMapStage 46 (count at utils.scala:135) finished in 0,044 s
21/03/20 14:55:38 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:55:38 INFO DAGScheduler: running: Set()
21/03/20 14:55:38 INFO DAGScheduler: waiting: Set(ResultStage 47)
21/03/20 14:55:38 INFO DAGScheduler: failed: Set()
21/03/20 14:55:38 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[169] at count at utils.scala:135), which has no missing parents
21/03/20 14:55:38 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:55:38 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:55:38 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:55:38 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1223
21/03/20 14:55:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[169] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:55:39 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
21/03/20 14:55:39 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 61, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:55:39 INFO Executor: Running task 0.0 in stage 47.0 (TID 61)
21/03/20 14:55:39 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:55:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:55:39 INFO Executor: Finished task 0.0 in stage 47.0 (TID 61). 2605 bytes result sent to driver
21/03/20 14:55:39 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 61) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:55:39 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
21/03/20 14:55:39 INFO DAGScheduler: ResultStage 47 (count at utils.scala:135) finished in 0,032 s
21/03/20 14:55:39 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:55:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
21/03/20 14:55:39 INFO DAGScheduler: Job 31 finished: count at utils.scala:135, took 0,087903 s
21/03/20 14:55:39 INFO Instrumentation: [3d371f33] training finished
21/03/20 14:55:39 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:55:39 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:55:40 INFO CodeGenerator: Code generated in 12.4013 ms
21/03/20 14:55:40 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:55:40 INFO DAGScheduler: Got job 32 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:55:40 INFO DAGScheduler: Final stage: ResultStage 48 (collect at utils.scala:137)
21/03/20 14:55:40 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:55:40 INFO DAGScheduler: Missing parents: List()
21/03/20 14:55:40 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[171] at collect at utils.scala:137), which has no missing parents
21/03/20 14:55:40 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 7.6 KiB, free 413.9 MiB)
21/03/20 14:55:40 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 413.9 MiB)
21/03/20 14:55:40 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:49848 (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 14:55:40 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1223
21/03/20 14:55:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[171] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:55:40 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
21/03/20 14:55:40 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 62, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 14:55:40 INFO Executor: Running task 0.0 in stage 48.0 (TID 62)
21/03/20 14:55:40 INFO Executor: Finished task 0.0 in stage 48.0 (TID 62). 1354 bytes result sent to driver
21/03/20 14:55:40 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 62) in 12 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:55:40 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
21/03/20 14:55:40 INFO DAGScheduler: ResultStage 48 (collect at utils.scala:137) finished in 0,028 s
21/03/20 14:55:40 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:55:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
21/03/20 14:55:40 INFO DAGScheduler: Job 32 finished: collect at utils.scala:137, took 0,035229 s
21/03/20 14:55:40 INFO CodeGenerator: Code generated in 15.8152 ms
21/03/20 14:55:40 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:49848 in memory (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 14:55:40 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:55:40 INFO DAGScheduler: Registering RDD 173 (count at utils.scala:135) as input to shuffle 17
21/03/20 14:55:40 INFO DAGScheduler: Got job 33 (count at utils.scala:135) with 1 output partitions
21/03/20 14:55:40 INFO DAGScheduler: Final stage: ResultStage 50 (count at utils.scala:135)
21/03/20 14:55:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
21/03/20 14:55:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 49)
21/03/20 14:55:40 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[173] at count at utils.scala:135), which has no missing parents
21/03/20 14:55:40 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:55:40 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:55:40 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:55:40 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1223
21/03/20 14:55:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[173] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:55:40 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
21/03/20 14:55:40 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 63, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 14:55:40 INFO Executor: Running task 0.0 in stage 49.0 (TID 63)
21/03/20 14:55:40 INFO Executor: Finished task 0.0 in stage 49.0 (TID 63). 1790 bytes result sent to driver
21/03/20 14:55:40 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 63) in 28 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:55:40 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
21/03/20 14:55:40 INFO DAGScheduler: ShuffleMapStage 49 (count at utils.scala:135) finished in 0,041 s
21/03/20 14:55:40 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:55:40 INFO DAGScheduler: running: Set()
21/03/20 14:55:40 INFO DAGScheduler: waiting: Set(ResultStage 50)
21/03/20 14:55:40 INFO DAGScheduler: failed: Set()
21/03/20 14:55:40 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[176] at count at utils.scala:135), which has no missing parents
21/03/20 14:55:40 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:55:40 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:55:40 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:55:40 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1223
21/03/20 14:55:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[176] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:55:40 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
21/03/20 14:55:40 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 64, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:55:40 INFO Executor: Running task 0.0 in stage 50.0 (TID 64)
21/03/20 14:55:40 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:55:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:55:40 INFO Executor: Finished task 0.0 in stage 50.0 (TID 64). 2605 bytes result sent to driver
21/03/20 14:55:40 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 64) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:55:40 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
21/03/20 14:55:40 INFO DAGScheduler: ResultStage 50 (count at utils.scala:135) finished in 0,032 s
21/03/20 14:55:40 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:55:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
21/03/20 14:55:40 INFO DAGScheduler: Job 33 finished: count at utils.scala:135, took 0,083091 s
21/03/20 14:55:41 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:55:41 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:55:41 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:55:41 INFO DAGScheduler: Got job 34 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:55:41 INFO DAGScheduler: Final stage: ResultStage 51 (collect at utils.scala:137)
21/03/20 14:55:41 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:55:41 INFO DAGScheduler: Missing parents: List()
21/03/20 14:55:41 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[178] at collect at utils.scala:137), which has no missing parents
21/03/20 14:55:41 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 7.6 KiB, free 413.9 MiB)
21/03/20 14:55:41 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 413.9 MiB)
21/03/20 14:55:41 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:49848 (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 14:55:41 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1223
21/03/20 14:55:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[178] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:55:41 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
21/03/20 14:55:41 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 65, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 14:55:41 INFO Executor: Running task 0.0 in stage 51.0 (TID 65)
21/03/20 14:55:41 INFO Executor: Finished task 0.0 in stage 51.0 (TID 65). 1311 bytes result sent to driver
21/03/20 14:55:41 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 65) in 8 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:55:41 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
21/03/20 14:55:41 INFO DAGScheduler: ResultStage 51 (collect at utils.scala:137) finished in 0,020 s
21/03/20 14:55:41 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:55:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
21/03/20 14:55:41 INFO DAGScheduler: Job 34 finished: collect at utils.scala:137, took 0,023831 s
21/03/20 14:55:41 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:49848 in memory (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 14:55:41 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:55:41 INFO DAGScheduler: Registering RDD 180 (count at utils.scala:135) as input to shuffle 18
21/03/20 14:55:41 INFO DAGScheduler: Got job 35 (count at utils.scala:135) with 1 output partitions
21/03/20 14:55:41 INFO DAGScheduler: Final stage: ResultStage 53 (count at utils.scala:135)
21/03/20 14:55:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
21/03/20 14:55:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 52)
21/03/20 14:55:41 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[180] at count at utils.scala:135), which has no missing parents
21/03/20 14:55:41 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:55:41 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:55:41 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:55:41 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1223
21/03/20 14:55:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[180] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:55:41 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
21/03/20 14:55:41 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 66, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 14:55:41 INFO Executor: Running task 0.0 in stage 52.0 (TID 66)
21/03/20 14:55:41 INFO Executor: Finished task 0.0 in stage 52.0 (TID 66). 1833 bytes result sent to driver
21/03/20 14:55:41 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 66) in 28 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:55:41 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
21/03/20 14:55:41 INFO DAGScheduler: ShuffleMapStage 52 (count at utils.scala:135) finished in 0,044 s
21/03/20 14:55:41 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:55:41 INFO DAGScheduler: running: Set()
21/03/20 14:55:41 INFO DAGScheduler: waiting: Set(ResultStage 53)
21/03/20 14:55:41 INFO DAGScheduler: failed: Set()
21/03/20 14:55:41 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[183] at count at utils.scala:135), which has no missing parents
21/03/20 14:55:41 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:55:41 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:55:41 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:55:41 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1223
21/03/20 14:55:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[183] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:55:41 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
21/03/20 14:55:41 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 67, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:55:41 INFO Executor: Running task 0.0 in stage 53.0 (TID 67)
21/03/20 14:55:41 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:55:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:55:41 INFO Executor: Finished task 0.0 in stage 53.0 (TID 67). 2605 bytes result sent to driver
21/03/20 14:55:41 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 67) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:55:41 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
21/03/20 14:55:41 INFO DAGScheduler: ResultStage 53 (count at utils.scala:135) finished in 0,028 s
21/03/20 14:55:41 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:55:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
21/03/20 14:55:41 INFO DAGScheduler: Job 35 finished: count at utils.scala:135, took 0,086832 s
21/03/20 14:55:59 INFO Instrumentation: [aa7df2ac] training finished
21/03/20 14:55:59 INFO Instrumentation: [7fc5e707] training finished
21/03/20 14:55:59 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:55:59 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:55:59 INFO Instrumentation: [a21b8cae] Stage class: LinearRegression
21/03/20 14:55:59 INFO Instrumentation: [a21b8cae] Stage uid: linear_regression__dbf9e4c1_8451_4818_817f_21f6766118ac
21/03/20 14:55:59 INFO Instrumentation: [a21b8cae] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
21/03/20 14:55:59 INFO Instrumentation: [a21b8cae] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
21/03/20 14:55:59 INFO Instrumentation: [a21b8cae] {"numFeatures":1}
21/03/20 14:55:59 WARN Instrumentation: [a21b8cae] regParam is zero, which might cause numerical instability and overfitting.
21/03/20 14:55:59 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
21/03/20 14:55:59 INFO DAGScheduler: Got job 36 (treeAggregate at WeightedLeastSquares.scala:107) with 1 output partitions
21/03/20 14:55:59 INFO DAGScheduler: Final stage: ResultStage 54 (treeAggregate at WeightedLeastSquares.scala:107)
21/03/20 14:55:59 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:55:59 INFO DAGScheduler: Missing parents: List()
21/03/20 14:55:59 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[199] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
21/03/20 14:55:59 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 44.0 KiB, free 413.9 MiB)
21/03/20 14:55:59 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 413.9 MiB)
21/03/20 14:55:59 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:49848 (size: 17.2 KiB, free: 413.9 MiB)
21/03/20 14:55:59 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1223
21/03/20 14:55:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[199] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0))
21/03/20 14:55:59 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
21/03/20 14:55:59 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 68, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 14:55:59 INFO Executor: Running task 0.0 in stage 54.0 (TID 68)
21/03/20 14:55:59 INFO BlockManager: Found block rdd_23_0 locally
21/03/20 14:55:59 INFO Executor: Finished task 0.0 in stage 54.0 (TID 68). 1989 bytes result sent to driver
21/03/20 14:55:59 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 68) in 32 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:55:59 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
21/03/20 14:55:59 INFO DAGScheduler: ResultStage 54 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0,060 s
21/03/20 14:55:59 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:55:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
21/03/20 14:55:59 INFO DAGScheduler: Job 36 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0,069115 s
21/03/20 14:55:59 INFO Instrumentation: [a21b8cae] Number of instances: 32.
21/03/20 14:56:00 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:49848 in memory (size: 17.2 KiB, free: 413.9 MiB)
21/03/20 14:56:00 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
21/03/20 14:56:00 INFO DAGScheduler: Got job 37 (treeAggregate at Statistics.scala:58) with 1 output partitions
21/03/20 14:56:00 INFO DAGScheduler: Final stage: ResultStage 55 (treeAggregate at Statistics.scala:58)
21/03/20 14:56:00 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:56:00 INFO DAGScheduler: Missing parents: List()
21/03/20 14:56:00 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[209] at treeAggregate at Statistics.scala:58), which has no missing parents
21/03/20 14:56:00 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 46.9 KiB, free 413.9 MiB)
21/03/20 14:56:00 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 413.9 MiB)
21/03/20 14:56:00 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:49848 (size: 19.1 KiB, free: 413.9 MiB)
21/03/20 14:56:00 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1223
21/03/20 14:56:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[209] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0))
21/03/20 14:56:00 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
21/03/20 14:56:00 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 69, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 14:56:00 INFO Executor: Running task 0.0 in stage 55.0 (TID 69)
21/03/20 14:56:00 INFO BlockManager: Found block rdd_23_0 locally
21/03/20 14:56:00 INFO Executor: Finished task 0.0 in stage 55.0 (TID 69). 2834 bytes result sent to driver
21/03/20 14:56:00 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 69) in 32 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:56:00 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
21/03/20 14:56:00 INFO DAGScheduler: ResultStage 55 (treeAggregate at Statistics.scala:58) finished in 0,060 s
21/03/20 14:56:00 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:56:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
21/03/20 14:56:00 INFO DAGScheduler: Job 37 finished: treeAggregate at Statistics.scala:58, took 0,070080 s
21/03/20 14:56:00 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:49848 in memory (size: 19.1 KiB, free: 413.9 MiB)
21/03/20 14:56:00 INFO SparkContext: Starting job: count at LinearRegression.scala:927
21/03/20 14:56:00 INFO DAGScheduler: Registering RDD 214 (count at LinearRegression.scala:927) as input to shuffle 19
21/03/20 14:56:00 INFO DAGScheduler: Got job 38 (count at LinearRegression.scala:927) with 1 output partitions
21/03/20 14:56:00 INFO DAGScheduler: Final stage: ResultStage 57 (count at LinearRegression.scala:927)
21/03/20 14:56:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
21/03/20 14:56:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 56)
21/03/20 14:56:00 INFO DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[214] at count at LinearRegression.scala:927), which has no missing parents
21/03/20 14:56:00 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 26.3 KiB, free 413.9 MiB)
21/03/20 14:56:00 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 413.9 MiB)
21/03/20 14:56:00 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:49848 (size: 10.7 KiB, free: 413.9 MiB)
21/03/20 14:56:00 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1223
21/03/20 14:56:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[214] at count at LinearRegression.scala:927) (first 15 tasks are for partitions Vector(0))
21/03/20 14:56:00 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
21/03/20 14:56:00 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 70, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 14:56:00 INFO Executor: Running task 0.0 in stage 56.0 (TID 70)
21/03/20 14:56:00 INFO BlockManager: Found block rdd_23_0 locally
21/03/20 14:56:00 INFO Executor: Finished task 0.0 in stage 56.0 (TID 70). 2231 bytes result sent to driver
21/03/20 14:56:00 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 70) in 32 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:56:00 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
21/03/20 14:56:00 INFO DAGScheduler: ShuffleMapStage 56 (count at LinearRegression.scala:927) finished in 0,048 s
21/03/20 14:56:00 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:56:00 INFO DAGScheduler: running: Set()
21/03/20 14:56:00 INFO DAGScheduler: waiting: Set(ResultStage 57)
21/03/20 14:56:00 INFO DAGScheduler: failed: Set()
21/03/20 14:56:00 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[217] at count at LinearRegression.scala:927), which has no missing parents
21/03/20 14:56:00 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:56:00 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:56:00 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:56:00 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1223
21/03/20 14:56:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[217] at count at LinearRegression.scala:927) (first 15 tasks are for partitions Vector(0))
21/03/20 14:56:00 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
21/03/20 14:56:00 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 71, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:56:00 INFO Executor: Running task 0.0 in stage 57.0 (TID 71)
21/03/20 14:56:00 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:56:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:56:00 INFO Executor: Finished task 0.0 in stage 57.0 (TID 71). 2605 bytes result sent to driver
21/03/20 14:56:00 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 71) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:56:00 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
21/03/20 14:56:00 INFO DAGScheduler: ResultStage 57 (count at LinearRegression.scala:927) finished in 0,044 s
21/03/20 14:56:00 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:56:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
21/03/20 14:56:00 INFO DAGScheduler: Job 38 finished: count at LinearRegression.scala:927, took 0,098334 s
21/03/20 14:56:00 INFO Instrumentation: [b3c5bbe2] training finished
21/03/20 14:56:01 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:56:01 INFO DAGScheduler: Got job 39 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:56:01 INFO DAGScheduler: Final stage: ResultStage 58 (collect at utils.scala:137)
21/03/20 14:56:01 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:56:01 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:49848 in memory (size: 10.7 KiB, free: 413.9 MiB)
21/03/20 14:56:01 INFO DAGScheduler: Missing parents: List()
21/03/20 14:56:01 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[219] at collect at utils.scala:137), which has no missing parents
21/03/20 14:56:01 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 7.6 KiB, free 413.9 MiB)
21/03/20 14:56:01 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:56:01 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 413.9 MiB)
21/03/20 14:56:01 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:49848 (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 14:56:01 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1223
21/03/20 14:56:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[219] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:56:01 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
21/03/20 14:56:01 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 72, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 14:56:01 INFO Executor: Running task 0.0 in stage 58.0 (TID 72)
21/03/20 14:56:01 INFO Executor: Finished task 0.0 in stage 58.0 (TID 72). 1311 bytes result sent to driver
21/03/20 14:56:01 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 72) in 8 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:56:01 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
21/03/20 14:56:01 INFO DAGScheduler: ResultStage 58 (collect at utils.scala:137) finished in 0,024 s
21/03/20 14:56:01 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:56:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
21/03/20 14:56:01 INFO DAGScheduler: Job 39 finished: collect at utils.scala:137, took 0,031968 s
21/03/20 14:56:01 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:56:01 INFO DAGScheduler: Registering RDD 221 (count at utils.scala:135) as input to shuffle 20
21/03/20 14:56:01 INFO DAGScheduler: Got job 40 (count at utils.scala:135) with 1 output partitions
21/03/20 14:56:01 INFO DAGScheduler: Final stage: ResultStage 60 (count at utils.scala:135)
21/03/20 14:56:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
21/03/20 14:56:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 59)
21/03/20 14:56:01 INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[221] at count at utils.scala:135), which has no missing parents
21/03/20 14:56:01 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:56:01 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:56:01 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:56:01 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1223
21/03/20 14:56:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[221] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:56:01 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
21/03/20 14:56:01 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 73, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 14:56:01 INFO Executor: Running task 0.0 in stage 59.0 (TID 73)
21/03/20 14:56:01 INFO Executor: Finished task 0.0 in stage 59.0 (TID 73). 1833 bytes result sent to driver
21/03/20 14:56:01 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 73) in 32 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:56:01 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
21/03/20 14:56:01 INFO DAGScheduler: ShuffleMapStage 59 (count at utils.scala:135) finished in 0,044 s
21/03/20 14:56:01 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:56:01 INFO DAGScheduler: running: Set()
21/03/20 14:56:01 INFO DAGScheduler: waiting: Set(ResultStage 60)
21/03/20 14:56:01 INFO DAGScheduler: failed: Set()
21/03/20 14:56:01 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[224] at count at utils.scala:135), which has no missing parents
21/03/20 14:56:01 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:56:01 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:56:01 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:56:01 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:49848 in memory (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 14:56:01 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1223
21/03/20 14:56:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[224] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:56:01 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
21/03/20 14:56:01 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 74, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:56:01 INFO Executor: Running task 0.0 in stage 60.0 (TID 74)
21/03/20 14:56:01 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:56:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:56:01 INFO Executor: Finished task 0.0 in stage 60.0 (TID 74). 2605 bytes result sent to driver
21/03/20 14:56:01 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 74) in 20 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:56:01 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
21/03/20 14:56:01 INFO DAGScheduler: ResultStage 60 (count at utils.scala:135) finished in 0,052 s
21/03/20 14:56:01 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:56:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
21/03/20 14:56:01 INFO DAGScheduler: Job 40 finished: count at utils.scala:135, took 0,105244 s
21/03/20 14:56:02 INFO Instrumentation: [4630abc4] training finished
21/03/20 14:56:02 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:56:02 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:56:02 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:56:02 INFO DAGScheduler: Got job 41 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:56:02 INFO DAGScheduler: Final stage: ResultStage 61 (collect at utils.scala:137)
21/03/20 14:56:02 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:56:02 INFO DAGScheduler: Missing parents: List()
21/03/20 14:56:02 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[226] at collect at utils.scala:137), which has no missing parents
21/03/20 14:56:02 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 7.6 KiB, free 413.9 MiB)
21/03/20 14:56:02 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 413.9 MiB)
21/03/20 14:56:02 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:49848 (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 14:56:02 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1223
21/03/20 14:56:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[226] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:56:02 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
21/03/20 14:56:02 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 75, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 14:56:02 INFO Executor: Running task 0.0 in stage 61.0 (TID 75)
21/03/20 14:56:02 INFO Executor: Finished task 0.0 in stage 61.0 (TID 75). 1354 bytes result sent to driver
21/03/20 14:56:02 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 75) in 8 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:56:02 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
21/03/20 14:56:02 INFO DAGScheduler: ResultStage 61 (collect at utils.scala:137) finished in 0,023 s
21/03/20 14:56:02 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:56:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
21/03/20 14:56:02 INFO DAGScheduler: Job 41 finished: collect at utils.scala:137, took 0,026486 s
21/03/20 14:56:02 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:56:02 INFO DAGScheduler: Registering RDD 228 (count at utils.scala:135) as input to shuffle 21
21/03/20 14:56:02 INFO DAGScheduler: Got job 42 (count at utils.scala:135) with 1 output partitions
21/03/20 14:56:02 INFO DAGScheduler: Final stage: ResultStage 63 (count at utils.scala:135)
21/03/20 14:56:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
21/03/20 14:56:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)
21/03/20 14:56:02 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[228] at count at utils.scala:135), which has no missing parents
21/03/20 14:56:02 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:56:02 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:56:02 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:56:02 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:49848 in memory (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 14:56:02 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1223
21/03/20 14:56:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[228] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:56:02 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
21/03/20 14:56:02 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 76, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 14:56:02 INFO Executor: Running task 0.0 in stage 62.0 (TID 76)
21/03/20 14:56:02 INFO Executor: Finished task 0.0 in stage 62.0 (TID 76). 1790 bytes result sent to driver
21/03/20 14:56:02 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 76) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:56:02 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
21/03/20 14:56:02 INFO DAGScheduler: ShuffleMapStage 62 (count at utils.scala:135) finished in 0,060 s
21/03/20 14:56:02 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:56:02 INFO DAGScheduler: running: Set()
21/03/20 14:56:02 INFO DAGScheduler: waiting: Set(ResultStage 63)
21/03/20 14:56:02 INFO DAGScheduler: failed: Set()
21/03/20 14:56:02 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[231] at count at utils.scala:135), which has no missing parents
21/03/20 14:56:02 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:56:02 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:56:02 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:56:02 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1223
21/03/20 14:56:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[231] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:56:02 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
21/03/20 14:56:02 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 77, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:56:02 INFO Executor: Running task 0.0 in stage 63.0 (TID 77)
21/03/20 14:56:02 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:56:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:56:02 INFO Executor: Finished task 0.0 in stage 63.0 (TID 77). 2562 bytes result sent to driver
21/03/20 14:56:02 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 77) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:56:02 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
21/03/20 14:56:02 INFO DAGScheduler: ResultStage 63 (count at utils.scala:135) finished in 0,032 s
21/03/20 14:56:02 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:56:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
21/03/20 14:56:02 INFO DAGScheduler: Job 42 finished: count at utils.scala:135, took 0,099010 s
21/03/20 14:56:03 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:56:04 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:56:04 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:56:04 INFO DAGScheduler: Got job 43 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:56:04 INFO DAGScheduler: Final stage: ResultStage 64 (collect at utils.scala:137)
21/03/20 14:56:04 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:56:04 INFO DAGScheduler: Missing parents: List()
21/03/20 14:56:04 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[233] at collect at utils.scala:137), which has no missing parents
21/03/20 14:56:04 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 7.6 KiB, free 413.9 MiB)
21/03/20 14:56:04 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 413.9 MiB)
21/03/20 14:56:04 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:49848 (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 14:56:04 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1223
21/03/20 14:56:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[233] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:56:04 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
21/03/20 14:56:04 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 78, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 14:56:04 INFO Executor: Running task 0.0 in stage 64.0 (TID 78)
21/03/20 14:56:04 INFO Executor: Finished task 0.0 in stage 64.0 (TID 78). 1354 bytes result sent to driver
21/03/20 14:56:04 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 78) in 8 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:56:04 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
21/03/20 14:56:04 INFO DAGScheduler: ResultStage 64 (collect at utils.scala:137) finished in 0,024 s
21/03/20 14:56:04 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:56:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
21/03/20 14:56:04 INFO DAGScheduler: Job 43 finished: collect at utils.scala:137, took 0,028719 s
21/03/20 14:56:04 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:56:04 INFO DAGScheduler: Registering RDD 235 (count at utils.scala:135) as input to shuffle 22
21/03/20 14:56:04 INFO DAGScheduler: Got job 44 (count at utils.scala:135) with 1 output partitions
21/03/20 14:56:04 INFO DAGScheduler: Final stage: ResultStage 66 (count at utils.scala:135)
21/03/20 14:56:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
21/03/20 14:56:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 65)
21/03/20 14:56:04 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[235] at count at utils.scala:135), which has no missing parents
21/03/20 14:56:04 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:56:04 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:56:04 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:56:04 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1223
21/03/20 14:56:04 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:49848 in memory (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 14:56:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[235] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:56:04 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
21/03/20 14:56:04 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 79, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 14:56:04 INFO Executor: Running task 0.0 in stage 65.0 (TID 79)
21/03/20 14:56:04 INFO Executor: Finished task 0.0 in stage 65.0 (TID 79). 1790 bytes result sent to driver
21/03/20 14:56:04 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 79) in 28 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:56:04 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
21/03/20 14:56:04 INFO DAGScheduler: ShuffleMapStage 65 (count at utils.scala:135) finished in 0,052 s
21/03/20 14:56:04 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:56:04 INFO DAGScheduler: running: Set()
21/03/20 14:56:04 INFO DAGScheduler: waiting: Set(ResultStage 66)
21/03/20 14:56:04 INFO DAGScheduler: failed: Set()
21/03/20 14:56:04 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[238] at count at utils.scala:135), which has no missing parents
21/03/20 14:56:04 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:56:04 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:56:04 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:56:04 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1223
21/03/20 14:56:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[238] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:56:04 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
21/03/20 14:56:04 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 80, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:56:04 INFO Executor: Running task 0.0 in stage 66.0 (TID 80)
21/03/20 14:56:04 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:56:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/03/20 14:56:04 INFO Executor: Finished task 0.0 in stage 66.0 (TID 80). 2605 bytes result sent to driver
21/03/20 14:56:04 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 80) in 20 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:56:04 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
21/03/20 14:56:04 INFO DAGScheduler: ResultStage 66 (count at utils.scala:135) finished in 0,040 s
21/03/20 14:56:04 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:56:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
21/03/20 14:56:04 INFO DAGScheduler: Job 44 finished: count at utils.scala:135, took 0,102784 s
21/03/20 14:58:37 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:58:37 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:58:37 INFO HiveMetaStore: 0: get_database: default
21/03/20 14:58:37 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 14:58:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 14:58:37 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 14:58:37 INFO CodeGenerator: Code generated in 12.7186 ms
21/03/20 14:58:37 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:58:37 INFO SparkContext: Starting job: collect at utils.scala:54
21/03/20 14:58:37 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:58:37 INFO DAGScheduler: Got job 45 (collect at utils.scala:54) with 8 output partitions
21/03/20 14:58:37 INFO DAGScheduler: Final stage: ResultStage 67 (collect at utils.scala:54)
21/03/20 14:58:37 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:58:37 INFO DAGScheduler: Missing parents: List()
21/03/20 14:58:37 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[244] at map at utils.scala:54), which has no missing parents
21/03/20 14:58:37 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 8.7 KiB, free 413.9 MiB)
21/03/20 14:58:37 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.9 MiB)
21/03/20 14:58:37 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:49848 (size: 4.6 KiB, free: 413.9 MiB)
21/03/20 14:58:37 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:37 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 67 (MapPartitionsRDD[244] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
21/03/20 14:58:37 INFO TaskSchedulerImpl: Adding task set 67.0 with 8 tasks
21/03/20 14:58:37 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 81, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
21/03/20 14:58:37 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 82, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7581 bytes)
21/03/20 14:58:37 INFO TaskSetManager: Starting task 2.0 in stage 67.0 (TID 83, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7670 bytes)
21/03/20 14:58:37 INFO TaskSetManager: Starting task 3.0 in stage 67.0 (TID 84, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7581 bytes)
21/03/20 14:58:37 INFO TaskSetManager: Starting task 4.0 in stage 67.0 (TID 85, 127.0.0.1, executor driver, partition 4, PROCESS_LOCAL, 7581 bytes)
21/03/20 14:58:37 INFO TaskSetManager: Starting task 5.0 in stage 67.0 (TID 86, 127.0.0.1, executor driver, partition 5, PROCESS_LOCAL, 7670 bytes)
21/03/20 14:58:37 INFO TaskSetManager: Starting task 6.0 in stage 67.0 (TID 87, 127.0.0.1, executor driver, partition 6, PROCESS_LOCAL, 7581 bytes)
21/03/20 14:58:37 INFO TaskSetManager: Starting task 7.0 in stage 67.0 (TID 88, 127.0.0.1, executor driver, partition 7, PROCESS_LOCAL, 7670 bytes)
21/03/20 14:58:37 INFO Executor: Running task 1.0 in stage 67.0 (TID 82)
21/03/20 14:58:37 INFO Executor: Running task 3.0 in stage 67.0 (TID 84)
21/03/20 14:58:37 INFO Executor: Running task 0.0 in stage 67.0 (TID 81)
21/03/20 14:58:37 INFO Executor: Running task 2.0 in stage 67.0 (TID 83)
21/03/20 14:58:37 INFO Executor: Running task 4.0 in stage 67.0 (TID 85)
21/03/20 14:58:37 INFO Executor: Running task 5.0 in stage 67.0 (TID 86)
21/03/20 14:58:37 INFO Executor: Running task 6.0 in stage 67.0 (TID 87)
21/03/20 14:58:37 INFO Executor: Running task 7.0 in stage 67.0 (TID 88)
21/03/20 14:58:37 INFO CodeGenerator: Code generated in 11.7075 ms
21/03/20 14:58:37 INFO Executor: Finished task 5.0 in stage 67.0 (TID 86). 1207 bytes result sent to driver
21/03/20 14:58:37 INFO Executor: Finished task 2.0 in stage 67.0 (TID 83). 1164 bytes result sent to driver
21/03/20 14:58:37 INFO Executor: Finished task 0.0 in stage 67.0 (TID 81). 1069 bytes result sent to driver
21/03/20 14:58:37 INFO Executor: Finished task 7.0 in stage 67.0 (TID 88). 1164 bytes result sent to driver
21/03/20 14:58:37 INFO Executor: Finished task 3.0 in stage 67.0 (TID 84). 1112 bytes result sent to driver
21/03/20 14:58:37 INFO Executor: Finished task 4.0 in stage 67.0 (TID 85). 1155 bytes result sent to driver
21/03/20 14:58:37 INFO Executor: Finished task 6.0 in stage 67.0 (TID 87). 1112 bytes result sent to driver
21/03/20 14:58:37 INFO Executor: Finished task 1.0 in stage 67.0 (TID 82). 1112 bytes result sent to driver
21/03/20 14:58:37 INFO TaskSetManager: Finished task 5.0 in stage 67.0 (TID 86) in 72 ms on 127.0.0.1 (executor driver) (1/8)
21/03/20 14:58:37 INFO TaskSetManager: Finished task 2.0 in stage 67.0 (TID 83) in 72 ms on 127.0.0.1 (executor driver) (2/8)
21/03/20 14:58:37 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 81) in 76 ms on 127.0.0.1 (executor driver) (3/8)
21/03/20 14:58:37 INFO TaskSetManager: Finished task 7.0 in stage 67.0 (TID 88) in 72 ms on 127.0.0.1 (executor driver) (4/8)
21/03/20 14:58:37 INFO TaskSetManager: Finished task 3.0 in stage 67.0 (TID 84) in 72 ms on 127.0.0.1 (executor driver) (5/8)
21/03/20 14:58:37 INFO TaskSetManager: Finished task 4.0 in stage 67.0 (TID 85) in 72 ms on 127.0.0.1 (executor driver) (6/8)
21/03/20 14:58:37 INFO TaskSetManager: Finished task 6.0 in stage 67.0 (TID 87) in 76 ms on 127.0.0.1 (executor driver) (7/8)
21/03/20 14:58:37 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 82) in 76 ms on 127.0.0.1 (executor driver) (8/8)
21/03/20 14:58:37 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
21/03/20 14:58:37 INFO DAGScheduler: ResultStage 67 (collect at utils.scala:54) finished in 0,092 s
21/03/20 14:58:37 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:58:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished
21/03/20 14:58:37 INFO DAGScheduler: Job 45 finished: collect at utils.scala:54, took 0,102638 s
21/03/20 14:58:37 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:49848 in memory (size: 4.6 KiB, free: 413.9 MiB)
21/03/20 14:58:38 INFO CodeGenerator: Code generated in 10.8045 ms
21/03/20 14:58:38 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:58:38 INFO DAGScheduler: Got job 46 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:58:38 INFO DAGScheduler: Final stage: ResultStage 68 (collect at utils.scala:137)
21/03/20 14:58:38 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:58:38 INFO DAGScheduler: Missing parents: List()
21/03/20 14:58:38 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[247] at collect at utils.scala:137), which has no missing parents
21/03/20 14:58:38 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 7.0 KiB, free 413.9 MiB)
21/03/20 14:58:38 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 413.9 MiB)
21/03/20 14:58:38 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:49848 (size: 3.6 KiB, free: 413.9 MiB)
21/03/20 14:58:38 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[247] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:58:38 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
21/03/20 14:58:38 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 89, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 14:58:38 INFO Executor: Running task 0.0 in stage 68.0 (TID 89)
21/03/20 14:58:38 INFO Executor: Finished task 0.0 in stage 68.0 (TID 89). 1353 bytes result sent to driver
21/03/20 14:58:38 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 89) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:58:38 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
21/03/20 14:58:38 INFO DAGScheduler: ResultStage 68 (collect at utils.scala:137) finished in 0,028 s
21/03/20 14:58:38 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:58:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished
21/03/20 14:58:38 INFO DAGScheduler: Job 46 finished: collect at utils.scala:137, took 0,034869 s
21/03/20 14:58:38 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:49848 in memory (size: 3.6 KiB, free: 413.9 MiB)
21/03/20 14:58:38 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:58:38 INFO DAGScheduler: Registering RDD 249 (count at utils.scala:135) as input to shuffle 23
21/03/20 14:58:38 INFO DAGScheduler: Got job 47 (count at utils.scala:135) with 1 output partitions
21/03/20 14:58:38 INFO DAGScheduler: Final stage: ResultStage 70 (count at utils.scala:135)
21/03/20 14:58:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 69)
21/03/20 14:58:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 69)
21/03/20 14:58:38 INFO DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[249] at count at utils.scala:135), which has no missing parents
21/03/20 14:58:38 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:58:38 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:58:38 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:58:38 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[249] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:58:38 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
21/03/20 14:58:38 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 90, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 14:58:38 INFO Executor: Running task 0.0 in stage 69.0 (TID 90)
21/03/20 14:58:38 INFO Executor: Finished task 0.0 in stage 69.0 (TID 90). 1790 bytes result sent to driver
21/03/20 14:58:38 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 90) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:58:38 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
21/03/20 14:58:38 INFO DAGScheduler: ShuffleMapStage 69 (count at utils.scala:135) finished in 0,040 s
21/03/20 14:58:38 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:58:38 INFO DAGScheduler: running: Set()
21/03/20 14:58:38 INFO DAGScheduler: waiting: Set(ResultStage 70)
21/03/20 14:58:38 INFO DAGScheduler: failed: Set()
21/03/20 14:58:38 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[252] at count at utils.scala:135), which has no missing parents
21/03/20 14:58:38 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:58:38 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:58:38 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:58:38 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[252] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:58:38 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
21/03/20 14:58:38 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 91, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:58:38 INFO Executor: Running task 0.0 in stage 70.0 (TID 91)
21/03/20 14:58:38 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:38 INFO Executor: Finished task 0.0 in stage 70.0 (TID 91). 2605 bytes result sent to driver
21/03/20 14:58:38 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 91) in 19 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:58:38 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
21/03/20 14:58:38 INFO DAGScheduler: ResultStage 70 (count at utils.scala:135) finished in 0,032 s
21/03/20 14:58:38 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:58:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 70: Stage finished
21/03/20 14:58:38 INFO DAGScheduler: Job 47 finished: count at utils.scala:135, took 0,087154 s
21/03/20 14:58:38 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:58:38 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:58:38 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:58:38 INFO DAGScheduler: Got job 48 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:58:38 INFO DAGScheduler: Final stage: ResultStage 71 (collect at utils.scala:137)
21/03/20 14:58:38 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:58:38 INFO DAGScheduler: Missing parents: List()
21/03/20 14:58:38 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[254] at collect at utils.scala:137), which has no missing parents
21/03/20 14:58:38 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 7.0 KiB, free 413.9 MiB)
21/03/20 14:58:38 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 413.9 MiB)
21/03/20 14:58:38 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:49848 (size: 3.6 KiB, free: 413.9 MiB)
21/03/20 14:58:38 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[254] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:58:38 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
21/03/20 14:58:38 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 92, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 14:58:38 INFO Executor: Running task 0.0 in stage 71.0 (TID 92)
21/03/20 14:58:38 INFO Executor: Finished task 0.0 in stage 71.0 (TID 92). 1353 bytes result sent to driver
21/03/20 14:58:38 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 92) in 8 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:58:38 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
21/03/20 14:58:38 INFO DAGScheduler: ResultStage 71 (collect at utils.scala:137) finished in 0,020 s
21/03/20 14:58:38 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:58:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished
21/03/20 14:58:38 INFO DAGScheduler: Job 48 finished: collect at utils.scala:137, took 0,024725 s
21/03/20 14:58:38 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:49848 in memory (size: 3.6 KiB, free: 413.9 MiB)
21/03/20 14:58:38 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:58:38 INFO DAGScheduler: Registering RDD 256 (count at utils.scala:135) as input to shuffle 24
21/03/20 14:58:38 INFO DAGScheduler: Got job 49 (count at utils.scala:135) with 1 output partitions
21/03/20 14:58:38 INFO DAGScheduler: Final stage: ResultStage 73 (count at utils.scala:135)
21/03/20 14:58:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)
21/03/20 14:58:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 72)
21/03/20 14:58:38 INFO DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[256] at count at utils.scala:135), which has no missing parents
21/03/20 14:58:38 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:58:38 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:58:38 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:58:38 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[256] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:58:38 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks
21/03/20 14:58:38 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 93, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 14:58:38 INFO Executor: Running task 0.0 in stage 72.0 (TID 93)
21/03/20 14:58:38 INFO Executor: Finished task 0.0 in stage 72.0 (TID 93). 1790 bytes result sent to driver
21/03/20 14:58:38 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 93) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:58:38 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
21/03/20 14:58:38 INFO DAGScheduler: ShuffleMapStage 72 (count at utils.scala:135) finished in 0,040 s
21/03/20 14:58:38 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:58:38 INFO DAGScheduler: running: Set()
21/03/20 14:58:38 INFO DAGScheduler: waiting: Set(ResultStage 73)
21/03/20 14:58:38 INFO DAGScheduler: failed: Set()
21/03/20 14:58:38 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[259] at count at utils.scala:135), which has no missing parents
21/03/20 14:58:38 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:58:38 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:58:38 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:58:38 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[259] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:58:38 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
21/03/20 14:58:38 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 94, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:58:38 INFO Executor: Running task 0.0 in stage 73.0 (TID 94)
21/03/20 14:58:38 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/20 14:58:38 INFO Executor: Finished task 0.0 in stage 73.0 (TID 94). 2605 bytes result sent to driver
21/03/20 14:58:38 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 94) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:58:38 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
21/03/20 14:58:38 INFO DAGScheduler: ResultStage 73 (count at utils.scala:135) finished in 0,024 s
21/03/20 14:58:38 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:58:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished
21/03/20 14:58:38 INFO DAGScheduler: Job 49 finished: count at utils.scala:135, took 0,074954 s
21/03/20 14:58:39 INFO Instrumentation: [0da90019] training finished
21/03/20 14:58:39 INFO Instrumentation: [1e30fd12] training finished
21/03/20 14:58:39 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:58:39 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:58:39 INFO CodeGenerator: Code generated in 15.3801 ms
21/03/20 14:58:39 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:58:39 INFO DAGScheduler: Got job 50 (collect at utils.scala:137) with 1 output partitions
21/03/20 14:58:39 INFO DAGScheduler: Final stage: ResultStage 74 (collect at utils.scala:137)
21/03/20 14:58:39 INFO DAGScheduler: Parents of final stage: List()
21/03/20 14:58:39 INFO DAGScheduler: Missing parents: List()
21/03/20 14:58:39 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[261] at collect at utils.scala:137), which has no missing parents
21/03/20 14:58:39 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 7.1 KiB, free 413.9 MiB)
21/03/20 14:58:39 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 413.9 MiB)
21/03/20 14:58:39 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:49848 (size: 3.6 KiB, free: 413.9 MiB)
21/03/20 14:58:39 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[261] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:58:39 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks
21/03/20 14:58:39 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 95, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 14:58:39 INFO Executor: Running task 0.0 in stage 74.0 (TID 95)
21/03/20 14:58:39 INFO Executor: Finished task 0.0 in stage 74.0 (TID 95). 1354 bytes result sent to driver
21/03/20 14:58:39 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 95) in 12 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:58:39 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
21/03/20 14:58:39 INFO DAGScheduler: ResultStage 74 (collect at utils.scala:137) finished in 0,028 s
21/03/20 14:58:39 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:58:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
21/03/20 14:58:39 INFO DAGScheduler: Job 50 finished: collect at utils.scala:137, took 0,033958 s
21/03/20 14:58:39 INFO CodeGenerator: Code generated in 15.8991 ms
21/03/20 14:58:39 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:49848 in memory (size: 3.6 KiB, free: 413.9 MiB)
21/03/20 14:58:39 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:58:39 INFO DAGScheduler: Registering RDD 263 (count at utils.scala:135) as input to shuffle 25
21/03/20 14:58:39 INFO DAGScheduler: Got job 51 (count at utils.scala:135) with 1 output partitions
21/03/20 14:58:39 INFO DAGScheduler: Final stage: ResultStage 76 (count at utils.scala:135)
21/03/20 14:58:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
21/03/20 14:58:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 75)
21/03/20 14:58:39 INFO DAGScheduler: Submitting ShuffleMapStage 75 (MapPartitionsRDD[263] at count at utils.scala:135), which has no missing parents
21/03/20 14:58:39 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 14:58:39 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:58:39 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:58:39 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[263] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:58:39 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks
21/03/20 14:58:39 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 96, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 14:58:39 INFO Executor: Running task 0.0 in stage 75.0 (TID 96)
21/03/20 14:58:39 INFO Executor: Finished task 0.0 in stage 75.0 (TID 96). 1833 bytes result sent to driver
21/03/20 14:58:39 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 96) in 32 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:58:39 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
21/03/20 14:58:39 INFO DAGScheduler: ShuffleMapStage 75 (count at utils.scala:135) finished in 0,044 s
21/03/20 14:58:39 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:58:39 INFO DAGScheduler: running: Set()
21/03/20 14:58:39 INFO DAGScheduler: waiting: Set(ResultStage 76)
21/03/20 14:58:39 INFO DAGScheduler: failed: Set()
21/03/20 14:58:39 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[266] at count at utils.scala:135), which has no missing parents
21/03/20 14:58:39 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 14:58:39 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 14:58:39 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:58:39 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[266] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:58:39 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
21/03/20 14:58:39 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 97, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:58:39 INFO Executor: Running task 0.0 in stage 76.0 (TID 97)
21/03/20 14:58:39 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:39 INFO Executor: Finished task 0.0 in stage 76.0 (TID 97). 2562 bytes result sent to driver
21/03/20 14:58:39 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 97) in 17 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:58:39 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
21/03/20 14:58:39 INFO DAGScheduler: ResultStage 76 (count at utils.scala:135) finished in 0,025 s
21/03/20 14:58:39 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:58:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished
21/03/20 14:58:39 INFO DAGScheduler: Job 51 finished: count at utils.scala:135, took 0,078160 s
21/03/20 14:58:40 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:58:40 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:58:41 INFO CodeGenerator: Code generated in 13.5439 ms
21/03/20 14:58:41 INFO CodeGenerator: Code generated in 25.3881 ms
21/03/20 14:58:41 INFO CodeGenerator: Code generated in 22.6792 ms
21/03/20 14:58:41 INFO CodeGenerator: Code generated in 9.6566 ms
21/03/20 14:58:41 INFO CodeGenerator: Code generated in 24.0918 ms
21/03/20 14:58:41 INFO CodeGenerator: Code generated in 10.6706 ms
21/03/20 14:58:41 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 14:58:41 INFO DAGScheduler: Registering RDD 273 (collect at utils.scala:137) as input to shuffle 26
21/03/20 14:58:41 INFO DAGScheduler: Registering RDD 277 (collect at utils.scala:137) as input to shuffle 27
21/03/20 14:58:41 INFO DAGScheduler: Got job 52 (collect at utils.scala:137) with 8 output partitions
21/03/20 14:58:41 INFO DAGScheduler: Final stage: ResultStage 79 (collect at utils.scala:137)
21/03/20 14:58:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78, ShuffleMapStage 77)
21/03/20 14:58:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78, ShuffleMapStage 77)
21/03/20 14:58:41 INFO DAGScheduler: Submitting ShuffleMapStage 77 (MapPartitionsRDD[273] at collect at utils.scala:137), which has no missing parents
21/03/20 14:58:41 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 31.9 KiB, free 413.9 MiB)
21/03/20 14:58:41 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 13.3 KiB, free 413.9 MiB)
21/03/20 14:58:41 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:49848 (size: 13.3 KiB, free: 413.9 MiB)
21/03/20 14:58:41 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 77 (MapPartitionsRDD[273] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:58:41 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks
21/03/20 14:58:41 INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[277] at collect at utils.scala:137), which has no missing parents
21/03/20 14:58:41 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 98, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7811 bytes)
21/03/20 14:58:41 INFO Executor: Running task 0.0 in stage 77.0 (TID 98)
21/03/20 14:58:41 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 9.9 KiB, free 413.9 MiB)
21/03/20 14:58:41 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 14:58:41 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:58:41 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[277] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 14:58:41 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks
21/03/20 14:58:41 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 99, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 14:58:41 INFO Executor: Running task 0.0 in stage 78.0 (TID 99)
21/03/20 14:58:41 INFO MemoryStore: Block rdd_268_0 stored as values in memory (estimated size 312.0 B, free 413.9 MiB)
21/03/20 14:58:41 INFO BlockManagerInfo: Added rdd_268_0 in memory on 127.0.0.1:49848 (size: 312.0 B, free: 413.9 MiB)
21/03/20 14:58:41 INFO CodeGenerator: Code generated in 34.8798 ms
21/03/20 14:58:41 INFO CodeGenerator: Code generated in 45.0599 ms
21/03/20 14:58:41 INFO Executor: Finished task 0.0 in stage 77.0 (TID 98). 2048 bytes result sent to driver
21/03/20 14:58:41 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 98) in 135 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:58:41 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
21/03/20 14:58:41 INFO DAGScheduler: ShuffleMapStage 77 (collect at utils.scala:137) finished in 0,151 s
21/03/20 14:58:41 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:58:41 INFO DAGScheduler: running: Set(ShuffleMapStage 78)
21/03/20 14:58:41 INFO DAGScheduler: waiting: Set(ResultStage 79)
21/03/20 14:58:41 INFO DAGScheduler: failed: Set()
21/03/20 14:58:41 INFO Executor: Finished task 0.0 in stage 78.0 (TID 99). 1693 bytes result sent to driver
21/03/20 14:58:41 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 99) in 143 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:58:41 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
21/03/20 14:58:41 INFO DAGScheduler: ShuffleMapStage 78 (collect at utils.scala:137) finished in 0,163 s
21/03/20 14:58:41 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:58:41 INFO DAGScheduler: running: Set()
21/03/20 14:58:41 INFO DAGScheduler: waiting: Set(ResultStage 79)
21/03/20 14:58:41 INFO DAGScheduler: failed: Set()
21/03/20 14:58:41 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[282] at collect at utils.scala:137), which has no missing parents
21/03/20 14:58:41 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 40.5 KiB, free 413.8 MiB)
21/03/20 14:58:41 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 18.3 KiB, free 413.8 MiB)
21/03/20 14:58:41 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:49848 (size: 18.3 KiB, free: 413.9 MiB)
21/03/20 14:58:41 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:41 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 79 (MapPartitionsRDD[282] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
21/03/20 14:58:41 INFO TaskSchedulerImpl: Adding task set 79.0 with 8 tasks
21/03/20 14:58:41 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 100, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7607 bytes)
21/03/20 14:58:41 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 101, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7607 bytes)
21/03/20 14:58:41 INFO TaskSetManager: Starting task 2.0 in stage 79.0 (TID 102, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7607 bytes)
21/03/20 14:58:41 INFO TaskSetManager: Starting task 3.0 in stage 79.0 (TID 103, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7607 bytes)
21/03/20 14:58:41 INFO TaskSetManager: Starting task 4.0 in stage 79.0 (TID 104, 127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7607 bytes)
21/03/20 14:58:41 INFO TaskSetManager: Starting task 5.0 in stage 79.0 (TID 105, 127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7607 bytes)
21/03/20 14:58:41 INFO TaskSetManager: Starting task 6.0 in stage 79.0 (TID 106, 127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7607 bytes)
21/03/20 14:58:41 INFO TaskSetManager: Starting task 7.0 in stage 79.0 (TID 107, 127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7607 bytes)
21/03/20 14:58:41 INFO Executor: Running task 1.0 in stage 79.0 (TID 101)
21/03/20 14:58:41 INFO Executor: Running task 3.0 in stage 79.0 (TID 103)
21/03/20 14:58:41 INFO Executor: Running task 6.0 in stage 79.0 (TID 106)
21/03/20 14:58:41 INFO Executor: Running task 2.0 in stage 79.0 (TID 102)
21/03/20 14:58:41 INFO Executor: Running task 0.0 in stage 79.0 (TID 100)
21/03/20 14:58:41 INFO Executor: Running task 4.0 in stage 79.0 (TID 104)
21/03/20 14:58:41 INFO Executor: Running task 5.0 in stage 79.0 (TID 105)
21/03/20 14:58:41 INFO Executor: Running task 7.0 in stage 79.0 (TID 107)
21/03/20 14:58:41 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:49848 in memory (size: 13.3 KiB, free: 413.9 MiB)
21/03/20 14:58:41 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/03/20 14:58:41 INFO CodeGenerator: Code generated in 28.9257 ms
21/03/20 14:58:42 INFO CodeGenerator: Code generated in 22.0074 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO CodeGenerator: Code generated in 35.0653 ms
21/03/20 14:58:42 INFO CodeGenerator: Code generated in 40.6366 ms
21/03/20 14:58:42 INFO CodeGenerator: Code generated in 21.7699 ms
21/03/20 14:58:42 INFO CodeGenerator: Code generated in 23.3668 ms
21/03/20 14:58:42 INFO CodeGenerator: Code generated in 15.4972 ms
21/03/20 14:58:42 INFO Executor: Finished task 1.0 in stage 79.0 (TID 101). 4458 bytes result sent to driver
21/03/20 14:58:42 INFO Executor: Finished task 7.0 in stage 79.0 (TID 107). 4458 bytes result sent to driver
21/03/20 14:58:42 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 101) in 505 ms on 127.0.0.1 (executor driver) (1/8)
21/03/20 14:58:42 INFO TaskSetManager: Finished task 7.0 in stage 79.0 (TID 107) in 509 ms on 127.0.0.1 (executor driver) (2/8)
21/03/20 14:58:42 INFO Executor: Finished task 4.0 in stage 79.0 (TID 104). 4507 bytes result sent to driver
21/03/20 14:58:42 INFO Executor: Finished task 0.0 in stage 79.0 (TID 100). 4494 bytes result sent to driver
21/03/20 14:58:42 INFO Executor: Finished task 3.0 in stage 79.0 (TID 103). 4532 bytes result sent to driver
21/03/20 14:58:42 INFO Executor: Finished task 6.0 in stage 79.0 (TID 106). 4539 bytes result sent to driver
21/03/20 14:58:42 INFO Executor: Finished task 5.0 in stage 79.0 (TID 105). 4508 bytes result sent to driver
21/03/20 14:58:42 INFO Executor: Finished task 2.0 in stage 79.0 (TID 102). 4547 bytes result sent to driver
21/03/20 14:58:42 INFO TaskSetManager: Finished task 4.0 in stage 79.0 (TID 104) in 521 ms on 127.0.0.1 (executor driver) (3/8)
21/03/20 14:58:42 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 100) in 525 ms on 127.0.0.1 (executor driver) (4/8)
21/03/20 14:58:42 INFO TaskSetManager: Finished task 6.0 in stage 79.0 (TID 106) in 525 ms on 127.0.0.1 (executor driver) (5/8)
21/03/20 14:58:42 INFO TaskSetManager: Finished task 3.0 in stage 79.0 (TID 103) in 525 ms on 127.0.0.1 (executor driver) (6/8)
21/03/20 14:58:42 INFO TaskSetManager: Finished task 5.0 in stage 79.0 (TID 105) in 525 ms on 127.0.0.1 (executor driver) (7/8)
21/03/20 14:58:42 INFO TaskSetManager: Finished task 2.0 in stage 79.0 (TID 102) in 525 ms on 127.0.0.1 (executor driver) (8/8)
21/03/20 14:58:42 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
21/03/20 14:58:42 INFO DAGScheduler: ResultStage 79 (collect at utils.scala:137) finished in 0,551 s
21/03/20 14:58:42 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:58:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished
21/03/20 14:58:42 INFO DAGScheduler: Job 52 finished: collect at utils.scala:137, took 0,767406 s
21/03/20 14:58:42 INFO CodeGenerator: Code generated in 13.2539 ms
21/03/20 14:58:42 INFO CodeGenerator: Code generated in 15.6819 ms
21/03/20 14:58:42 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 14:58:42 INFO DAGScheduler: Registering RDD 287 (count at utils.scala:135) as input to shuffle 28
21/03/20 14:58:42 INFO DAGScheduler: Registering RDD 291 (count at utils.scala:135) as input to shuffle 29
21/03/20 14:58:42 INFO DAGScheduler: Registering RDD 296 (count at utils.scala:135) as input to shuffle 30
21/03/20 14:58:42 INFO DAGScheduler: Got job 53 (count at utils.scala:135) with 1 output partitions
21/03/20 14:58:42 INFO DAGScheduler: Final stage: ResultStage 83 (count at utils.scala:135)
21/03/20 14:58:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82)
21/03/20 14:58:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 82)
21/03/20 14:58:42 INFO DAGScheduler: Submitting ShuffleMapStage 80 (MapPartitionsRDD[287] at count at utils.scala:135), which has no missing parents
21/03/20 14:58:42 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 31.9 KiB, free 413.8 MiB)
21/03/20 14:58:42 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 13.3 KiB, free 413.8 MiB)
21/03/20 14:58:42 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:49848 (size: 13.3 KiB, free: 413.9 MiB)
21/03/20 14:58:42 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[287] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:58:42 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
21/03/20 14:58:42 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[291] at count at utils.scala:135), which has no missing parents
21/03/20 14:58:42 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 108, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7811 bytes)
21/03/20 14:58:42 INFO Executor: Running task 0.0 in stage 80.0 (TID 108)
21/03/20 14:58:42 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 9.9 KiB, free 413.8 MiB)
21/03/20 14:58:42 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.8 MiB)
21/03/20 14:58:42 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:49848 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:58:42 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[291] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:58:42 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
21/03/20 14:58:42 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 109, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 14:58:42 INFO Executor: Running task 0.0 in stage 81.0 (TID 109)
21/03/20 14:58:42 INFO BlockManager: Found block rdd_268_0 locally
21/03/20 14:58:42 INFO Executor: Finished task 0.0 in stage 80.0 (TID 108). 2134 bytes result sent to driver
21/03/20 14:58:42 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 108) in 60 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:58:42 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
21/03/20 14:58:42 INFO DAGScheduler: ShuffleMapStage 80 (count at utils.scala:135) finished in 0,092 s
21/03/20 14:58:42 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:58:42 INFO DAGScheduler: running: Set(ShuffleMapStage 81)
21/03/20 14:58:42 INFO DAGScheduler: waiting: Set(ShuffleMapStage 82, ResultStage 83)
21/03/20 14:58:42 INFO DAGScheduler: failed: Set()
21/03/20 14:58:42 INFO Executor: Finished task 0.0 in stage 81.0 (TID 109). 1693 bytes result sent to driver
21/03/20 14:58:42 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 109) in 82 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:58:42 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
21/03/20 14:58:42 INFO DAGScheduler: ShuffleMapStage 81 (count at utils.scala:135) finished in 0,094 s
21/03/20 14:58:42 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:58:42 INFO DAGScheduler: running: Set()
21/03/20 14:58:42 INFO DAGScheduler: waiting: Set(ShuffleMapStage 82, ResultStage 83)
21/03/20 14:58:42 INFO DAGScheduler: failed: Set()
21/03/20 14:58:42 INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[296] at count at utils.scala:135), which has no missing parents
21/03/20 14:58:42 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 40.3 KiB, free 413.8 MiB)
21/03/20 14:58:42 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 18.6 KiB, free 413.7 MiB)
21/03/20 14:58:42 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:49848 (size: 18.6 KiB, free: 413.9 MiB)
21/03/20 14:58:42 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:42 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[296] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
21/03/20 14:58:42 INFO TaskSchedulerImpl: Adding task set 82.0 with 8 tasks
21/03/20 14:58:42 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 110, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7596 bytes)
21/03/20 14:58:42 INFO TaskSetManager: Starting task 1.0 in stage 82.0 (TID 111, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7596 bytes)
21/03/20 14:58:42 INFO TaskSetManager: Starting task 2.0 in stage 82.0 (TID 112, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7596 bytes)
21/03/20 14:58:42 INFO TaskSetManager: Starting task 3.0 in stage 82.0 (TID 113, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7596 bytes)
21/03/20 14:58:42 INFO TaskSetManager: Starting task 4.0 in stage 82.0 (TID 114, 127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7596 bytes)
21/03/20 14:58:42 INFO TaskSetManager: Starting task 5.0 in stage 82.0 (TID 115, 127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7596 bytes)
21/03/20 14:58:42 INFO TaskSetManager: Starting task 6.0 in stage 82.0 (TID 116, 127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7596 bytes)
21/03/20 14:58:42 INFO TaskSetManager: Starting task 7.0 in stage 82.0 (TID 117, 127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7596 bytes)
21/03/20 14:58:42 INFO Executor: Running task 1.0 in stage 82.0 (TID 111)
21/03/20 14:58:42 INFO Executor: Running task 6.0 in stage 82.0 (TID 116)
21/03/20 14:58:42 INFO Executor: Running task 7.0 in stage 82.0 (TID 117)
21/03/20 14:58:42 INFO Executor: Running task 4.0 in stage 82.0 (TID 114)
21/03/20 14:58:42 INFO Executor: Running task 5.0 in stage 82.0 (TID 115)
21/03/20 14:58:42 INFO Executor: Running task 3.0 in stage 82.0 (TID 113)
21/03/20 14:58:42 INFO Executor: Running task 2.0 in stage 82.0 (TID 112)
21/03/20 14:58:42 INFO Executor: Running task 0.0 in stage 82.0 (TID 110)
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 14:58:42 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:49848 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 14:58:42 INFO Executor: Finished task 7.0 in stage 82.0 (TID 117). 4813 bytes result sent to driver
21/03/20 14:58:42 INFO TaskSetManager: Finished task 7.0 in stage 82.0 (TID 117) in 108 ms on 127.0.0.1 (executor driver) (1/8)
21/03/20 14:58:42 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:49848 in memory (size: 13.3 KiB, free: 413.9 MiB)
21/03/20 14:58:42 INFO Executor: Finished task 1.0 in stage 82.0 (TID 111). 4813 bytes result sent to driver
21/03/20 14:58:42 INFO TaskSetManager: Finished task 1.0 in stage 82.0 (TID 111) in 116 ms on 127.0.0.1 (executor driver) (2/8)
21/03/20 14:58:42 INFO Executor: Finished task 5.0 in stage 82.0 (TID 115). 4813 bytes result sent to driver
21/03/20 14:58:42 INFO TaskSetManager: Finished task 5.0 in stage 82.0 (TID 115) in 124 ms on 127.0.0.1 (executor driver) (3/8)
21/03/20 14:58:42 INFO Executor: Finished task 4.0 in stage 82.0 (TID 114). 4813 bytes result sent to driver
21/03/20 14:58:42 INFO TaskSetManager: Finished task 4.0 in stage 82.0 (TID 114) in 128 ms on 127.0.0.1 (executor driver) (4/8)
21/03/20 14:58:42 INFO Executor: Finished task 0.0 in stage 82.0 (TID 110). 4813 bytes result sent to driver
21/03/20 14:58:42 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 110) in 140 ms on 127.0.0.1 (executor driver) (5/8)
21/03/20 14:58:42 INFO Executor: Finished task 6.0 in stage 82.0 (TID 116). 4813 bytes result sent to driver
21/03/20 14:58:42 INFO TaskSetManager: Finished task 6.0 in stage 82.0 (TID 116) in 140 ms on 127.0.0.1 (executor driver) (6/8)
21/03/20 14:58:42 INFO Executor: Finished task 3.0 in stage 82.0 (TID 113). 4770 bytes result sent to driver
21/03/20 14:58:42 INFO TaskSetManager: Finished task 3.0 in stage 82.0 (TID 113) in 148 ms on 127.0.0.1 (executor driver) (7/8)
21/03/20 14:58:43 INFO Executor: Finished task 2.0 in stage 82.0 (TID 112). 4813 bytes result sent to driver
21/03/20 14:58:43 INFO TaskSetManager: Finished task 2.0 in stage 82.0 (TID 112) in 152 ms on 127.0.0.1 (executor driver) (8/8)
21/03/20 14:58:43 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
21/03/20 14:58:43 INFO DAGScheduler: ShuffleMapStage 82 (count at utils.scala:135) finished in 0,172 s
21/03/20 14:58:43 INFO DAGScheduler: looking for newly runnable stages
21/03/20 14:58:43 INFO DAGScheduler: running: Set()
21/03/20 14:58:43 INFO DAGScheduler: waiting: Set(ResultStage 83)
21/03/20 14:58:43 INFO DAGScheduler: failed: Set()
21/03/20 14:58:43 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[299] at count at utils.scala:135), which has no missing parents
21/03/20 14:58:43 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 10.1 KiB, free 413.8 MiB)
21/03/20 14:58:43 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
21/03/20 14:58:43 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:49848 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 14:58:43 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1223
21/03/20 14:58:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[299] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 14:58:43 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks
21/03/20 14:58:43 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 118, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 14:58:43 INFO Executor: Running task 0.0 in stage 83.0 (TID 118)
21/03/20 14:58:43 INFO ShuffleBlockFetcherIterator: Getting 8 (480.0 B) non-empty blocks including 8 (480.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 14:58:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/20 14:58:43 INFO Executor: Finished task 0.0 in stage 83.0 (TID 118). 2605 bytes result sent to driver
21/03/20 14:58:43 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 118) in 28 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 14:58:43 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
21/03/20 14:58:43 INFO DAGScheduler: ResultStage 83 (count at utils.scala:135) finished in 0,036 s
21/03/20 14:58:43 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 14:58:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 83: Stage finished
21/03/20 14:58:43 INFO DAGScheduler: Job 53 finished: count at utils.scala:135, took 0,332830 s
21/03/20 15:02:27 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:49848 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 15:02:27 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:49848 in memory (size: 18.6 KiB, free: 413.9 MiB)
21/03/20 15:02:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/03/20 15:02:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/03/20 15:02:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/20 15:02:29 INFO SparkContext: Starting job: csv at <unknown>:0
21/03/20 15:02:29 INFO DAGScheduler: Got job 54 (csv at <unknown>:0) with 1 output partitions
21/03/20 15:02:29 INFO DAGScheduler: Final stage: ResultStage 84 (csv at <unknown>:0)
21/03/20 15:02:29 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:02:29 INFO DAGScheduler: Missing parents: List()
21/03/20 15:02:29 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[303] at csv at <unknown>:0), which has no missing parents
21/03/20 15:02:29 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 195.7 KiB, free 413.7 MiB)
21/03/20 15:02:29 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 68.3 KiB, free 413.6 MiB)
21/03/20 15:02:29 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:49848 (size: 68.3 KiB, free: 413.8 MiB)
21/03/20 15:02:29 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1223
21/03/20 15:02:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[303] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/03/20 15:02:29 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks
21/03/20 15:02:29 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 119, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 15:02:29 INFO Executor: Running task 0.0 in stage 84.0 (TID 119)
21/03/20 15:02:29 INFO BlockManager: Found block rdd_23_0 locally
21/03/20 15:02:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/03/20 15:02:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/03/20 15:02:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/20 15:02:31 ERROR Utils: Aborting task
java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:281)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 15:02:31 ERROR FileFormatWriter: Job job_20210320150229_0084 aborted.
21/03/20 15:02:31 ERROR Executor: Exception in task 0.0 in stage 84.0 (TID 119)
org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:291)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:281)
	... 9 more
21/03/20 15:02:31 WARN TaskSetManager: Lost task 0.0 in stage 84.0 (TID 119, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:291)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:281)
	... 9 more

21/03/20 15:02:31 ERROR TaskSetManager: Task 0 in stage 84.0 failed 1 times; aborting job
21/03/20 15:02:31 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
21/03/20 15:02:31 INFO TaskSchedulerImpl: Cancelling stage 84
21/03/20 15:02:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 84: Stage cancelled
21/03/20 15:02:31 INFO DAGScheduler: ResultStage 84 (csv at <unknown>:0) failed in 1,978 s due to Job aborted due to stage failure: Task 0 in stage 84.0 failed 1 times, most recent failure: Lost task 0.0 in stage 84.0 (TID 119, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:291)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:281)
	... 9 more

Driver stacktrace:
21/03/20 15:02:31 INFO DAGScheduler: Job 54 failed: csv at <unknown>:0, took 1,987906 s
21/03/20 15:02:31 ERROR FileFormatWriter: Aborting job b64368c8-e0e0-4652-8782-e3bde3d3f6f3.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 84.0 failed 1 times, most recent failure: Lost task 0.0 in stage 84.0 (TID 119, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:291)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:281)
	... 9 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:195)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:122)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:121)
	at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:963)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:963)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:415)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:399)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:288)
	at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:953)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at sparklyr.Invoke.invoke(invoke.scala:147)
	at sparklyr.StreamHandler.handleMethodCall(stream.scala:136)
	at sparklyr.StreamHandler.read(stream.scala:61)
	at sparklyr.BackendHandler.$anonfun$channelRead0$1(handler.scala:58)
	at scala.util.control.Breaks.breakable(Breaks.scala:42)
	at sparklyr.BackendHandler.channelRead0(handler.scala:39)
	at sparklyr.BackendHandler.channelRead0(handler.scala:14)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:321)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:295)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:291)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:281)
	... 9 more
21/03/20 15:03:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/03/20 15:03:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/03/20 15:03:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/20 15:03:48 INFO SparkContext: Starting job: csv at <unknown>:0
21/03/20 15:03:48 INFO DAGScheduler: Got job 55 (csv at <unknown>:0) with 1 output partitions
21/03/20 15:03:48 INFO DAGScheduler: Final stage: ResultStage 85 (csv at <unknown>:0)
21/03/20 15:03:48 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:03:48 INFO DAGScheduler: Missing parents: List()
21/03/20 15:03:48 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[307] at csv at <unknown>:0), which has no missing parents
21/03/20 15:03:48 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 195.7 KiB, free 413.4 MiB)
21/03/20 15:03:48 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 68.3 KiB, free 413.3 MiB)
21/03/20 15:03:48 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:49848 (size: 68.3 KiB, free: 413.8 MiB)
21/03/20 15:03:48 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1223
21/03/20 15:03:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[307] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/03/20 15:03:48 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks
21/03/20 15:03:48 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 120, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 15:03:48 INFO Executor: Running task 0.0 in stage 85.0 (TID 120)
21/03/20 15:03:48 INFO BlockManager: Found block rdd_23_0 locally
21/03/20 15:03:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/03/20 15:03:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/03/20 15:03:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
21/03/20 15:03:49 ERROR Utils: Aborting task
java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:281)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 15:03:49 ERROR FileFormatWriter: Job job_20210320150348_0085 aborted.
21/03/20 15:03:49 ERROR Executor: Exception in task 0.0 in stage 85.0 (TID 120)
org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:291)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:281)
	... 9 more
21/03/20 15:03:49 WARN TaskSetManager: Lost task 0.0 in stage 85.0 (TID 120, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:291)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:281)
	... 9 more

21/03/20 15:03:49 ERROR TaskSetManager: Task 0 in stage 85.0 failed 1 times; aborting job
21/03/20 15:03:49 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
21/03/20 15:03:49 INFO TaskSchedulerImpl: Cancelling stage 85
21/03/20 15:03:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage cancelled
21/03/20 15:03:49 INFO DAGScheduler: ResultStage 85 (csv at <unknown>:0) failed in 1,269 s due to Job aborted due to stage failure: Task 0 in stage 85.0 failed 1 times, most recent failure: Lost task 0.0 in stage 85.0 (TID 120, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:291)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:281)
	... 9 more

Driver stacktrace:
21/03/20 15:03:49 INFO DAGScheduler: Job 55 failed: csv at <unknown>:0, took 1,276311 s
21/03/20 15:03:49 ERROR FileFormatWriter: Aborting job 41a8da5e-c0fc-4361-a5e0-c7238adbe484.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 85.0 failed 1 times, most recent failure: Lost task 0.0 in stage 85.0 (TID 120, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:291)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:281)
	... 9 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:195)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:122)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:121)
	at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:963)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:963)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:415)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:399)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:288)
	at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:953)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at sparklyr.Invoke.invoke(invoke.scala:147)
	at sparklyr.StreamHandler.handleMethodCall(stream.scala:136)
	at sparklyr.StreamHandler.read(stream.scala:61)
	at sparklyr.BackendHandler.$anonfun$channelRead0$1(handler.scala:58)
	at scala.util.control.Breaks.breakable(Breaks.scala:42)
	at sparklyr.BackendHandler.channelRead0(handler.scala:39)
	at sparklyr.BackendHandler.channelRead0(handler.scala:14)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:321)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:295)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:291)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:281)
	... 9 more
21/03/20 15:04:47 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:49848 in memory (size: 68.3 KiB, free: 413.8 MiB)
21/03/20 15:05:38 INFO HiveMetaStore: 0: get_database: default
21/03/20 15:05:38 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 15:05:38 INFO HiveMetaStore: 0: get_database: default
21/03/20 15:05:38 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 15:05:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 15:05:38 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 15:05:38 INFO SparkContext: Starting job: collect at utils.scala:54
21/03/20 15:05:38 INFO DAGScheduler: Got job 56 (collect at utils.scala:54) with 8 output partitions
21/03/20 15:05:38 INFO DAGScheduler: Final stage: ResultStage 86 (collect at utils.scala:54)
21/03/20 15:05:38 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:05:38 INFO DAGScheduler: Missing parents: List()
21/03/20 15:05:38 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[313] at map at utils.scala:54), which has no missing parents
21/03/20 15:05:38 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 8.7 KiB, free 413.6 MiB)
21/03/20 15:05:38 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.6 MiB)
21/03/20 15:05:38 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:49848 (size: 4.6 KiB, free: 413.8 MiB)
21/03/20 15:05:38 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1223
21/03/20 15:05:38 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 86 (MapPartitionsRDD[313] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
21/03/20 15:05:38 INFO TaskSchedulerImpl: Adding task set 86.0 with 8 tasks
21/03/20 15:05:38 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 121, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
21/03/20 15:05:38 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 122, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7670 bytes)
21/03/20 15:05:38 INFO TaskSetManager: Starting task 2.0 in stage 86.0 (TID 123, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7581 bytes)
21/03/20 15:05:38 INFO TaskSetManager: Starting task 3.0 in stage 86.0 (TID 124, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7670 bytes)
21/03/20 15:05:38 INFO TaskSetManager: Starting task 4.0 in stage 86.0 (TID 125, 127.0.0.1, executor driver, partition 4, PROCESS_LOCAL, 7670 bytes)
21/03/20 15:05:38 INFO TaskSetManager: Starting task 5.0 in stage 86.0 (TID 126, 127.0.0.1, executor driver, partition 5, PROCESS_LOCAL, 7581 bytes)
21/03/20 15:05:38 INFO TaskSetManager: Starting task 6.0 in stage 86.0 (TID 127, 127.0.0.1, executor driver, partition 6, PROCESS_LOCAL, 7670 bytes)
21/03/20 15:05:38 INFO TaskSetManager: Starting task 7.0 in stage 86.0 (TID 128, 127.0.0.1, executor driver, partition 7, PROCESS_LOCAL, 7670 bytes)
21/03/20 15:05:38 INFO Executor: Running task 1.0 in stage 86.0 (TID 122)
21/03/20 15:05:38 INFO Executor: Running task 2.0 in stage 86.0 (TID 123)
21/03/20 15:05:38 INFO Executor: Running task 0.0 in stage 86.0 (TID 121)
21/03/20 15:05:38 INFO Executor: Running task 3.0 in stage 86.0 (TID 124)
21/03/20 15:05:38 INFO Executor: Running task 4.0 in stage 86.0 (TID 125)
21/03/20 15:05:38 INFO Executor: Running task 6.0 in stage 86.0 (TID 127)
21/03/20 15:05:38 INFO Executor: Running task 5.0 in stage 86.0 (TID 126)
21/03/20 15:05:38 INFO Executor: Running task 7.0 in stage 86.0 (TID 128)
21/03/20 15:05:38 INFO Executor: Finished task 2.0 in stage 86.0 (TID 123). 1112 bytes result sent to driver
21/03/20 15:05:38 INFO Executor: Finished task 0.0 in stage 86.0 (TID 121). 1069 bytes result sent to driver
21/03/20 15:05:38 INFO Executor: Finished task 1.0 in stage 86.0 (TID 122). 1164 bytes result sent to driver
21/03/20 15:05:38 INFO Executor: Finished task 5.0 in stage 86.0 (TID 126). 1112 bytes result sent to driver
21/03/20 15:05:38 INFO TaskSetManager: Finished task 2.0 in stage 86.0 (TID 123) in 24 ms on 127.0.0.1 (executor driver) (1/8)
21/03/20 15:05:38 INFO Executor: Finished task 6.0 in stage 86.0 (TID 127). 1164 bytes result sent to driver
21/03/20 15:05:38 INFO Executor: Finished task 7.0 in stage 86.0 (TID 128). 1164 bytes result sent to driver
21/03/20 15:05:38 INFO TaskSetManager: Finished task 5.0 in stage 86.0 (TID 126) in 28 ms on 127.0.0.1 (executor driver) (2/8)
21/03/20 15:05:38 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 122) in 32 ms on 127.0.0.1 (executor driver) (3/8)
21/03/20 15:05:38 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 121) in 32 ms on 127.0.0.1 (executor driver) (4/8)
21/03/20 15:05:38 INFO TaskSetManager: Finished task 6.0 in stage 86.0 (TID 127) in 32 ms on 127.0.0.1 (executor driver) (5/8)
21/03/20 15:05:38 INFO Executor: Finished task 4.0 in stage 86.0 (TID 125). 1165 bytes result sent to driver
21/03/20 15:05:38 INFO Executor: Finished task 3.0 in stage 86.0 (TID 124). 1164 bytes result sent to driver
21/03/20 15:05:38 INFO TaskSetManager: Finished task 7.0 in stage 86.0 (TID 128) in 32 ms on 127.0.0.1 (executor driver) (6/8)
21/03/20 15:05:38 INFO TaskSetManager: Finished task 4.0 in stage 86.0 (TID 125) in 32 ms on 127.0.0.1 (executor driver) (7/8)
21/03/20 15:05:38 INFO TaskSetManager: Finished task 3.0 in stage 86.0 (TID 124) in 36 ms on 127.0.0.1 (executor driver) (8/8)
21/03/20 15:05:38 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
21/03/20 15:05:38 INFO DAGScheduler: ResultStage 86 (collect at utils.scala:54) finished in 0,052 s
21/03/20 15:05:38 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:05:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 86: Stage finished
21/03/20 15:05:38 INFO DAGScheduler: Job 56 finished: collect at utils.scala:54, took 0,067392 s
21/03/20 15:13:35 INFO SparkContext: Invoking stop() from shutdown hook
21/03/20 15:13:35 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
21/03/20 15:13:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/20 15:13:35 INFO MemoryStore: MemoryStore cleared
21/03/20 15:13:35 INFO BlockManager: BlockManager stopped
21/03/20 15:13:35 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/20 15:13:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/20 15:13:35 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-6b35cc38-6524-48c1-a022-2e12d823d664\userFiles-268699f0-2202-4605-a224-33034dbefc77
java.io.IOException: Failed to delete: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-6b35cc38-6524-48c1-a022-2e12d823d664\userFiles-268699f0-2202-4605-a224-33034dbefc77\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:105)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2012)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2012)
	at org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:631)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 15:13:35 INFO SparkContext: Successfully stopped SparkContext
21/03/20 15:13:35 INFO ShutdownHookManager: Shutdown hook called
21/03/20 15:13:35 INFO ShutdownHookManager: Deleting directory C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-6b35cc38-6524-48c1-a022-2e12d823d664\userFiles-268699f0-2202-4605-a224-33034dbefc77
21/03/20 15:13:35 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-6b35cc38-6524-48c1-a022-2e12d823d664\userFiles-268699f0-2202-4605-a224-33034dbefc77
java.io.IOException: Failed to delete: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-6b35cc38-6524-48c1-a022-2e12d823d664\userFiles-268699f0-2202-4605-a224-33034dbefc77\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 15:13:35 INFO ShutdownHookManager: Deleting directory C:\Users\wilto\AppData\Local\Temp\spark-4fd6ff59-4589-4577-b048-f0cd66842224
21/03/20 15:13:35 INFO ShutdownHookManager: Deleting directory C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-6b35cc38-6524-48c1-a022-2e12d823d664
21/03/20 15:13:35 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-6b35cc38-6524-48c1-a022-2e12d823d664
java.io.IOException: Failed to delete: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-6b35cc38-6524-48c1-a022-2e12d823d664\userFiles-268699f0-2202-4605-a224-33034dbefc77\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 15:38:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/20 15:38:41 INFO SecurityManager: Changing view acls to: wilto
21/03/20 15:38:41 INFO SecurityManager: Changing modify acls to: wilto
21/03/20 15:38:41 INFO SecurityManager: Changing view acls groups to: 
21/03/20 15:38:41 INFO SecurityManager: Changing modify acls groups to: 
21/03/20 15:38:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wilto); groups with view permissions: Set(); users  with modify permissions: Set(wilto); groups with modify permissions: Set()
21/03/20 15:38:45 INFO HiveConf: Found configuration file file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/03/20 15:38:45 INFO SparkContext: Running Spark version 3.0.1
21/03/20 15:38:45 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/03/20 15:38:45 INFO ResourceUtils: ==============================================================
21/03/20 15:38:45 INFO ResourceUtils: Resources for spark.driver:

21/03/20 15:38:45 INFO ResourceUtils: ==============================================================
21/03/20 15:38:45 INFO SparkContext: Submitted application: sparklyr
21/03/20 15:38:45 INFO SecurityManager: Changing view acls to: wilto
21/03/20 15:38:45 INFO SecurityManager: Changing modify acls to: wilto
21/03/20 15:38:45 INFO SecurityManager: Changing view acls groups to: 
21/03/20 15:38:45 INFO SecurityManager: Changing modify acls groups to: 
21/03/20 15:38:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wilto); groups with view permissions: Set(); users  with modify permissions: Set(wilto); groups with modify permissions: Set()
21/03/20 15:38:46 INFO Utils: Successfully started service 'sparkDriver' on port 51156.
21/03/20 15:38:46 INFO SparkEnv: Registering MapOutputTracker
21/03/20 15:38:46 INFO SparkEnv: Registering BlockManagerMaster
21/03/20 15:38:46 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/20 15:38:46 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/20 15:38:46 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/03/20 15:38:46 INFO DiskBlockManager: Created local directory at C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\blockmgr-2ee5f380-dd35-49ce-95af-f04a26ba31fd
21/03/20 15:38:46 INFO MemoryStore: MemoryStore started with capacity 413.9 MiB
21/03/20 15:38:46 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/20 15:38:46 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/local]. Please check your configured local directories.
21/03/20 15:38:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/20 15:38:47 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
21/03/20 15:38:47 INFO SparkContext: Added JAR file:/C:/Users/wilto/OneDrive/Documentos/R/win-library/4.0/sparklyr/java/sparklyr-3.0-2.12.jar at spark://127.0.0.1:51156/jars/sparklyr-3.0-2.12.jar with timestamp 1616265527481
21/03/20 15:38:47 INFO Executor: Starting executor ID driver on host 127.0.0.1
21/03/20 15:38:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51200.
21/03/20 15:38:47 INFO NettyBlockTransferService: Server created on 127.0.0.1:51200
21/03/20 15:38:47 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/20 15:38:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51200, None)
21/03/20 15:38:47 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:51200 with 413.9 MiB RAM, BlockManagerId(driver, 127.0.0.1, 51200, None)
21/03/20 15:38:47 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51200, None)
21/03/20 15:38:47 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51200, None)
21/03/20 15:38:48 INFO SharedState: loading hive config file: file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/03/20 15:38:48 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive').
21/03/20 15:38:48 INFO SharedState: Warehouse path is 'C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive'.
21/03/20 15:38:48 WARN SharedState: Not allowing to set spark.sql.warehouse.dir or hive.metastore.warehouse.dir in SparkSession's options, it should be set statically for cross-session usages
21/03/20 15:38:56 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/03/20 15:38:56 INFO HiveConf: Found configuration file file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/03/20 15:38:58 INFO SessionState: Created HDFS directory: C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive/wilto/23e570c0-128c-4cdc-8cba-594bfc2b825a
21/03/20 15:38:58 INFO SessionState: Created local directory: C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive/23e570c0-128c-4cdc-8cba-594bfc2b825a
21/03/20 15:38:59 INFO SessionState: Created HDFS directory: C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive/wilto/23e570c0-128c-4cdc-8cba-594bfc2b825a/_tmp_space.db
21/03/20 15:38:59 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive
21/03/20 15:39:01 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/03/20 15:39:01 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/03/20 15:39:01 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/20 15:39:01 INFO ObjectStore: ObjectStore, initialize called
21/03/20 15:39:01 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/20 15:39:01 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/20 15:39:04 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/20 15:39:07 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/20 15:39:07 INFO ObjectStore: Initialized ObjectStore
21/03/20 15:39:08 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/03/20 15:39:08 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.1.38
21/03/20 15:39:08 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/20 15:39:08 INFO HiveMetaStore: Added admin role in metastore
21/03/20 15:39:08 INFO HiveMetaStore: Added public role in metastore
21/03/20 15:39:08 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/20 15:39:08 INFO HiveMetaStore: 0: get_all_functions
21/03/20 15:39:08 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_all_functions	
21/03/20 15:39:09 INFO HiveMetaStore: 0: get_database: default
21/03/20 15:39:09 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 15:39:09 INFO HiveMetaStore: 0: get_database: global_temp
21/03/20 15:39:09 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/20 15:39:09 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/20 15:39:09 INFO HiveMetaStore: 0: get_database: default
21/03/20 15:39:09 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 15:39:09 INFO HiveMetaStore: 0: get_database: default
21/03/20 15:39:09 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 15:39:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 15:39:09 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 15:39:11 INFO CodeGenerator: Code generated in 536.19 ms
21/03/20 15:39:11 INFO CodeGenerator: Code generated in 29.4143 ms
21/03/20 15:39:12 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 15:39:12 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/03/20 15:39:12 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/03/20 15:39:12 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/03/20 15:39:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/03/20 15:39:12 INFO DAGScheduler: Missing parents: List()
21/03/20 15:39:12 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/03/20 15:39:12 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
21/03/20 15:39:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 15:39:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 15:39:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:51200 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 15:39:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/03/20 15:39:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:39:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/20 15:39:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/03/20 15:39:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/03/20 15:39:12 INFO Executor: Fetching spark://127.0.0.1:51156/jars/sparklyr-3.0-2.12.jar with timestamp 1616265527481
21/03/20 15:39:13 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:51156 after 58 ms (0 ms spent in bootstraps)
21/03/20 15:39:13 INFO Utils: Fetching spark://127.0.0.1:51156/jars/sparklyr-3.0-2.12.jar to C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-73eb9d27-87f9-4c47-91dd-d389abeea179\userFiles-af18454c-3744-4751-a896-bf94cc7d2a4c\fetchFileTemp1946793158440428733.tmp
21/03/20 15:39:13 INFO Executor: Adding file:/C:/Users/wilto/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/local/spark-73eb9d27-87f9-4c47-91dd-d389abeea179/userFiles-af18454c-3744-4751-a896-bf94cc7d2a4c/sparklyr-3.0-2.12.jar to class loader
21/03/20 15:39:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:39:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms
21/03/20 15:39:14 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2727 bytes result sent to driver
21/03/20 15:39:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 1551 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:39:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/20 15:39:14 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 2,016 s
21/03/20 15:39:14 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:39:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/03/20 15:39:14 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 2,149298 s
21/03/20 15:40:12 INFO HiveMetaStore: 0: get_database: default
21/03/20 15:40:12 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 15:40:12 INFO HiveMetaStore: 0: get_database: default
21/03/20 15:40:12 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 15:40:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 15:40:12 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 15:40:12 INFO SparkContext: Starting job: collect at utils.scala:54
21/03/20 15:40:12 INFO DAGScheduler: Job 1 finished: collect at utils.scala:54, took 0,000360 s
21/03/20 15:40:13 INFO CodeGenerator: Code generated in 29.2567 ms
21/03/20 15:40:13 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 15:40:13 INFO DAGScheduler: Got job 2 (collect at utils.scala:137) with 1 output partitions
21/03/20 15:40:13 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:137)
21/03/20 15:40:13 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:40:13 INFO DAGScheduler: Missing parents: List()
21/03/20 15:40:13 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at collect at utils.scala:137), which has no missing parents
21/03/20 15:40:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.7 KiB, free 413.9 MiB)
21/03/20 15:40:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 413.9 MiB)
21/03/20 15:40:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:51200 (size: 3.3 KiB, free: 413.9 MiB)
21/03/20 15:40:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/03/20 15:40:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 15:40:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/20 15:40:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 15:40:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
21/03/20 15:40:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 1397 bytes result sent to driver
21/03/20 15:40:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 39 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:40:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/20 15:40:13 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:137) finished in 0,063 s
21/03/20 15:40:13 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:40:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
21/03/20 15:40:13 INFO DAGScheduler: Job 2 finished: collect at utils.scala:137, took 0,070636 s
21/03/20 15:40:13 INFO CodeGenerator: Code generated in 25.4538 ms
21/03/20 15:40:13 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:51200 in memory (size: 3.3 KiB, free: 413.9 MiB)
21/03/20 15:40:14 INFO CodeGenerator: Code generated in 17.4514 ms
21/03/20 15:40:14 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 15:40:14 INFO DAGScheduler: Registering RDD 17 (count at utils.scala:135) as input to shuffle 1
21/03/20 15:40:14 INFO DAGScheduler: Got job 3 (count at utils.scala:135) with 1 output partitions
21/03/20 15:40:14 INFO DAGScheduler: Final stage: ResultStage 4 (count at utils.scala:135)
21/03/20 15:40:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
21/03/20 15:40:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
21/03/20 15:40:14 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at count at utils.scala:135), which has no missing parents
21/03/20 15:40:14 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 15:40:14 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 15:40:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:51200 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 15:40:14 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1223
21/03/20 15:40:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:40:14 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/20 15:40:14 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 15:40:14 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)
21/03/20 15:40:14 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 1876 bytes result sent to driver
21/03/20 15:40:14 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 170 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:40:14 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/20 15:40:14 INFO DAGScheduler: ShuffleMapStage 3 (count at utils.scala:135) finished in 0,219 s
21/03/20 15:40:14 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:40:14 INFO DAGScheduler: running: Set()
21/03/20 15:40:14 INFO DAGScheduler: waiting: Set(ResultStage 4)
21/03/20 15:40:14 INFO DAGScheduler: failed: Set()
21/03/20 15:40:14 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at count at utils.scala:135), which has no missing parents
21/03/20 15:40:14 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 15:40:14 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 15:40:14 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:51200 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 15:40:14 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1223
21/03/20 15:40:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:40:14 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/20 15:40:14 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:40:14 INFO Executor: Running task 0.0 in stage 4.0 (TID 3)
21/03/20 15:40:14 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:40:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
21/03/20 15:40:14 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:51200 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 15:40:14 INFO Executor: Finished task 0.0 in stage 4.0 (TID 3). 2648 bytes result sent to driver
21/03/20 15:40:14 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 80 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:40:14 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/20 15:40:14 INFO DAGScheduler: ResultStage 4 (count at utils.scala:135) finished in 0,104 s
21/03/20 15:40:14 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:40:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
21/03/20 15:40:14 INFO DAGScheduler: Job 3 finished: count at utils.scala:135, took 0,390340 s
21/03/20 15:40:15 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:51200 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 15:40:15 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 15:40:15 INFO DAGScheduler: Got job 4 (collect at utils.scala:137) with 1 output partitions
21/03/20 15:40:15 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:137)
21/03/20 15:40:15 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:40:15 INFO DAGScheduler: Missing parents: List()
21/03/20 15:40:15 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[22] at collect at utils.scala:137), which has no missing parents
21/03/20 15:40:15 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.5 KiB, free 413.9 MiB)
21/03/20 15:40:15 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 413.9 MiB)
21/03/20 15:40:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:51200 (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 15:40:15 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1223
21/03/20 15:40:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[22] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 15:40:15 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/20 15:40:15 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 15:40:15 INFO Executor: Running task 0.0 in stage 5.0 (TID 4)
21/03/20 15:40:15 INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 1354 bytes result sent to driver
21/03/20 15:40:15 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:40:15 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/20 15:40:15 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:137) finished in 0,036 s
21/03/20 15:40:15 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:40:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
21/03/20 15:40:15 INFO DAGScheduler: Job 4 finished: collect at utils.scala:137, took 0,044251 s
21/03/20 15:40:15 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:51200 in memory (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 15:40:15 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 15:40:15 INFO DAGScheduler: Registering RDD 24 (count at utils.scala:135) as input to shuffle 2
21/03/20 15:40:15 INFO DAGScheduler: Got job 5 (count at utils.scala:135) with 1 output partitions
21/03/20 15:40:15 INFO DAGScheduler: Final stage: ResultStage 7 (count at utils.scala:135)
21/03/20 15:40:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
21/03/20 15:40:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
21/03/20 15:40:15 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/20 15:40:15 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.0 KiB, free 413.9 MiB)
21/03/20 15:40:15 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
21/03/20 15:40:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:51200 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 15:40:15 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1223
21/03/20 15:40:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:40:15 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/20 15:40:15 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 15:40:15 INFO Executor: Running task 0.0 in stage 6.0 (TID 5)
21/03/20 15:40:15 INFO Executor: Finished task 0.0 in stage 6.0 (TID 5). 1790 bytes result sent to driver
21/03/20 15:40:15 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 72 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:40:15 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/20 15:40:15 INFO DAGScheduler: ShuffleMapStage 6 (count at utils.scala:135) finished in 0,108 s
21/03/20 15:40:15 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:40:15 INFO DAGScheduler: running: Set()
21/03/20 15:40:15 INFO DAGScheduler: waiting: Set(ResultStage 7)
21/03/20 15:40:15 INFO DAGScheduler: failed: Set()
21/03/20 15:40:15 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[27] at count at utils.scala:135), which has no missing parents
21/03/20 15:40:15 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 15:40:15 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 15:40:15 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:51200 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 15:40:15 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1223
21/03/20 15:40:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[27] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:40:15 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/20 15:40:15 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 6, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:40:15 INFO Executor: Running task 0.0 in stage 7.0 (TID 6)
21/03/20 15:40:15 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:40:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:40:15 INFO Executor: Finished task 0.0 in stage 7.0 (TID 6). 2605 bytes result sent to driver
21/03/20 15:40:15 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 6) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:40:15 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/20 15:40:15 INFO DAGScheduler: ResultStage 7 (count at utils.scala:135) finished in 0,044 s
21/03/20 15:40:15 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:40:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
21/03/20 15:40:15 INFO DAGScheduler: Job 5 finished: count at utils.scala:135, took 0,171365 s
21/03/20 15:40:16 INFO HiveMetaStore: 0: get_database: default
21/03/20 15:40:16 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 15:40:16 INFO HiveMetaStore: 0: get_database: default
21/03/20 15:40:16 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_database: default	
21/03/20 15:40:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/20 15:40:16 INFO audit: ugi=wilto	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/20 15:40:16 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:51200 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 15:40:16 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:51200 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 15:40:16 INFO CodeGenerator: Code generated in 17.5335 ms
21/03/20 15:40:16 INFO CodeGenerator: Code generated in 22.3366 ms
21/03/20 15:40:16 INFO CodeGenerator: Code generated in 20.8545 ms
21/03/20 15:40:16 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 15:40:16 INFO DAGScheduler: Registering RDD 30 (count at utils.scala:135) as input to shuffle 3
21/03/20 15:40:16 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/20 15:40:16 INFO DAGScheduler: Final stage: ResultStage 9 (count at utils.scala:135)
21/03/20 15:40:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/20 15:40:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/20 15:40:16 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[30] at count at utils.scala:135), which has no missing parents
21/03/20 15:40:16 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 15:40:16 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.9 MiB)
21/03/20 15:40:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:51200 (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 15:40:16 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1223
21/03/20 15:40:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[30] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:40:16 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/20 15:40:16 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7498 bytes)
21/03/20 15:40:16 INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
21/03/20 15:40:16 INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 1790 bytes result sent to driver
21/03/20 15:40:16 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 39 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:40:16 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/20 15:40:16 INFO DAGScheduler: ShuffleMapStage 8 (count at utils.scala:135) finished in 0,056 s
21/03/20 15:40:16 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:40:16 INFO DAGScheduler: running: Set()
21/03/20 15:40:16 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/20 15:40:16 INFO DAGScheduler: failed: Set()
21/03/20 15:40:16 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[33] at count at utils.scala:135), which has no missing parents
21/03/20 15:40:16 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 10.1 KiB, free 413.9 MiB)
21/03/20 15:40:16 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
21/03/20 15:40:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:51200 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 15:40:16 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1223
21/03/20 15:40:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[33] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:40:16 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/20 15:40:16 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 8, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:40:16 INFO Executor: Running task 0.0 in stage 9.0 (TID 8)
21/03/20 15:40:16 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:40:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:40:16 INFO Executor: Finished task 0.0 in stage 9.0 (TID 8). 2605 bytes result sent to driver
21/03/20 15:40:16 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 8) in 17 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:40:16 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/20 15:40:16 INFO DAGScheduler: ResultStage 9 (count at utils.scala:135) finished in 0,032 s
21/03/20 15:40:16 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:40:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
21/03/20 15:40:16 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0,098890 s
21/03/20 15:43:27 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:51200 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 15:43:27 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:51200 in memory (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 15:43:34 INFO CodeGenerator: Code generated in 113.3369 ms
21/03/20 15:43:34 INFO CodeGenerator: Code generated in 58.8221 ms
21/03/20 15:43:34 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 15:43:34 INFO DAGScheduler: Registering RDD 35 (collect at utils.scala:137) as input to shuffle 4
21/03/20 15:43:34 INFO DAGScheduler: Got job 7 (collect at utils.scala:137) with 1 output partitions
21/03/20 15:43:34 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:137)
21/03/20 15:43:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
21/03/20 15:43:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
21/03/20 15:43:34 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[35] at collect at utils.scala:137), which has no missing parents
21/03/20 15:43:34 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 31.3 KiB, free 413.9 MiB)
21/03/20 15:43:34 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 413.9 MiB)
21/03/20 15:43:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:51200 (size: 11.0 KiB, free: 413.9 MiB)
21/03/20 15:43:34 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1223
21/03/20 15:43:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[35] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 15:43:34 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/20 15:43:34 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 15:43:34 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
21/03/20 15:43:34 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 1790 bytes result sent to driver
21/03/20 15:43:34 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 52 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:43:34 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/20 15:43:34 INFO DAGScheduler: ShuffleMapStage 10 (collect at utils.scala:137) finished in 0,108 s
21/03/20 15:43:34 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:43:34 INFO DAGScheduler: running: Set()
21/03/20 15:43:34 INFO DAGScheduler: waiting: Set(ResultStage 11)
21/03/20 15:43:34 INFO DAGScheduler: failed: Set()
21/03/20 15:43:34 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[38] at collect at utils.scala:137), which has no missing parents
21/03/20 15:43:34 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 32.1 KiB, free 413.8 MiB)
21/03/20 15:43:34 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 413.8 MiB)
21/03/20 15:43:34 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:51200 (size: 10.9 KiB, free: 413.9 MiB)
21/03/20 15:43:34 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1223
21/03/20 15:43:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[38] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 15:43:34 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/20 15:43:34 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 10, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:43:34 INFO Executor: Running task 0.0 in stage 11.0 (TID 10)
21/03/20 15:43:34 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:43:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/03/20 15:43:34 INFO Executor: Finished task 0.0 in stage 11.0 (TID 10). 2720 bytes result sent to driver
21/03/20 15:43:34 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 10) in 32 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:43:34 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/20 15:43:34 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:137) finished in 0,051 s
21/03/20 15:43:34 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:43:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
21/03/20 15:43:34 INFO DAGScheduler: Job 7 finished: collect at utils.scala:137, took 0,178319 s
21/03/20 15:43:34 INFO CodeGenerator: Code generated in 22.3877 ms
21/03/20 15:43:34 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:51200 in memory (size: 10.9 KiB, free: 413.9 MiB)
21/03/20 15:43:34 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:51200 in memory (size: 11.0 KiB, free: 413.9 MiB)
21/03/20 15:43:35 INFO CodeGenerator: Code generated in 32.95 ms
21/03/20 15:43:35 INFO CodeGenerator: Code generated in 13.6772 ms
21/03/20 15:43:35 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 15:43:35 INFO DAGScheduler: Registering RDD 40 (count at utils.scala:135) as input to shuffle 5
21/03/20 15:43:35 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/03/20 15:43:35 INFO DAGScheduler: Final stage: ResultStage 13 (count at utils.scala:135)
21/03/20 15:43:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
21/03/20 15:43:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
21/03/20 15:43:35 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[40] at count at utils.scala:135), which has no missing parents
21/03/20 15:43:35 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 9.1 KiB, free 413.9 MiB)
21/03/20 15:43:35 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 413.9 MiB)
21/03/20 15:43:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:51200 (size: 4.8 KiB, free: 413.9 MiB)
21/03/20 15:43:35 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1223
21/03/20 15:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[40] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:43:35 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/20 15:43:35 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 15:43:35 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)
21/03/20 15:43:35 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 1833 bytes result sent to driver
21/03/20 15:43:35 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 52 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:43:35 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/20 15:43:35 INFO DAGScheduler: ShuffleMapStage 12 (count at utils.scala:135) finished in 0,080 s
21/03/20 15:43:35 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:43:35 INFO DAGScheduler: running: Set()
21/03/20 15:43:35 INFO DAGScheduler: waiting: Set(ResultStage 13)
21/03/20 15:43:35 INFO DAGScheduler: failed: Set()
21/03/20 15:43:35 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[43] at count at utils.scala:135), which has no missing parents
21/03/20 15:43:35 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 12.4 KiB, free 413.9 MiB)
21/03/20 15:43:35 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 413.9 MiB)
21/03/20 15:43:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:51200 (size: 5.4 KiB, free: 413.9 MiB)
21/03/20 15:43:35 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1223
21/03/20 15:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[43] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:43:35 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/20 15:43:35 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:43:35 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)
21/03/20 15:43:35 INFO ShuffleBlockFetcherIterator: Getting 1 (49.0 B) non-empty blocks including 1 (49.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:43:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:43:35 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 2896 bytes result sent to driver
21/03/20 15:43:35 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 25 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:43:35 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/20 15:43:35 INFO DAGScheduler: ResultStage 13 (count at utils.scala:135) finished in 0,065 s
21/03/20 15:43:35 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:43:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
21/03/20 15:43:35 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0,159294 s
21/03/20 15:43:36 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:51200 in memory (size: 5.4 KiB, free: 413.9 MiB)
21/03/20 15:43:36 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:51200 in memory (size: 4.8 KiB, free: 413.9 MiB)
21/03/20 15:46:18 INFO CodeGenerator: Code generated in 88.5728 ms
21/03/20 15:46:18 INFO CodeGenerator: Code generated in 129.2279 ms
21/03/20 15:46:19 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 15:46:19 INFO DAGScheduler: Registering RDD 45 (collect at utils.scala:137) as input to shuffle 6
21/03/20 15:46:19 INFO DAGScheduler: Got job 9 (collect at utils.scala:137) with 1 output partitions
21/03/20 15:46:19 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:137)
21/03/20 15:46:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
21/03/20 15:46:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
21/03/20 15:46:19 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[45] at collect at utils.scala:137), which has no missing parents
21/03/20 15:46:19 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 60.6 KiB, free 413.9 MiB)
21/03/20 15:46:19 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 21.7 KiB, free 413.8 MiB)
21/03/20 15:46:19 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:51200 (size: 21.7 KiB, free: 413.9 MiB)
21/03/20 15:46:19 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1223
21/03/20 15:46:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[45] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 15:46:19 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/20 15:46:19 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 13, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 15:46:19 INFO Executor: Running task 0.0 in stage 14.0 (TID 13)
21/03/20 15:46:19 INFO CodeGenerator: Code generated in 87.866 ms
21/03/20 15:46:19 INFO CodeGenerator: Code generated in 19.4903 ms
21/03/20 15:46:19 INFO CodeGenerator: Code generated in 19.2722 ms
21/03/20 15:46:19 INFO CodeGenerator: Code generated in 9.3394 ms
21/03/20 15:46:19 INFO Executor: Finished task 0.0 in stage 14.0 (TID 13). 2164 bytes result sent to driver
21/03/20 15:46:19 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 13) in 341 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:46:19 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/20 15:46:19 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:137) finished in 0,365 s
21/03/20 15:46:19 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:46:19 INFO DAGScheduler: running: Set()
21/03/20 15:46:19 INFO DAGScheduler: waiting: Set(ResultStage 15)
21/03/20 15:46:19 INFO DAGScheduler: failed: Set()
21/03/20 15:46:19 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[48] at collect at utils.scala:137), which has no missing parents
21/03/20 15:46:19 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 59.4 KiB, free 413.8 MiB)
21/03/20 15:46:19 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 21.2 KiB, free 413.8 MiB)
21/03/20 15:46:19 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:51200 (size: 21.2 KiB, free: 413.9 MiB)
21/03/20 15:46:19 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1223
21/03/20 15:46:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[48] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 15:46:19 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/03/20 15:46:19 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 14, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:46:19 INFO Executor: Running task 0.0 in stage 15.0 (TID 14)
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:46:19 INFO Executor: Finished task 0.0 in stage 15.0 (TID 14). 3428 bytes result sent to driver
21/03/20 15:46:19 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 14) in 48 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:46:19 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/03/20 15:46:19 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:137) finished in 0,064 s
21/03/20 15:46:19 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:46:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
21/03/20 15:46:19 INFO DAGScheduler: Job 9 finished: collect at utils.scala:137, took 0,438608 s
21/03/20 15:46:19 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 15:46:19 INFO DAGScheduler: Got job 10 (collect at utils.scala:137) with 4 output partitions
21/03/20 15:46:19 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:137)
21/03/20 15:46:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
21/03/20 15:46:19 INFO DAGScheduler: Missing parents: List()
21/03/20 15:46:19 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[48] at collect at utils.scala:137), which has no missing parents
21/03/20 15:46:19 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 59.4 KiB, free 413.7 MiB)
21/03/20 15:46:19 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 21.2 KiB, free 413.7 MiB)
21/03/20 15:46:19 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:51200 (size: 21.2 KiB, free: 413.9 MiB)
21/03/20 15:46:19 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1223
21/03/20 15:46:19 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 17 (MapPartitionsRDD[48] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
21/03/20 15:46:19 INFO TaskSchedulerImpl: Adding task set 17.0 with 4 tasks
21/03/20 15:46:19 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 15, 127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7325 bytes)
21/03/20 15:46:19 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 16, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7325 bytes)
21/03/20 15:46:19 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 17, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7325 bytes)
21/03/20 15:46:19 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 18, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7325 bytes)
21/03/20 15:46:19 INFO Executor: Running task 3.0 in stage 17.0 (TID 15)
21/03/20 15:46:19 INFO Executor: Running task 0.0 in stage 17.0 (TID 16)
21/03/20 15:46:19 INFO Executor: Running task 2.0 in stage 17.0 (TID 18)
21/03/20 15:46:19 INFO Executor: Running task 1.0 in stage 17.0 (TID 17)
21/03/20 15:46:19 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:51200 in memory (size: 21.7 KiB, free: 413.9 MiB)
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/03/20 15:46:19 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:51200 in memory (size: 21.2 KiB, free: 413.9 MiB)
21/03/20 15:46:19 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:51200 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 15:46:19 INFO Executor: Finished task 1.0 in stage 17.0 (TID 17). 3350 bytes result sent to driver
21/03/20 15:46:19 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 17) in 296 ms on 127.0.0.1 (executor driver) (1/4)
21/03/20 15:46:19 INFO Executor: Finished task 2.0 in stage 17.0 (TID 18). 3350 bytes result sent to driver
21/03/20 15:46:19 INFO Executor: Finished task 0.0 in stage 17.0 (TID 16). 3350 bytes result sent to driver
21/03/20 15:46:19 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 18) in 302 ms on 127.0.0.1 (executor driver) (2/4)
21/03/20 15:46:19 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 16) in 302 ms on 127.0.0.1 (executor driver) (3/4)
21/03/20 15:46:19 INFO Executor: Finished task 3.0 in stage 17.0 (TID 15). 3463 bytes result sent to driver
21/03/20 15:46:19 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 15) in 310 ms on 127.0.0.1 (executor driver) (4/4)
21/03/20 15:46:19 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/03/20 15:46:19 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:137) finished in 0,330 s
21/03/20 15:46:19 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:46:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
21/03/20 15:46:19 INFO DAGScheduler: Job 10 finished: collect at utils.scala:137, took 0,338252 s
21/03/20 15:46:19 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 15:46:19 INFO DAGScheduler: Got job 11 (collect at utils.scala:137) with 3 output partitions
21/03/20 15:46:19 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:137)
21/03/20 15:46:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
21/03/20 15:46:19 INFO DAGScheduler: Missing parents: List()
21/03/20 15:46:19 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[48] at collect at utils.scala:137), which has no missing parents
21/03/20 15:46:19 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 59.4 KiB, free 413.8 MiB)
21/03/20 15:46:19 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 21.2 KiB, free 413.8 MiB)
21/03/20 15:46:19 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:51200 (size: 21.2 KiB, free: 413.9 MiB)
21/03/20 15:46:19 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1223
21/03/20 15:46:19 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 19 (MapPartitionsRDD[48] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(5, 6, 7))
21/03/20 15:46:19 INFO TaskSchedulerImpl: Adding task set 19.0 with 3 tasks
21/03/20 15:46:19 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, 127.0.0.1, executor driver, partition 5, PROCESS_LOCAL, 7325 bytes)
21/03/20 15:46:19 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 20, 127.0.0.1, executor driver, partition 6, PROCESS_LOCAL, 7325 bytes)
21/03/20 15:46:19 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 21, 127.0.0.1, executor driver, partition 7, PROCESS_LOCAL, 7325 bytes)
21/03/20 15:46:19 INFO Executor: Running task 1.0 in stage 19.0 (TID 20)
21/03/20 15:46:19 INFO Executor: Running task 2.0 in stage 19.0 (TID 21)
21/03/20 15:46:19 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/20 15:46:19 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 3307 bytes result sent to driver
21/03/20 15:46:19 INFO Executor: Finished task 1.0 in stage 19.0 (TID 20). 3307 bytes result sent to driver
21/03/20 15:46:19 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 36 ms on 127.0.0.1 (executor driver) (1/3)
21/03/20 15:46:19 INFO Executor: Finished task 2.0 in stage 19.0 (TID 21). 3307 bytes result sent to driver
21/03/20 15:46:19 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 20) in 40 ms on 127.0.0.1 (executor driver) (2/3)
21/03/20 15:46:19 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 21) in 36 ms on 127.0.0.1 (executor driver) (3/3)
21/03/20 15:46:19 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/03/20 15:46:19 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:137) finished in 0,052 s
21/03/20 15:46:19 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:46:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
21/03/20 15:46:19 INFO DAGScheduler: Job 11 finished: collect at utils.scala:137, took 0,062528 s
21/03/20 15:46:19 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:51200 in memory (size: 21.2 KiB, free: 413.9 MiB)
21/03/20 15:46:19 INFO CodeGenerator: Code generated in 32.9501 ms
21/03/20 15:46:20 INFO CodeGenerator: Code generated in 31.4681 ms
21/03/20 15:46:20 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
21/03/20 15:46:20 INFO CodeGenerator: Code generated in 29.9167 ms
21/03/20 15:46:20 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
21/03/20 15:46:20 INFO CodeGenerator: Code generated in 23.8834 ms
21/03/20 15:46:20 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 15:46:20 INFO DAGScheduler: Registering RDD 50 (count at utils.scala:135) as input to shuffle 7
21/03/20 15:46:20 INFO DAGScheduler: Registering RDD 53 (count at utils.scala:135) as input to shuffle 8
21/03/20 15:46:20 INFO DAGScheduler: Got job 12 (count at utils.scala:135) with 1 output partitions
21/03/20 15:46:20 INFO DAGScheduler: Final stage: ResultStage 22 (count at utils.scala:135)
21/03/20 15:46:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
21/03/20 15:46:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
21/03/20 15:46:20 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[50] at count at utils.scala:135), which has no missing parents
21/03/20 15:46:20 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 18.2 KiB, free 413.8 MiB)
21/03/20 15:46:20 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 413.8 MiB)
21/03/20 15:46:20 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:51200 (size: 8.6 KiB, free: 413.9 MiB)
21/03/20 15:46:20 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1223
21/03/20 15:46:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[50] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:46:20 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/03/20 15:46:20 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 22, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 15:46:20 INFO Executor: Running task 0.0 in stage 20.0 (TID 22)
21/03/20 15:46:20 INFO Executor: Finished task 0.0 in stage 20.0 (TID 22). 2121 bytes result sent to driver
21/03/20 15:46:20 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 22) in 72 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:46:20 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/03/20 15:46:20 INFO DAGScheduler: ShuffleMapStage 20 (count at utils.scala:135) finished in 0,086 s
21/03/20 15:46:20 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:46:20 INFO DAGScheduler: running: Set()
21/03/20 15:46:20 INFO DAGScheduler: waiting: Set(ShuffleMapStage 21, ResultStage 22)
21/03/20 15:46:20 INFO DAGScheduler: failed: Set()
21/03/20 15:46:20 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[53] at count at utils.scala:135), which has no missing parents
21/03/20 15:46:20 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 20.1 KiB, free 413.8 MiB)
21/03/20 15:46:20 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 9.8 KiB, free 413.8 MiB)
21/03/20 15:46:20 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:51200 (size: 9.8 KiB, free: 413.9 MiB)
21/03/20 15:46:20 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1223
21/03/20 15:46:20 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[53] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
21/03/20 15:46:20 INFO TaskSchedulerImpl: Adding task set 21.0 with 8 tasks
21/03/20 15:46:20 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 23, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7314 bytes)
21/03/20 15:46:20 INFO TaskSetManager: Starting task 4.0 in stage 21.0 (TID 24, 127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7314 bytes)
21/03/20 15:46:20 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 25, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7314 bytes)
21/03/20 15:46:20 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 26, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7314 bytes)
21/03/20 15:46:20 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 27, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7314 bytes)
21/03/20 15:46:20 INFO TaskSetManager: Starting task 5.0 in stage 21.0 (TID 28, 127.0.0.1, executor driver, partition 5, PROCESS_LOCAL, 7314 bytes)
21/03/20 15:46:20 INFO TaskSetManager: Starting task 6.0 in stage 21.0 (TID 29, 127.0.0.1, executor driver, partition 6, PROCESS_LOCAL, 7314 bytes)
21/03/20 15:46:20 INFO TaskSetManager: Starting task 7.0 in stage 21.0 (TID 30, 127.0.0.1, executor driver, partition 7, PROCESS_LOCAL, 7314 bytes)
21/03/20 15:46:20 INFO Executor: Running task 4.0 in stage 21.0 (TID 24)
21/03/20 15:46:20 INFO Executor: Running task 0.0 in stage 21.0 (TID 23)
21/03/20 15:46:20 INFO Executor: Running task 1.0 in stage 21.0 (TID 25)
21/03/20 15:46:20 INFO Executor: Running task 2.0 in stage 21.0 (TID 26)
21/03/20 15:46:20 INFO Executor: Running task 5.0 in stage 21.0 (TID 28)
21/03/20 15:46:20 INFO Executor: Running task 3.0 in stage 21.0 (TID 27)
21/03/20 15:46:20 INFO Executor: Running task 6.0 in stage 21.0 (TID 29)
21/03/20 15:46:20 INFO Executor: Running task 7.0 in stage 21.0 (TID 30)
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:46:20 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:51200 in memory (size: 8.6 KiB, free: 413.9 MiB)
21/03/20 15:46:20 INFO Executor: Finished task 2.0 in stage 21.0 (TID 26). 3489 bytes result sent to driver
21/03/20 15:46:20 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 26) in 52 ms on 127.0.0.1 (executor driver) (1/8)
21/03/20 15:46:20 INFO Executor: Finished task 7.0 in stage 21.0 (TID 30). 3489 bytes result sent to driver
21/03/20 15:46:20 INFO TaskSetManager: Finished task 7.0 in stage 21.0 (TID 30) in 60 ms on 127.0.0.1 (executor driver) (2/8)
21/03/20 15:46:20 INFO Executor: Finished task 5.0 in stage 21.0 (TID 28). 3446 bytes result sent to driver
21/03/20 15:46:20 INFO TaskSetManager: Finished task 5.0 in stage 21.0 (TID 28) in 85 ms on 127.0.0.1 (executor driver) (3/8)
21/03/20 15:46:20 INFO Executor: Finished task 1.0 in stage 21.0 (TID 25). 3446 bytes result sent to driver
21/03/20 15:46:20 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 25) in 89 ms on 127.0.0.1 (executor driver) (4/8)
21/03/20 15:46:20 INFO Executor: Finished task 6.0 in stage 21.0 (TID 29). 3446 bytes result sent to driver
21/03/20 15:46:20 INFO TaskSetManager: Finished task 6.0 in stage 21.0 (TID 29) in 97 ms on 127.0.0.1 (executor driver) (5/8)
21/03/20 15:46:20 INFO Executor: Finished task 3.0 in stage 21.0 (TID 27). 3446 bytes result sent to driver
21/03/20 15:46:20 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 27) in 109 ms on 127.0.0.1 (executor driver) (6/8)
21/03/20 15:46:20 INFO Executor: Finished task 0.0 in stage 21.0 (TID 23). 3618 bytes result sent to driver
21/03/20 15:46:20 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 23) in 141 ms on 127.0.0.1 (executor driver) (7/8)
21/03/20 15:46:20 INFO Executor: Finished task 4.0 in stage 21.0 (TID 24). 3575 bytes result sent to driver
21/03/20 15:46:20 INFO TaskSetManager: Finished task 4.0 in stage 21.0 (TID 24) in 165 ms on 127.0.0.1 (executor driver) (8/8)
21/03/20 15:46:20 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/03/20 15:46:20 INFO DAGScheduler: ShuffleMapStage 21 (count at utils.scala:135) finished in 0,189 s
21/03/20 15:46:20 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:46:20 INFO DAGScheduler: running: Set()
21/03/20 15:46:20 INFO DAGScheduler: waiting: Set(ResultStage 22)
21/03/20 15:46:20 INFO DAGScheduler: failed: Set()
21/03/20 15:46:20 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[56] at count at utils.scala:135), which has no missing parents
21/03/20 15:46:20 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 11.5 KiB, free 413.8 MiB)
21/03/20 15:46:20 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.8 MiB)
21/03/20 15:46:20 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:51200 (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 15:46:20 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1223
21/03/20 15:46:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[56] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:46:20 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/03/20 15:46:20 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 31, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:46:20 INFO Executor: Running task 0.0 in stage 22.0 (TID 31)
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Getting 2 (98.0 B) non-empty blocks including 2 (98.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:46:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:46:20 INFO Executor: Finished task 0.0 in stage 22.0 (TID 31). 2729 bytes result sent to driver
21/03/20 15:46:20 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 31) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:46:20 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/03/20 15:46:20 INFO DAGScheduler: ResultStage 22 (count at utils.scala:135) finished in 0,040 s
21/03/20 15:46:20 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:46:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
21/03/20 15:46:20 INFO DAGScheduler: Job 12 finished: count at utils.scala:135, took 0,339322 s
21/03/20 15:49:30 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:51200 in memory (size: 9.8 KiB, free: 413.9 MiB)
21/03/20 15:49:30 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:51200 in memory (size: 5.3 KiB, free: 413.9 MiB)
21/03/20 15:49:30 INFO CodeGenerator: Code generated in 10.4093 ms
21/03/20 15:49:30 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 15:49:30 INFO DAGScheduler: Registering RDD 59 (collect at utils.scala:137) as input to shuffle 9
21/03/20 15:49:30 INFO DAGScheduler: Got job 13 (collect at utils.scala:137) with 1 output partitions
21/03/20 15:49:30 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:137)
21/03/20 15:49:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
21/03/20 15:49:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
21/03/20 15:49:30 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[59] at collect at utils.scala:137), which has no missing parents
21/03/20 15:49:30 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 12.8 KiB, free 413.8 MiB)
21/03/20 15:49:30 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 413.8 MiB)
21/03/20 15:49:30 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:51200 (size: 6.4 KiB, free: 413.9 MiB)
21/03/20 15:49:30 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1223
21/03/20 15:49:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[59] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 15:49:30 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/03/20 15:49:30 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 32, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 15:49:30 INFO Executor: Running task 0.0 in stage 23.0 (TID 32)
21/03/20 15:49:30 INFO CodeGenerator: Code generated in 11.2429 ms
21/03/20 15:49:30 INFO CodeGenerator: Code generated in 13.4556 ms
21/03/20 15:49:30 INFO CodeGenerator: Code generated in 33.2739 ms
21/03/20 15:49:30 INFO Executor: Finished task 0.0 in stage 23.0 (TID 32). 1876 bytes result sent to driver
21/03/20 15:49:30 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 32) in 258 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:49:30 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/03/20 15:49:30 INFO DAGScheduler: ShuffleMapStage 23 (collect at utils.scala:137) finished in 0,286 s
21/03/20 15:49:30 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:49:30 INFO DAGScheduler: running: Set()
21/03/20 15:49:30 INFO DAGScheduler: waiting: Set(ResultStage 24)
21/03/20 15:49:30 INFO DAGScheduler: failed: Set()
21/03/20 15:49:30 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[62] at collect at utils.scala:137), which has no missing parents
21/03/20 15:49:30 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 13.4 KiB, free 413.8 MiB)
21/03/20 15:49:30 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 413.8 MiB)
21/03/20 15:49:30 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:51200 (size: 6.7 KiB, free: 413.9 MiB)
21/03/20 15:49:30 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1223
21/03/20 15:49:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[62] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 15:49:30 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/03/20 15:49:30 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 33, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:49:30 INFO Executor: Running task 0.0 in stage 24.0 (TID 33)
21/03/20 15:49:30 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:49:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:49:30 INFO CodeGenerator: Code generated in 10.3769 ms
21/03/20 15:49:30 INFO Executor: Finished task 0.0 in stage 24.0 (TID 33). 2752 bytes result sent to driver
21/03/20 15:49:30 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 33) in 56 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:49:30 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/03/20 15:49:30 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:137) finished in 0,076 s
21/03/20 15:49:30 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:49:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
21/03/20 15:49:30 INFO DAGScheduler: Job 13 finished: collect at utils.scala:137, took 0,378476 s
21/03/20 15:49:30 INFO CodeGenerator: Code generated in 9.2106 ms
21/03/20 15:49:31 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:51200 in memory (size: 6.7 KiB, free: 413.9 MiB)
21/03/20 15:49:31 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:51200 in memory (size: 6.4 KiB, free: 413.9 MiB)
21/03/20 15:49:31 INFO CodeGenerator: Code generated in 14.3319 ms
21/03/20 15:49:31 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 15:49:31 INFO DAGScheduler: Registering RDD 64 (count at utils.scala:135) as input to shuffle 10
21/03/20 15:49:31 INFO DAGScheduler: Got job 14 (count at utils.scala:135) with 1 output partitions
21/03/20 15:49:31 INFO DAGScheduler: Final stage: ResultStage 26 (count at utils.scala:135)
21/03/20 15:49:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
21/03/20 15:49:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
21/03/20 15:49:31 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[64] at count at utils.scala:135), which has no missing parents
21/03/20 15:49:31 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 9.1 KiB, free 413.8 MiB)
21/03/20 15:49:31 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 413.8 MiB)
21/03/20 15:49:31 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:51200 (size: 4.8 KiB, free: 413.9 MiB)
21/03/20 15:49:31 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1223
21/03/20 15:49:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[64] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:49:31 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/03/20 15:49:31 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 34, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 15:49:31 INFO Executor: Running task 0.0 in stage 25.0 (TID 34)
21/03/20 15:49:31 INFO Executor: Finished task 0.0 in stage 25.0 (TID 34). 1790 bytes result sent to driver
21/03/20 15:49:31 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 34) in 28 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:49:31 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/03/20 15:49:31 INFO DAGScheduler: ShuffleMapStage 25 (count at utils.scala:135) finished in 0,044 s
21/03/20 15:49:31 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:49:31 INFO DAGScheduler: running: Set()
21/03/20 15:49:31 INFO DAGScheduler: waiting: Set(ResultStage 26)
21/03/20 15:49:31 INFO DAGScheduler: failed: Set()
21/03/20 15:49:31 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[67] at count at utils.scala:135), which has no missing parents
21/03/20 15:49:31 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 12.4 KiB, free 413.8 MiB)
21/03/20 15:49:31 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 413.8 MiB)
21/03/20 15:49:31 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:51200 (size: 5.4 KiB, free: 413.9 MiB)
21/03/20 15:49:31 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1223
21/03/20 15:49:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[67] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:49:31 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/03/20 15:49:31 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 35, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:49:31 INFO Executor: Running task 0.0 in stage 26.0 (TID 35)
21/03/20 15:49:31 INFO ShuffleBlockFetcherIterator: Getting 1 (49.0 B) non-empty blocks including 1 (49.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:49:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/20 15:49:31 INFO Executor: Finished task 0.0 in stage 26.0 (TID 35). 2853 bytes result sent to driver
21/03/20 15:49:31 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 35) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:49:31 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/03/20 15:49:31 INFO DAGScheduler: ResultStage 26 (count at utils.scala:135) finished in 0,032 s
21/03/20 15:49:31 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:49:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
21/03/20 15:49:31 INFO DAGScheduler: Job 14 finished: count at utils.scala:135, took 0,083238 s
21/03/20 15:50:29 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:51200 in memory (size: 4.8 KiB, free: 413.9 MiB)
21/03/20 15:50:29 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:51200 in memory (size: 5.4 KiB, free: 413.9 MiB)
21/03/20 15:50:29 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 15:50:29 INFO DAGScheduler: Registering RDD 70 (collect at utils.scala:137) as input to shuffle 11
21/03/20 15:50:29 INFO DAGScheduler: Got job 15 (collect at utils.scala:137) with 1 output partitions
21/03/20 15:50:29 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:137)
21/03/20 15:50:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
21/03/20 15:50:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)
21/03/20 15:50:29 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[70] at collect at utils.scala:137), which has no missing parents
21/03/20 15:50:29 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 13.1 KiB, free 413.8 MiB)
21/03/20 15:50:29 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 413.8 MiB)
21/03/20 15:50:29 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:51200 (size: 6.5 KiB, free: 413.9 MiB)
21/03/20 15:50:29 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1223
21/03/20 15:50:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[70] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 15:50:29 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
21/03/20 15:50:29 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 36, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 15:50:29 INFO Executor: Running task 0.0 in stage 27.0 (TID 36)
21/03/20 15:50:29 INFO Executor: Finished task 0.0 in stage 27.0 (TID 36). 1833 bytes result sent to driver
21/03/20 15:50:29 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 36) in 36 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:50:29 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
21/03/20 15:50:29 INFO DAGScheduler: ShuffleMapStage 27 (collect at utils.scala:137) finished in 0,072 s
21/03/20 15:50:29 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:50:29 INFO DAGScheduler: running: Set()
21/03/20 15:50:29 INFO DAGScheduler: waiting: Set(ResultStage 28)
21/03/20 15:50:29 INFO DAGScheduler: failed: Set()
21/03/20 15:50:29 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[73] at collect at utils.scala:137), which has no missing parents
21/03/20 15:50:29 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 13.6 KiB, free 413.8 MiB)
21/03/20 15:50:29 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 413.8 MiB)
21/03/20 15:50:29 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:51200 (size: 6.9 KiB, free: 413.9 MiB)
21/03/20 15:50:29 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1223
21/03/20 15:50:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[73] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 15:50:29 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
21/03/20 15:50:29 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 37, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:50:29 INFO Executor: Running task 0.0 in stage 28.0 (TID 37)
21/03/20 15:50:29 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:50:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:50:29 INFO CodeGenerator: Code generated in 18.2075 ms
21/03/20 15:50:29 INFO Executor: Finished task 0.0 in stage 28.0 (TID 37). 2783 bytes result sent to driver
21/03/20 15:50:29 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 37) in 48 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:50:29 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
21/03/20 15:50:29 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:137) finished in 0,064 s
21/03/20 15:50:29 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:50:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
21/03/20 15:50:29 INFO DAGScheduler: Job 15 finished: collect at utils.scala:137, took 0,152410 s
21/03/20 15:50:29 INFO CodeGenerator: Code generated in 40.8312 ms
21/03/20 15:50:29 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:51200 in memory (size: 6.5 KiB, free: 413.9 MiB)
21/03/20 15:50:29 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:51200 in memory (size: 6.9 KiB, free: 413.9 MiB)
21/03/20 15:50:29 INFO CodeGenerator: Code generated in 16.9491 ms
21/03/20 15:50:29 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 15:50:29 INFO DAGScheduler: Registering RDD 75 (count at utils.scala:135) as input to shuffle 12
21/03/20 15:50:29 INFO DAGScheduler: Got job 16 (count at utils.scala:135) with 1 output partitions
21/03/20 15:50:29 INFO DAGScheduler: Final stage: ResultStage 30 (count at utils.scala:135)
21/03/20 15:50:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
21/03/20 15:50:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
21/03/20 15:50:29 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[75] at count at utils.scala:135), which has no missing parents
21/03/20 15:50:29 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 9.1 KiB, free 413.8 MiB)
21/03/20 15:50:29 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 413.8 MiB)
21/03/20 15:50:29 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:51200 (size: 4.8 KiB, free: 413.9 MiB)
21/03/20 15:50:29 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1223
21/03/20 15:50:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[75] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:50:29 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
21/03/20 15:50:29 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 38, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 15:50:29 INFO Executor: Running task 0.0 in stage 29.0 (TID 38)
21/03/20 15:50:29 INFO Executor: Finished task 0.0 in stage 29.0 (TID 38). 1790 bytes result sent to driver
21/03/20 15:50:29 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 38) in 32 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:50:29 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
21/03/20 15:50:29 INFO DAGScheduler: ShuffleMapStage 29 (count at utils.scala:135) finished in 0,044 s
21/03/20 15:50:29 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:50:29 INFO DAGScheduler: running: Set()
21/03/20 15:50:29 INFO DAGScheduler: waiting: Set(ResultStage 30)
21/03/20 15:50:29 INFO DAGScheduler: failed: Set()
21/03/20 15:50:29 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[78] at count at utils.scala:135), which has no missing parents
21/03/20 15:50:29 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 12.4 KiB, free 413.8 MiB)
21/03/20 15:50:29 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 413.8 MiB)
21/03/20 15:50:29 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:51200 (size: 5.4 KiB, free: 413.9 MiB)
21/03/20 15:50:29 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1223
21/03/20 15:50:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[78] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:50:29 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
21/03/20 15:50:29 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 39, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:50:29 INFO Executor: Running task 0.0 in stage 30.0 (TID 39)
21/03/20 15:50:29 INFO ShuffleBlockFetcherIterator: Getting 1 (49.0 B) non-empty blocks including 1 (49.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:50:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:50:29 INFO Executor: Finished task 0.0 in stage 30.0 (TID 39). 2853 bytes result sent to driver
21/03/20 15:50:29 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 39) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:50:29 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
21/03/20 15:50:29 INFO DAGScheduler: ResultStage 30 (count at utils.scala:135) finished in 0,044 s
21/03/20 15:50:29 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:50:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
21/03/20 15:50:29 INFO DAGScheduler: Job 16 finished: count at utils.scala:135, took 0,097109 s
21/03/20 15:51:09 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:51200 in memory (size: 5.4 KiB, free: 413.9 MiB)
21/03/20 15:51:09 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:51200 in memory (size: 4.8 KiB, free: 413.9 MiB)
21/03/20 15:51:09 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 15:51:09 INFO DAGScheduler: Registering RDD 81 (collect at utils.scala:137) as input to shuffle 13
21/03/20 15:51:09 INFO DAGScheduler: Got job 17 (collect at utils.scala:137) with 1 output partitions
21/03/20 15:51:09 INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:137)
21/03/20 15:51:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
21/03/20 15:51:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
21/03/20 15:51:09 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[81] at collect at utils.scala:137), which has no missing parents
21/03/20 15:51:09 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 13.1 KiB, free 413.8 MiB)
21/03/20 15:51:09 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 413.8 MiB)
21/03/20 15:51:09 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:51200 (size: 6.5 KiB, free: 413.9 MiB)
21/03/20 15:51:09 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1223
21/03/20 15:51:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[81] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 15:51:09 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
21/03/20 15:51:09 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 40, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 15:51:09 INFO Executor: Running task 0.0 in stage 31.0 (TID 40)
21/03/20 15:51:09 INFO Executor: Finished task 0.0 in stage 31.0 (TID 40). 1790 bytes result sent to driver
21/03/20 15:51:09 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 40) in 44 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:51:09 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
21/03/20 15:51:09 INFO DAGScheduler: ShuffleMapStage 31 (collect at utils.scala:137) finished in 0,060 s
21/03/20 15:51:09 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:51:09 INFO DAGScheduler: running: Set()
21/03/20 15:51:09 INFO DAGScheduler: waiting: Set(ResultStage 32)
21/03/20 15:51:09 INFO DAGScheduler: failed: Set()
21/03/20 15:51:09 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[85] at collect at utils.scala:137), which has no missing parents
21/03/20 15:51:09 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 14.7 KiB, free 413.8 MiB)
21/03/20 15:51:09 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 413.8 MiB)
21/03/20 15:51:09 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:51200 (size: 7.3 KiB, free: 413.9 MiB)
21/03/20 15:51:09 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1223
21/03/20 15:51:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[85] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 15:51:09 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
21/03/20 15:51:09 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 41, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:51:09 INFO Executor: Running task 0.0 in stage 32.0 (TID 41)
21/03/20 15:51:09 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:51:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:51:09 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:51200 in memory (size: 6.5 KiB, free: 413.9 MiB)
21/03/20 15:51:09 INFO CodeGenerator: Code generated in 9.4048 ms
21/03/20 15:51:09 INFO Executor: Finished task 0.0 in stage 32.0 (TID 41). 2921 bytes result sent to driver
21/03/20 15:51:09 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 41) in 120 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:51:09 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
21/03/20 15:51:09 INFO DAGScheduler: ResultStage 32 (collect at utils.scala:137) finished in 0,162 s
21/03/20 15:51:09 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:51:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
21/03/20 15:51:09 INFO DAGScheduler: Job 17 finished: collect at utils.scala:137, took 0,240414 s
21/03/20 15:51:09 INFO CodeGenerator: Code generated in 8.286 ms
21/03/20 15:51:09 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:51200 in memory (size: 7.3 KiB, free: 413.9 MiB)
21/03/20 15:51:09 INFO CodeGenerator: Code generated in 19.0652 ms
21/03/20 15:51:09 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 15:51:09 INFO DAGScheduler: Registering RDD 88 (count at utils.scala:135) as input to shuffle 14
21/03/20 15:51:09 INFO DAGScheduler: Got job 18 (count at utils.scala:135) with 1 output partitions
21/03/20 15:51:09 INFO DAGScheduler: Final stage: ResultStage 34 (count at utils.scala:135)
21/03/20 15:51:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
21/03/20 15:51:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
21/03/20 15:51:09 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[88] at count at utils.scala:135), which has no missing parents
21/03/20 15:51:09 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 13.1 KiB, free 413.8 MiB)
21/03/20 15:51:09 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 413.8 MiB)
21/03/20 15:51:09 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:51200 (size: 6.5 KiB, free: 413.9 MiB)
21/03/20 15:51:09 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1223
21/03/20 15:51:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[88] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:51:09 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
21/03/20 15:51:09 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 42, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11097 bytes)
21/03/20 15:51:09 INFO Executor: Running task 0.0 in stage 33.0 (TID 42)
21/03/20 15:51:09 INFO Executor: Finished task 0.0 in stage 33.0 (TID 42). 1790 bytes result sent to driver
21/03/20 15:51:09 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 42) in 52 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:51:09 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
21/03/20 15:51:09 INFO DAGScheduler: ShuffleMapStage 33 (count at utils.scala:135) finished in 0,064 s
21/03/20 15:51:09 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:51:09 INFO DAGScheduler: running: Set()
21/03/20 15:51:09 INFO DAGScheduler: waiting: Set(ResultStage 34)
21/03/20 15:51:09 INFO DAGScheduler: failed: Set()
21/03/20 15:51:09 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[93] at count at utils.scala:135), which has no missing parents
21/03/20 15:51:09 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 19.5 KiB, free 413.8 MiB)
21/03/20 15:51:09 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 8.9 KiB, free 413.8 MiB)
21/03/20 15:51:09 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:51200 (size: 8.9 KiB, free: 413.9 MiB)
21/03/20 15:51:09 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1223
21/03/20 15:51:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[93] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:51:09 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
21/03/20 15:51:09 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 43, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:51:09 INFO Executor: Running task 0.0 in stage 34.0 (TID 43)
21/03/20 15:51:09 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:51:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:51:09 INFO Executor: Finished task 0.0 in stage 34.0 (TID 43). 3206 bytes result sent to driver
21/03/20 15:51:09 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 43) in 36 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:51:09 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
21/03/20 15:51:09 INFO DAGScheduler: ResultStage 34 (count at utils.scala:135) finished in 0,052 s
21/03/20 15:51:09 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:51:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
21/03/20 15:51:09 INFO DAGScheduler: Job 18 finished: count at utils.scala:135, took 0,131593 s
21/03/20 15:51:45 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:51200 in memory (size: 8.9 KiB, free: 413.9 MiB)
21/03/20 15:51:45 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:51200 in memory (size: 6.5 KiB, free: 413.9 MiB)
21/03/20 15:51:46 INFO CodeGenerator: Code generated in 13.225 ms
21/03/20 15:51:46 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 15:51:46 INFO DAGScheduler: Got job 19 (collect at utils.scala:137) with 1 output partitions
21/03/20 15:51:46 INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:137)
21/03/20 15:51:46 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:51:46 INFO DAGScheduler: Missing parents: List()
21/03/20 15:51:46 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[95] at collect at utils.scala:137), which has no missing parents
21/03/20 15:51:46 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 7.5 KiB, free 413.8 MiB)
21/03/20 15:51:46 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 413.8 MiB)
21/03/20 15:51:46 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:51200 (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 15:51:46 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1223
21/03/20 15:51:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[95] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 15:51:46 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
21/03/20 15:51:46 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 44, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 15:51:46 INFO Executor: Running task 0.0 in stage 35.0 (TID 44)
21/03/20 15:51:46 INFO Executor: Finished task 0.0 in stage 35.0 (TID 44). 1354 bytes result sent to driver
21/03/20 15:51:46 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 44) in 23 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:51:46 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
21/03/20 15:51:46 INFO DAGScheduler: ResultStage 35 (collect at utils.scala:137) finished in 0,043 s
21/03/20 15:51:46 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:51:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
21/03/20 15:51:46 INFO DAGScheduler: Job 19 finished: collect at utils.scala:137, took 0,049958 s
21/03/20 15:51:46 INFO CodeGenerator: Code generated in 21.2597 ms
21/03/20 15:51:46 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:51200 in memory (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 15:51:46 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 15:51:46 INFO DAGScheduler: Registering RDD 97 (count at utils.scala:135) as input to shuffle 15
21/03/20 15:51:46 INFO DAGScheduler: Got job 20 (count at utils.scala:135) with 1 output partitions
21/03/20 15:51:46 INFO DAGScheduler: Final stage: ResultStage 37 (count at utils.scala:135)
21/03/20 15:51:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
21/03/20 15:51:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 36)
21/03/20 15:51:46 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[97] at count at utils.scala:135), which has no missing parents
21/03/20 15:51:46 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 10.0 KiB, free 413.8 MiB)
21/03/20 15:51:46 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.8 MiB)
21/03/20 15:51:46 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:51200 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 15:51:46 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1223
21/03/20 15:51:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[97] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:51:46 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
21/03/20 15:51:46 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 45, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 15:51:46 INFO Executor: Running task 0.0 in stage 36.0 (TID 45)
21/03/20 15:51:46 INFO Executor: Finished task 0.0 in stage 36.0 (TID 45). 1790 bytes result sent to driver
21/03/20 15:51:46 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 45) in 36 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:51:46 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
21/03/20 15:51:46 INFO DAGScheduler: ShuffleMapStage 36 (count at utils.scala:135) finished in 0,056 s
21/03/20 15:51:46 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:51:46 INFO DAGScheduler: running: Set()
21/03/20 15:51:46 INFO DAGScheduler: waiting: Set(ResultStage 37)
21/03/20 15:51:46 INFO DAGScheduler: failed: Set()
21/03/20 15:51:46 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[100] at count at utils.scala:135), which has no missing parents
21/03/20 15:51:46 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 10.1 KiB, free 413.8 MiB)
21/03/20 15:51:46 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
21/03/20 15:51:46 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:51200 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 15:51:46 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1223
21/03/20 15:51:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[100] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:51:46 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
21/03/20 15:51:46 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 46, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:51:46 INFO Executor: Running task 0.0 in stage 37.0 (TID 46)
21/03/20 15:51:46 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:51:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:51:46 INFO Executor: Finished task 0.0 in stage 37.0 (TID 46). 2605 bytes result sent to driver
21/03/20 15:51:46 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 46) in 21 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:51:46 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
21/03/20 15:51:46 INFO DAGScheduler: ResultStage 37 (count at utils.scala:135) finished in 0,033 s
21/03/20 15:51:46 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:51:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
21/03/20 15:51:46 INFO DAGScheduler: Job 20 finished: count at utils.scala:135, took 0,104065 s
21/03/20 15:51:47 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:51200 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 15:51:47 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:51200 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 15:51:47 INFO CodeGenerator: Code generated in 45.2955 ms
21/03/20 15:51:47 INFO CodeGenerator: Code generated in 13.0948 ms
21/03/20 15:51:48 INFO SparkContext: Starting job: first at RowMatrix.scala:62
21/03/20 15:51:48 INFO DAGScheduler: Got job 21 (first at RowMatrix.scala:62) with 1 output partitions
21/03/20 15:51:48 INFO DAGScheduler: Final stage: ResultStage 38 (first at RowMatrix.scala:62)
21/03/20 15:51:48 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:51:48 INFO DAGScheduler: Missing parents: List()
21/03/20 15:51:48 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[110] at map at Correlation.scala:68), which has no missing parents
21/03/20 15:51:48 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 43.8 KiB, free 413.8 MiB)
21/03/20 15:51:48 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 413.8 MiB)
21/03/20 15:51:48 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:51200 (size: 17.2 KiB, free: 413.9 MiB)
21/03/20 15:51:48 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1223
21/03/20 15:51:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[110] at map at Correlation.scala:68) (first 15 tasks are for partitions Vector(0))
21/03/20 15:51:48 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
21/03/20 15:51:48 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 47, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 15:51:48 INFO Executor: Running task 0.0 in stage 38.0 (TID 47)
21/03/20 15:51:48 INFO MemoryStore: Block rdd_102_0 stored as values in memory (estimated size 3.9 KiB, free 413.8 MiB)
21/03/20 15:51:48 INFO BlockManagerInfo: Added rdd_102_0 in memory on 127.0.0.1:51200 (size: 3.9 KiB, free: 413.9 MiB)
21/03/20 15:51:48 INFO CodeGenerator: Code generated in 8.5549 ms
21/03/20 15:51:48 INFO CodeGenerator: Code generated in 10.5237 ms
21/03/20 15:51:48 INFO Executor: 1 block locks were not released by TID = 47:
[rdd_102_0]
21/03/20 15:51:48 INFO Executor: Finished task 0.0 in stage 38.0 (TID 47). 1819 bytes result sent to driver
21/03/20 15:51:48 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 47) in 503 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:51:48 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
21/03/20 15:51:48 INFO DAGScheduler: ResultStage 38 (first at RowMatrix.scala:62) finished in 0,527 s
21/03/20 15:51:48 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:51:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
21/03/20 15:51:48 INFO DAGScheduler: Job 21 finished: first at RowMatrix.scala:62, took 0,540145 s
21/03/20 15:51:48 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:51200 in memory (size: 17.2 KiB, free: 413.9 MiB)
21/03/20 15:51:48 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
21/03/20 15:51:48 INFO DAGScheduler: Got job 22 (treeAggregate at Statistics.scala:58) with 1 output partitions
21/03/20 15:51:48 INFO DAGScheduler: Final stage: ResultStage 39 (treeAggregate at Statistics.scala:58)
21/03/20 15:51:48 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:51:48 INFO DAGScheduler: Missing parents: List()
21/03/20 15:51:48 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[112] at treeAggregate at Statistics.scala:58), which has no missing parents
21/03/20 15:51:48 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 45.8 KiB, free 413.8 MiB)
21/03/20 15:51:48 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 413.8 MiB)
21/03/20 15:51:48 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:51200 (size: 17.9 KiB, free: 413.9 MiB)
21/03/20 15:51:48 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1223
21/03/20 15:51:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[112] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0))
21/03/20 15:51:48 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
21/03/20 15:51:48 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 48, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 15:51:48 INFO Executor: Running task 0.0 in stage 39.0 (TID 48)
21/03/20 15:51:48 INFO BlockManager: Found block rdd_102_0 locally
21/03/20 15:51:48 INFO Executor: Finished task 0.0 in stage 39.0 (TID 48). 2548 bytes result sent to driver
21/03/20 15:51:48 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 48) in 102 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:51:48 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
21/03/20 15:51:48 INFO DAGScheduler: ResultStage 39 (treeAggregate at Statistics.scala:58) finished in 0,126 s
21/03/20 15:51:48 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:51:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
21/03/20 15:51:48 INFO DAGScheduler: Job 22 finished: treeAggregate at Statistics.scala:58, took 0,134594 s
21/03/20 15:51:48 INFO SparkContext: Starting job: first at RowMatrix.scala:442
21/03/20 15:51:48 INFO DAGScheduler: Got job 23 (first at RowMatrix.scala:442) with 1 output partitions
21/03/20 15:51:48 INFO DAGScheduler: Final stage: ResultStage 40 (first at RowMatrix.scala:442)
21/03/20 15:51:48 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:51:48 INFO DAGScheduler: Missing parents: List()
21/03/20 15:51:48 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[110] at map at Correlation.scala:68), which has no missing parents
21/03/20 15:51:48 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 43.8 KiB, free 413.7 MiB)
21/03/20 15:51:48 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 413.7 MiB)
21/03/20 15:51:48 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:51200 (size: 17.2 KiB, free: 413.9 MiB)
21/03/20 15:51:48 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1223
21/03/20 15:51:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[110] at map at Correlation.scala:68) (first 15 tasks are for partitions Vector(0))
21/03/20 15:51:48 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
21/03/20 15:51:48 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 49, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 15:51:48 INFO Executor: Running task 0.0 in stage 40.0 (TID 49)
21/03/20 15:51:48 INFO BlockManager: Found block rdd_102_0 locally
21/03/20 15:51:48 INFO Executor: 1 block locks were not released by TID = 49:
[rdd_102_0]
21/03/20 15:51:48 INFO Executor: Finished task 0.0 in stage 40.0 (TID 49). 1776 bytes result sent to driver
21/03/20 15:51:48 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 49) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:51:48 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
21/03/20 15:51:48 INFO DAGScheduler: ResultStage 40 (first at RowMatrix.scala:442) finished in 0,040 s
21/03/20 15:51:48 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:51:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
21/03/20 15:51:48 INFO DAGScheduler: Job 23 finished: first at RowMatrix.scala:442, took 0,052265 s
21/03/20 15:51:48 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 144.0 B, free 413.7 MiB)
21/03/20 15:51:49 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 224.0 B, free 413.7 MiB)
21/03/20 15:51:49 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:51200 (size: 224.0 B, free: 413.9 MiB)
21/03/20 15:51:49 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:51200 in memory (size: 17.9 KiB, free: 413.9 MiB)
21/03/20 15:51:49 INFO SparkContext: Created broadcast 38 from broadcast at RowMatrix.scala:150
21/03/20 15:51:49 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:51200 in memory (size: 17.2 KiB, free: 413.9 MiB)
21/03/20 15:51:49 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:156
21/03/20 15:51:49 INFO DAGScheduler: Got job 24 (treeAggregate at RowMatrix.scala:156) with 1 output partitions
21/03/20 15:51:49 INFO DAGScheduler: Final stage: ResultStage 41 (treeAggregate at RowMatrix.scala:156)
21/03/20 15:51:49 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:51:49 INFO DAGScheduler: Missing parents: List()
21/03/20 15:51:49 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[113] at treeAggregate at RowMatrix.scala:156), which has no missing parents
21/03/20 15:51:49 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 45.4 KiB, free 413.8 MiB)
21/03/20 15:51:49 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 413.8 MiB)
21/03/20 15:51:49 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:51200 (size: 17.8 KiB, free: 413.9 MiB)
21/03/20 15:51:49 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1223
21/03/20 15:51:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[113] at treeAggregate at RowMatrix.scala:156) (first 15 tasks are for partitions Vector(0))
21/03/20 15:51:49 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
21/03/20 15:51:49 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 50, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 15:51:49 INFO Executor: Running task 0.0 in stage 41.0 (TID 50)
21/03/20 15:51:49 INFO BlockManager: Found block rdd_102_0 locally
21/03/20 15:51:50 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
21/03/20 15:51:50 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
21/03/20 15:51:50 INFO Executor: Finished task 0.0 in stage 41.0 (TID 50). 2340 bytes result sent to driver
21/03/20 15:51:50 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 50) in 1533 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:51:50 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
21/03/20 15:51:50 INFO DAGScheduler: ResultStage 41 (treeAggregate at RowMatrix.scala:156) finished in 1,793 s
21/03/20 15:51:50 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:51:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
21/03/20 15:51:50 INFO DAGScheduler: Job 24 finished: treeAggregate at RowMatrix.scala:156, took 1,802258 s
21/03/20 15:51:50 INFO TorrentBroadcast: Destroying Broadcast(38) (from destroy at RowMatrix.scala:186)
21/03/20 15:51:50 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:51200 in memory (size: 224.0 B, free: 413.9 MiB)
21/03/20 15:51:51 INFO CodeGenerator: Code generated in 17.673 ms
21/03/20 15:51:51 INFO CodeGenerator: Code generated in 15.7143 ms
21/03/20 15:53:21 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 15:53:21 INFO DAGScheduler: Got job 25 (collect at utils.scala:137) with 1 output partitions
21/03/20 15:53:21 INFO DAGScheduler: Final stage: ResultStage 42 (collect at utils.scala:137)
21/03/20 15:53:21 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:53:21 INFO DAGScheduler: Missing parents: List()
21/03/20 15:53:21 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[115] at collect at utils.scala:137), which has no missing parents
21/03/20 15:53:21 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 7.5 KiB, free 413.8 MiB)
21/03/20 15:53:21 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 413.8 MiB)
21/03/20 15:53:21 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:51200 (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 15:53:21 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1223
21/03/20 15:53:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[115] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 15:53:21 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
21/03/20 15:53:21 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 51, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 15:53:21 INFO Executor: Running task 0.0 in stage 42.0 (TID 51)
21/03/20 15:53:21 INFO Executor: Finished task 0.0 in stage 42.0 (TID 51). 1354 bytes result sent to driver
21/03/20 15:53:21 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 51) in 12 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:53:21 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
21/03/20 15:53:21 INFO DAGScheduler: ResultStage 42 (collect at utils.scala:137) finished in 0,028 s
21/03/20 15:53:21 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:53:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
21/03/20 15:53:21 INFO DAGScheduler: Job 25 finished: collect at utils.scala:137, took 0,037926 s
21/03/20 15:53:21 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:51200 in memory (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 15:53:21 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 15:53:21 INFO DAGScheduler: Registering RDD 117 (count at utils.scala:135) as input to shuffle 16
21/03/20 15:53:21 INFO DAGScheduler: Got job 26 (count at utils.scala:135) with 1 output partitions
21/03/20 15:53:21 INFO DAGScheduler: Final stage: ResultStage 44 (count at utils.scala:135)
21/03/20 15:53:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
21/03/20 15:53:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)
21/03/20 15:53:21 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[117] at count at utils.scala:135), which has no missing parents
21/03/20 15:53:21 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 10.0 KiB, free 413.8 MiB)
21/03/20 15:53:21 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.8 MiB)
21/03/20 15:53:21 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:51200 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 15:53:21 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1223
21/03/20 15:53:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[117] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:53:21 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
21/03/20 15:53:21 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 52, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 15:53:21 INFO Executor: Running task 0.0 in stage 43.0 (TID 52)
21/03/20 15:53:21 INFO Executor: Finished task 0.0 in stage 43.0 (TID 52). 1833 bytes result sent to driver
21/03/20 15:53:21 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 52) in 36 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:53:21 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
21/03/20 15:53:21 INFO DAGScheduler: ShuffleMapStage 43 (count at utils.scala:135) finished in 0,052 s
21/03/20 15:53:21 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:53:21 INFO DAGScheduler: running: Set()
21/03/20 15:53:21 INFO DAGScheduler: waiting: Set(ResultStage 44)
21/03/20 15:53:21 INFO DAGScheduler: failed: Set()
21/03/20 15:53:21 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[120] at count at utils.scala:135), which has no missing parents
21/03/20 15:53:21 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 10.1 KiB, free 413.8 MiB)
21/03/20 15:53:21 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
21/03/20 15:53:21 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:51200 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 15:53:21 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1223
21/03/20 15:53:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[120] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:53:21 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
21/03/20 15:53:21 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 53, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:53:21 INFO Executor: Running task 0.0 in stage 44.0 (TID 53)
21/03/20 15:53:21 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:53:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:53:21 INFO Executor: Finished task 0.0 in stage 44.0 (TID 53). 2605 bytes result sent to driver
21/03/20 15:53:21 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 53) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:53:21 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
21/03/20 15:53:21 INFO DAGScheduler: ResultStage 44 (count at utils.scala:135) finished in 0,036 s
21/03/20 15:53:21 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:53:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
21/03/20 15:53:21 INFO DAGScheduler: Job 26 finished: count at utils.scala:135, took 0,098677 s
21/03/20 15:53:22 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:51200 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 15:53:22 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:51200 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 15:53:22 INFO SparkContext: Starting job: first at RowMatrix.scala:62
21/03/20 15:53:22 INFO DAGScheduler: Got job 27 (first at RowMatrix.scala:62) with 1 output partitions
21/03/20 15:53:22 INFO DAGScheduler: Final stage: ResultStage 45 (first at RowMatrix.scala:62)
21/03/20 15:53:22 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:53:22 INFO DAGScheduler: Missing parents: List()
21/03/20 15:53:22 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[128] at map at Correlation.scala:68), which has no missing parents
21/03/20 15:53:22 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 43.8 KiB, free 413.7 MiB)
21/03/20 15:53:22 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 413.7 MiB)
21/03/20 15:53:22 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:51200 (size: 17.2 KiB, free: 413.9 MiB)
21/03/20 15:53:22 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1223
21/03/20 15:53:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[128] at map at Correlation.scala:68) (first 15 tasks are for partitions Vector(0))
21/03/20 15:53:22 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
21/03/20 15:53:22 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 54, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 15:53:22 INFO Executor: Running task 0.0 in stage 45.0 (TID 54)
21/03/20 15:53:22 INFO BlockManager: Found block rdd_102_0 locally
21/03/20 15:53:22 INFO Executor: 1 block locks were not released by TID = 54:
[rdd_102_0]
21/03/20 15:53:22 INFO Executor: Finished task 0.0 in stage 45.0 (TID 54). 1776 bytes result sent to driver
21/03/20 15:53:22 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 54) in 32 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:53:22 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
21/03/20 15:53:22 INFO DAGScheduler: ResultStage 45 (first at RowMatrix.scala:62) finished in 0,052 s
21/03/20 15:53:22 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:53:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
21/03/20 15:53:22 INFO DAGScheduler: Job 27 finished: first at RowMatrix.scala:62, took 0,056200 s
21/03/20 15:53:22 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:51200 in memory (size: 17.2 KiB, free: 413.9 MiB)
21/03/20 15:53:22 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
21/03/20 15:53:22 INFO DAGScheduler: Got job 28 (treeAggregate at Statistics.scala:58) with 1 output partitions
21/03/20 15:53:22 INFO DAGScheduler: Final stage: ResultStage 46 (treeAggregate at Statistics.scala:58)
21/03/20 15:53:22 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:53:22 INFO DAGScheduler: Missing parents: List()
21/03/20 15:53:22 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[130] at treeAggregate at Statistics.scala:58), which has no missing parents
21/03/20 15:53:22 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 45.8 KiB, free 413.7 MiB)
21/03/20 15:53:22 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 413.7 MiB)
21/03/20 15:53:22 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:51200 (size: 17.9 KiB, free: 413.9 MiB)
21/03/20 15:53:22 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1223
21/03/20 15:53:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[130] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0))
21/03/20 15:53:22 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
21/03/20 15:53:22 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 55, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 15:53:22 INFO Executor: Running task 0.0 in stage 46.0 (TID 55)
21/03/20 15:53:22 INFO BlockManager: Found block rdd_102_0 locally
21/03/20 15:53:22 INFO Executor: Finished task 0.0 in stage 46.0 (TID 55). 2548 bytes result sent to driver
21/03/20 15:53:22 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 55) in 44 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:53:22 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
21/03/20 15:53:22 INFO DAGScheduler: ResultStage 46 (treeAggregate at Statistics.scala:58) finished in 0,068 s
21/03/20 15:53:22 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:53:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
21/03/20 15:53:22 INFO DAGScheduler: Job 28 finished: treeAggregate at Statistics.scala:58, took 0,080494 s
21/03/20 15:53:22 INFO SparkContext: Starting job: first at RowMatrix.scala:442
21/03/20 15:53:22 INFO DAGScheduler: Got job 29 (first at RowMatrix.scala:442) with 1 output partitions
21/03/20 15:53:22 INFO DAGScheduler: Final stage: ResultStage 47 (first at RowMatrix.scala:442)
21/03/20 15:53:22 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:53:22 INFO DAGScheduler: Missing parents: List()
21/03/20 15:53:22 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[128] at map at Correlation.scala:68), which has no missing parents
21/03/20 15:53:22 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 43.8 KiB, free 413.7 MiB)
21/03/20 15:53:22 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 413.7 MiB)
21/03/20 15:53:22 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:51200 (size: 17.2 KiB, free: 413.8 MiB)
21/03/20 15:53:22 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1223
21/03/20 15:53:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[128] at map at Correlation.scala:68) (first 15 tasks are for partitions Vector(0))
21/03/20 15:53:22 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
21/03/20 15:53:22 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 56, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 15:53:22 INFO Executor: Running task 0.0 in stage 47.0 (TID 56)
21/03/20 15:53:22 INFO BlockManager: Found block rdd_102_0 locally
21/03/20 15:53:22 INFO Executor: 1 block locks were not released by TID = 56:
[rdd_102_0]
21/03/20 15:53:22 INFO Executor: Finished task 0.0 in stage 47.0 (TID 56). 1819 bytes result sent to driver
21/03/20 15:53:22 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 56) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:53:22 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
21/03/20 15:53:22 INFO DAGScheduler: ResultStage 47 (first at RowMatrix.scala:442) finished in 0,043 s
21/03/20 15:53:22 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:53:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
21/03/20 15:53:22 INFO DAGScheduler: Job 29 finished: first at RowMatrix.scala:442, took 0,054795 s
21/03/20 15:53:22 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 144.0 B, free 413.7 MiB)
21/03/20 15:53:22 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 224.0 B, free 413.7 MiB)
21/03/20 15:53:22 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:51200 (size: 224.0 B, free: 413.8 MiB)
21/03/20 15:53:22 INFO SparkContext: Created broadcast 46 from broadcast at RowMatrix.scala:150
21/03/20 15:53:22 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:156
21/03/20 15:53:22 INFO DAGScheduler: Got job 30 (treeAggregate at RowMatrix.scala:156) with 1 output partitions
21/03/20 15:53:22 INFO DAGScheduler: Final stage: ResultStage 48 (treeAggregate at RowMatrix.scala:156)
21/03/20 15:53:22 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:53:22 INFO DAGScheduler: Missing parents: List()
21/03/20 15:53:22 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[131] at treeAggregate at RowMatrix.scala:156), which has no missing parents
21/03/20 15:53:22 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 45.4 KiB, free 413.6 MiB)
21/03/20 15:53:22 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:51200 in memory (size: 17.9 KiB, free: 413.9 MiB)
21/03/20 15:53:22 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 413.7 MiB)
21/03/20 15:53:22 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:51200 (size: 17.8 KiB, free: 413.8 MiB)
21/03/20 15:53:22 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1223
21/03/20 15:53:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[131] at treeAggregate at RowMatrix.scala:156) (first 15 tasks are for partitions Vector(0))
21/03/20 15:53:22 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
21/03/20 15:53:22 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:51200 in memory (size: 17.2 KiB, free: 413.9 MiB)
21/03/20 15:53:22 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 57, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 15:53:22 INFO Executor: Running task 0.0 in stage 48.0 (TID 57)
21/03/20 15:53:22 INFO BlockManager: Found block rdd_102_0 locally
21/03/20 15:53:22 INFO Executor: Finished task 0.0 in stage 48.0 (TID 57). 2254 bytes result sent to driver
21/03/20 15:53:22 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 57) in 36 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:53:22 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
21/03/20 15:53:22 INFO DAGScheduler: ResultStage 48 (treeAggregate at RowMatrix.scala:156) finished in 0,068 s
21/03/20 15:53:22 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:53:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
21/03/20 15:53:22 INFO DAGScheduler: Job 30 finished: treeAggregate at RowMatrix.scala:156, took 0,078972 s
21/03/20 15:53:22 INFO TorrentBroadcast: Destroying Broadcast(46) (from destroy at RowMatrix.scala:186)
21/03/20 15:53:22 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:51200 in memory (size: 224.0 B, free: 413.9 MiB)
21/03/20 15:53:37 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:51200 in memory (size: 17.8 KiB, free: 413.9 MiB)
21/03/20 15:53:37 INFO SparkContext: Starting job: collect at utils.scala:137
21/03/20 15:53:37 INFO DAGScheduler: Got job 31 (collect at utils.scala:137) with 1 output partitions
21/03/20 15:53:37 INFO DAGScheduler: Final stage: ResultStage 49 (collect at utils.scala:137)
21/03/20 15:53:37 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:53:37 INFO DAGScheduler: Missing parents: List()
21/03/20 15:53:37 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[133] at collect at utils.scala:137), which has no missing parents
21/03/20 15:53:37 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 7.5 KiB, free 413.8 MiB)
21/03/20 15:53:37 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 413.8 MiB)
21/03/20 15:53:37 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:51200 (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 15:53:37 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1223
21/03/20 15:53:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[133] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/03/20 15:53:37 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
21/03/20 15:53:37 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 58, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/03/20 15:53:37 INFO Executor: Running task 0.0 in stage 49.0 (TID 58)
21/03/20 15:53:37 INFO Executor: Finished task 0.0 in stage 49.0 (TID 58). 1354 bytes result sent to driver
21/03/20 15:53:37 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 58) in 8 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:53:37 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
21/03/20 15:53:37 INFO DAGScheduler: ResultStage 49 (collect at utils.scala:137) finished in 0,016 s
21/03/20 15:53:37 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:53:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
21/03/20 15:53:37 INFO DAGScheduler: Job 31 finished: collect at utils.scala:137, took 0,023173 s
21/03/20 15:53:37 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:51200 in memory (size: 3.7 KiB, free: 413.9 MiB)
21/03/20 15:53:37 INFO SparkContext: Starting job: count at utils.scala:135
21/03/20 15:53:37 INFO DAGScheduler: Registering RDD 135 (count at utils.scala:135) as input to shuffle 17
21/03/20 15:53:37 INFO DAGScheduler: Got job 32 (count at utils.scala:135) with 1 output partitions
21/03/20 15:53:37 INFO DAGScheduler: Final stage: ResultStage 51 (count at utils.scala:135)
21/03/20 15:53:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
21/03/20 15:53:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 50)
21/03/20 15:53:37 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[135] at count at utils.scala:135), which has no missing parents
21/03/20 15:53:37 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 10.0 KiB, free 413.8 MiB)
21/03/20 15:53:37 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.8 MiB)
21/03/20 15:53:37 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:51200 (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 15:53:37 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1223
21/03/20 15:53:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[135] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:53:37 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
21/03/20 15:53:37 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 59, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/03/20 15:53:37 INFO Executor: Running task 0.0 in stage 50.0 (TID 59)
21/03/20 15:53:37 INFO Executor: Finished task 0.0 in stage 50.0 (TID 59). 1833 bytes result sent to driver
21/03/20 15:53:37 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 59) in 28 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:53:37 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
21/03/20 15:53:37 INFO DAGScheduler: ShuffleMapStage 50 (count at utils.scala:135) finished in 0,040 s
21/03/20 15:53:37 INFO DAGScheduler: looking for newly runnable stages
21/03/20 15:53:37 INFO DAGScheduler: running: Set()
21/03/20 15:53:37 INFO DAGScheduler: waiting: Set(ResultStage 51)
21/03/20 15:53:37 INFO DAGScheduler: failed: Set()
21/03/20 15:53:37 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[138] at count at utils.scala:135), which has no missing parents
21/03/20 15:53:37 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 10.1 KiB, free 413.8 MiB)
21/03/20 15:53:37 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
21/03/20 15:53:37 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:51200 (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 15:53:37 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1223
21/03/20 15:53:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[138] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/20 15:53:37 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
21/03/20 15:53:37 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 60, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/03/20 15:53:37 INFO Executor: Running task 0.0 in stage 51.0 (TID 60)
21/03/20 15:53:37 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/03/20 15:53:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/20 15:53:37 INFO Executor: Finished task 0.0 in stage 51.0 (TID 60). 2605 bytes result sent to driver
21/03/20 15:53:37 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 60) in 16 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:53:37 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
21/03/20 15:53:37 INFO DAGScheduler: ResultStage 51 (count at utils.scala:135) finished in 0,028 s
21/03/20 15:53:37 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:53:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
21/03/20 15:53:37 INFO DAGScheduler: Job 32 finished: count at utils.scala:135, took 0,078799 s
21/03/20 15:53:38 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:51200 in memory (size: 5.0 KiB, free: 413.9 MiB)
21/03/20 15:53:38 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:51200 in memory (size: 5.2 KiB, free: 413.9 MiB)
21/03/20 15:53:38 INFO SparkContext: Starting job: first at RowMatrix.scala:62
21/03/20 15:53:38 INFO DAGScheduler: Got job 33 (first at RowMatrix.scala:62) with 1 output partitions
21/03/20 15:53:38 INFO DAGScheduler: Final stage: ResultStage 52 (first at RowMatrix.scala:62)
21/03/20 15:53:38 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:53:38 INFO DAGScheduler: Missing parents: List()
21/03/20 15:53:38 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[146] at map at Correlation.scala:68), which has no missing parents
21/03/20 15:53:38 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 43.8 KiB, free 413.7 MiB)
21/03/20 15:53:38 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 413.7 MiB)
21/03/20 15:53:38 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:51200 (size: 17.2 KiB, free: 413.9 MiB)
21/03/20 15:53:38 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1223
21/03/20 15:53:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[146] at map at Correlation.scala:68) (first 15 tasks are for partitions Vector(0))
21/03/20 15:53:38 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
21/03/20 15:53:38 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 61, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 15:53:38 INFO Executor: Running task 0.0 in stage 52.0 (TID 61)
21/03/20 15:53:38 INFO BlockManager: Found block rdd_102_0 locally
21/03/20 15:53:38 INFO Executor: 1 block locks were not released by TID = 61:
[rdd_102_0]
21/03/20 15:53:38 INFO Executor: Finished task 0.0 in stage 52.0 (TID 61). 1819 bytes result sent to driver
21/03/20 15:53:38 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 61) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:53:38 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
21/03/20 15:53:38 INFO DAGScheduler: ResultStage 52 (first at RowMatrix.scala:62) finished in 0,044 s
21/03/20 15:53:38 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:53:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished
21/03/20 15:53:38 INFO DAGScheduler: Job 33 finished: first at RowMatrix.scala:62, took 0,056432 s
21/03/20 15:53:38 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
21/03/20 15:53:38 INFO DAGScheduler: Got job 34 (treeAggregate at Statistics.scala:58) with 1 output partitions
21/03/20 15:53:38 INFO DAGScheduler: Final stage: ResultStage 53 (treeAggregate at Statistics.scala:58)
21/03/20 15:53:38 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:53:38 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:51200 in memory (size: 17.2 KiB, free: 413.9 MiB)
21/03/20 15:53:38 INFO DAGScheduler: Missing parents: List()
21/03/20 15:53:38 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[148] at treeAggregate at Statistics.scala:58), which has no missing parents
21/03/20 15:53:38 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 45.8 KiB, free 413.7 MiB)
21/03/20 15:53:38 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 413.7 MiB)
21/03/20 15:53:38 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:51200 (size: 17.9 KiB, free: 413.9 MiB)
21/03/20 15:53:38 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1223
21/03/20 15:53:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[148] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0))
21/03/20 15:53:38 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
21/03/20 15:53:38 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 62, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 15:53:38 INFO Executor: Running task 0.0 in stage 53.0 (TID 62)
21/03/20 15:53:38 INFO BlockManager: Found block rdd_102_0 locally
21/03/20 15:53:38 INFO Executor: Finished task 0.0 in stage 53.0 (TID 62). 2505 bytes result sent to driver
21/03/20 15:53:38 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 62) in 24 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:53:38 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
21/03/20 15:53:38 INFO DAGScheduler: ResultStage 53 (treeAggregate at Statistics.scala:58) finished in 0,044 s
21/03/20 15:53:38 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:53:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
21/03/20 15:53:38 INFO DAGScheduler: Job 34 finished: treeAggregate at Statistics.scala:58, took 0,073273 s
21/03/20 15:53:38 INFO SparkContext: Starting job: first at RowMatrix.scala:442
21/03/20 15:53:38 INFO DAGScheduler: Got job 35 (first at RowMatrix.scala:442) with 1 output partitions
21/03/20 15:53:38 INFO DAGScheduler: Final stage: ResultStage 54 (first at RowMatrix.scala:442)
21/03/20 15:53:38 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:53:38 INFO DAGScheduler: Missing parents: List()
21/03/20 15:53:38 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[146] at map at Correlation.scala:68), which has no missing parents
21/03/20 15:53:38 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 43.8 KiB, free 413.7 MiB)
21/03/20 15:53:38 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 413.7 MiB)
21/03/20 15:53:38 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:51200 (size: 17.2 KiB, free: 413.8 MiB)
21/03/20 15:53:38 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1223
21/03/20 15:53:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[146] at map at Correlation.scala:68) (first 15 tasks are for partitions Vector(0))
21/03/20 15:53:38 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
21/03/20 15:53:38 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 63, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 15:53:38 INFO Executor: Running task 0.0 in stage 54.0 (TID 63)
21/03/20 15:53:38 INFO BlockManager: Found block rdd_102_0 locally
21/03/20 15:53:38 INFO Executor: 1 block locks were not released by TID = 63:
[rdd_102_0]
21/03/20 15:53:38 INFO Executor: Finished task 0.0 in stage 54.0 (TID 63). 1776 bytes result sent to driver
21/03/20 15:53:38 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 63) in 25 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:53:38 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
21/03/20 15:53:38 INFO DAGScheduler: ResultStage 54 (first at RowMatrix.scala:442) finished in 0,041 s
21/03/20 15:53:38 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:53:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
21/03/20 15:53:38 INFO DAGScheduler: Job 35 finished: first at RowMatrix.scala:442, took 0,046792 s
21/03/20 15:53:38 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 144.0 B, free 413.7 MiB)
21/03/20 15:53:38 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 224.0 B, free 413.7 MiB)
21/03/20 15:53:38 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:51200 (size: 224.0 B, free: 413.8 MiB)
21/03/20 15:53:38 INFO SparkContext: Created broadcast 54 from broadcast at RowMatrix.scala:150
21/03/20 15:53:38 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:156
21/03/20 15:53:38 INFO DAGScheduler: Got job 36 (treeAggregate at RowMatrix.scala:156) with 1 output partitions
21/03/20 15:53:38 INFO DAGScheduler: Final stage: ResultStage 55 (treeAggregate at RowMatrix.scala:156)
21/03/20 15:53:38 INFO DAGScheduler: Parents of final stage: List()
21/03/20 15:53:38 INFO DAGScheduler: Missing parents: List()
21/03/20 15:53:38 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[149] at treeAggregate at RowMatrix.scala:156), which has no missing parents
21/03/20 15:53:38 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 45.4 KiB, free 413.6 MiB)
21/03/20 15:53:38 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 413.6 MiB)
21/03/20 15:53:38 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:51200 (size: 17.8 KiB, free: 413.8 MiB)
21/03/20 15:53:38 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:51200 in memory (size: 17.2 KiB, free: 413.8 MiB)
21/03/20 15:53:38 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1223
21/03/20 15:53:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[149] at treeAggregate at RowMatrix.scala:156) (first 15 tasks are for partitions Vector(0))
21/03/20 15:53:38 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
21/03/20 15:53:38 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 64, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11108 bytes)
21/03/20 15:53:38 INFO Executor: Running task 0.0 in stage 55.0 (TID 64)
21/03/20 15:53:38 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:51200 in memory (size: 17.9 KiB, free: 413.9 MiB)
21/03/20 15:53:38 INFO BlockManager: Found block rdd_102_0 locally
21/03/20 15:53:38 INFO Executor: Finished task 0.0 in stage 55.0 (TID 64). 2254 bytes result sent to driver
21/03/20 15:53:38 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 64) in 32 ms on 127.0.0.1 (executor driver) (1/1)
21/03/20 15:53:38 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
21/03/20 15:53:38 INFO DAGScheduler: ResultStage 55 (treeAggregate at RowMatrix.scala:156) finished in 0,060 s
21/03/20 15:53:38 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
21/03/20 15:53:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
21/03/20 15:53:38 INFO DAGScheduler: Job 36 finished: treeAggregate at RowMatrix.scala:156, took 0,073245 s
21/03/20 15:53:38 INFO TorrentBroadcast: Destroying Broadcast(54) (from destroy at RowMatrix.scala:186)
21/03/20 15:53:38 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:51200 in memory (size: 224.0 B, free: 413.9 MiB)
21/03/20 15:53:40 INFO SparkContext: Invoking stop() from shutdown hook
21/03/20 15:53:40 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
21/03/20 15:53:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/20 15:53:40 INFO MemoryStore: MemoryStore cleared
21/03/20 15:53:40 INFO BlockManager: BlockManager stopped
21/03/20 15:53:40 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/20 15:53:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/20 15:53:40 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-73eb9d27-87f9-4c47-91dd-d389abeea179\userFiles-af18454c-3744-4751-a896-bf94cc7d2a4c
java.io.IOException: Failed to delete: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-73eb9d27-87f9-4c47-91dd-d389abeea179\userFiles-af18454c-3744-4751-a896-bf94cc7d2a4c\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:105)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2012)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2012)
	at org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:631)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 15:53:40 INFO SparkContext: Successfully stopped SparkContext
21/03/20 15:53:40 INFO ShutdownHookManager: Shutdown hook called
21/03/20 15:53:40 INFO ShutdownHookManager: Deleting directory C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-73eb9d27-87f9-4c47-91dd-d389abeea179\userFiles-af18454c-3744-4751-a896-bf94cc7d2a4c
21/03/20 15:53:40 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-73eb9d27-87f9-4c47-91dd-d389abeea179\userFiles-af18454c-3744-4751-a896-bf94cc7d2a4c
java.io.IOException: Failed to delete: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-73eb9d27-87f9-4c47-91dd-d389abeea179\userFiles-af18454c-3744-4751-a896-bf94cc7d2a4c\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 15:53:40 INFO ShutdownHookManager: Deleting directory C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-73eb9d27-87f9-4c47-91dd-d389abeea179
21/03/20 15:53:40 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-73eb9d27-87f9-4c47-91dd-d389abeea179
java.io.IOException: Failed to delete: C:\Users\wilto\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-73eb9d27-87f9-4c47-91dd-d389abeea179\userFiles-af18454c-3744-4751-a896-bf94cc7d2a4c\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/03/20 15:53:40 INFO ShutdownHookManager: Deleting directory C:\Users\wilto\AppData\Local\Temp\spark-45d585b6-58c7-4057-827e-d1c788f52791
